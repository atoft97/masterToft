[01/28 11:39:53] detectron2 INFO: Rank of current process: 0. World size: 1
[01/28 11:39:53] detectron2 INFO: Environment info:
----------------------  ------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]
numpy                   1.20.3
detectron2              0.6 @/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 9.3
CUDA compiler           CUDA 11.4
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.1+cu102 @/usr/local/lib/python3.8/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   GRID RTX8000-8Q (arch=7.5)
Driver version          470.63.01
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.1+cu102 @/usr/local/lib/python3.8/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.4
----------------------  ------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/28 11:39:53] detectron2 INFO: Command line arguments: Namespace(config_file='', dist_url='tcp://127.0.0.1:54076', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/28 11:39:53] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m  [39m-[38;5;15m [39mffi_train_stuffonly
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mabsolute
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39mmask_former_semantic
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mbitmask
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m256
[38;5;15m  [39m-[38;5;15m [39m307
[38;5;15m  [39m-[38;5;15m [39m358
[38;5;15m  [39m-[38;5;15m [39m409
[38;5;15m  [39m-[38;5;15m [39m460
[38;5;15m  [39m-[38;5;15m [39m512
[38;5;15m  [39m-[38;5;15m [39m563
[38;5;15m  [39m-[38;5;15m [39m614
[38;5;15m  [39m-[38;5;15m [39m665
[38;5;15m  [39m-[38;5;15m [39m716
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m819
[38;5;15m  [39m-[38;5;15m [39m870
[38;5;15m  [39m-[38;5;15m [39m921
[38;5;15m  [39m-[38;5;15m [39m972
[38;5;15m  [39m-[38;5;15m [39m1024
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m      [39m-[38;5;15m [39m64
[38;5;15m      [39m-[38;5;15m [39m128
[38;5;15m      [39m-[38;5;15m [39m256
[38;5;15m      [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mD2SwinTransformer
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m6
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m20.0
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m32
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39mres5
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mMaskFormer
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m123.675
[38;5;15m  [39m-[38;5;15m [39m116.28
[38;5;15m  [39m-[38;5;15m [39m103.53
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m58.395
[38;5;15m  [39m-[38;5;15m [39m57.12
[38;5;15m  [39m-[38;5;15m [39m57.375
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39mbasic
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id003[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRes5ROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id003[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m6000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m12000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m18
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39mhard_pixel_mining
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskFormerHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m13
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39mBasePixelDecoder
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m48
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.3
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m96
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m4.0
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m3
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m24
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m224
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m7
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39mmodels/model_final_8657a5.pkl
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m./ffiModel
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.0002
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mfull_model
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupPolyLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m160
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39mADAMW
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0e-06
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m1500
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m3584
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m384
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m640
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m896
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m40
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[01/28 11:39:53] detectron2 INFO: Full config saved to ./ffiModel/config.yaml
[01/28 11:39:53] d2.utils.env INFO: Using a generated random seed 54199928
[01/28 11:39:58] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): BasePixelDecoder(
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_2): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_3): Conv2d(
        384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_4): Conv2d(
        768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (predictor): TransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList()
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (3): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (4): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (5): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (query_embed): Embedding(100, 256)
      (input_proj): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (class_embed): Linear(in_features=256, out_features=14, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 1.0
  )
)
[01/28 11:39:58] mask_former.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerSemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2048, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[512, 512], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7ff3a3a650a0>, RandomFlip()]
[01/28 11:39:58] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:39:58] d2.data.build INFO: Using training sampler TrainingSampler
[01/28 11:39:58] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:39:58] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:39:58] fvcore.common.checkpoint INFO: [Checkpointer] Loading from models/model_final_8657a5.pkl ...
[01/28 11:39:58] fvcore.common.checkpoint INFO: Reading a file from 'MaskFormer Model Zoo'
[01/28 11:39:58] mask_former.modeling.heads.mask_former_head WARNING: Weight format of MaskFormerHead have changed! Please upgrade your models. Applying automatic conversion now ...
[01/28 11:39:58] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (151, 256) in the checkpoint but (14, 256) in the model! You might want to double check if this is expected.
[01/28 11:39:58] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (151,) in the checkpoint but (14,) in the model! You might want to double check if this is expected.
[01/28 11:39:58] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (151,) in the checkpoint but (14,) in the model! You might want to double check if this is expected.
[01/28 11:39:58] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[01/28 11:39:58] d2.engine.train_loop INFO: Starting training from iteration 0
[01/28 11:40:07] d2.utils.events INFO:  eta: 0:01:02  iter: 19  total_loss: 18.19  loss_ce: 2.579  loss_mask: 0.174  loss_dice: 0.3502  loss_ce_0: 2.531  loss_mask_0: 0.1827  loss_dice_0: 0.3406  loss_ce_1: 2.38  loss_mask_1: 0.1806  loss_dice_1: 0.3435  loss_ce_2: 2.466  loss_mask_2: 0.1849  loss_dice_2: 0.3451  loss_ce_3: 2.5  loss_mask_3: 0.1675  loss_dice_3: 0.3495  loss_ce_4: 2.598  loss_mask_4: 0.1738  loss_dice_4: 0.3522  time: 0.4465  data_time: 0.0782  lr: 2.2611e-06  max_mem: 5320M
[01/28 11:40:16] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:40:16] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/28 11:40:16] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:40:16] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:40:16] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:40:16] d2.evaluation.evaluator INFO: Start inference on 6 batches
[01/28 11:40:16] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.094949 (0.094949 s / iter per device, on 1 devices)
[01/28 11:40:16] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.043645 s / iter per device, on 1 devices)
[01/28 11:40:16] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 5.89516056747419, 'fwIoU': 4.97844743917727, 'IoU-Grass': nan, 'IoU-CameraEdge': 2.6113789793626623, 'IoU-Vehicle': 0.0, 'IoU-Person': nan, 'IoU-Bush': 0.0, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 32.75958442548248, 'IoU-Large_stone': 0.0, 'IoU-Forrest': nan, 'IoU-Gravel': 0.0, 'IoU-Car': nan, 'mACC': 17.961128627504127, 'pACC': 15.234257133238705, 'ACC-Grass': nan, 'ACC-CameraEdge': 8.475616481014136, 'ACC-Vehicle': 0.0, 'ACC-Person': nan, 'ACC-Bush': 0.0, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 99.29115528401063, 'ACC-Large_stone': 0.0, 'ACC-Forrest': nan, 'ACC-Gravel': 0.0, 'ACC-Car': nan})])
[01/28 11:40:16] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 150, in train
    self.after_step()
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 180, in after_step
    h.after_step()
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/hooks.py", line 552, in after_step
    self._do_eval()
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/hooks.py", line 525, in _do_eval
    results = self._func()
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 453, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "trainMaskSemantic.py", line 365, in test
    write_to_csv(results_train, trainName)
  File "trainMaskSemantic.py", line 77, in write_to_csv
    writer_object.writerow(new_data)
  File "/usr/lib/python3.8/csv.py", line 154, in writerow
    return self.writer.writerow(self._dict_to_list(rowdict))
  File "/usr/lib/python3.8/csv.py", line 149, in _dict_to_list
    raise ValueError("dict contains fields not in fieldnames: "
ValueError: dict contains fields not in fieldnames: 'IoU-Car', 'ACC-Car'
[01/28 11:40:16] d2.engine.hooks INFO: Overall training speed: 37 iterations in 0:00:16 (0.4571 s / it)
[01/28 11:40:16] d2.engine.hooks INFO: Total training time: 0:00:17 (0:00:00 on hooks)
[01/28 11:40:16] d2.utils.events INFO:  eta: 0:00:53  iter: 39  total_loss: 14.92  loss_ce: 1.976  loss_mask: 0.1671  loss_dice: 0.3195  loss_ce_0: 2.199  loss_mask_0: 0.165  loss_dice_0: 0.3133  loss_ce_1: 1.953  loss_mask_1: 0.1645  loss_dice_1: 0.3012  loss_ce_2: 1.975  loss_mask_2: 0.1608  loss_dice_2: 0.3163  loss_ce_3: 1.972  loss_mask_3: 0.1564  loss_dice_3: 0.3104  loss_ce_4: 2.009  loss_mask_4: 0.1745  loss_dice_4: 0.3071  time: 0.4450  data_time: 0.0689  lr: 4.0441e-06  max_mem: 5401M
[01/28 11:41:32] detectron2 INFO: Rank of current process: 0. World size: 1
[01/28 11:41:32] detectron2 INFO: Environment info:
----------------------  ------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]
numpy                   1.20.3
detectron2              0.6 @/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 9.3
CUDA compiler           CUDA 11.4
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.1+cu102 @/usr/local/lib/python3.8/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   GRID RTX8000-8Q (arch=7.5)
Driver version          470.63.01
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.1+cu102 @/usr/local/lib/python3.8/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.4
----------------------  ------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/28 11:41:32] detectron2 INFO: Command line arguments: Namespace(config_file='', dist_url='tcp://127.0.0.1:54076', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/28 11:41:32] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m  [39m-[38;5;15m [39mffi_train_stuffonly
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mabsolute
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39mmask_former_semantic
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mbitmask
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m256
[38;5;15m  [39m-[38;5;15m [39m307
[38;5;15m  [39m-[38;5;15m [39m358
[38;5;15m  [39m-[38;5;15m [39m409
[38;5;15m  [39m-[38;5;15m [39m460
[38;5;15m  [39m-[38;5;15m [39m512
[38;5;15m  [39m-[38;5;15m [39m563
[38;5;15m  [39m-[38;5;15m [39m614
[38;5;15m  [39m-[38;5;15m [39m665
[38;5;15m  [39m-[38;5;15m [39m716
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m819
[38;5;15m  [39m-[38;5;15m [39m870
[38;5;15m  [39m-[38;5;15m [39m921
[38;5;15m  [39m-[38;5;15m [39m972
[38;5;15m  [39m-[38;5;15m [39m1024
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m      [39m-[38;5;15m [39m64
[38;5;15m      [39m-[38;5;15m [39m128
[38;5;15m      [39m-[38;5;15m [39m256
[38;5;15m      [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mD2SwinTransformer
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m6
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m20.0
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m32
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39mres5
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mMaskFormer
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m123.675
[38;5;15m  [39m-[38;5;15m [39m116.28
[38;5;15m  [39m-[38;5;15m [39m103.53
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m58.395
[38;5;15m  [39m-[38;5;15m [39m57.12
[38;5;15m  [39m-[38;5;15m [39m57.375
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39mbasic
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id003[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRes5ROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id003[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m6000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m12000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m18
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39mhard_pixel_mining
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskFormerHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m12
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39mBasePixelDecoder
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m48
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.3
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m96
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m4.0
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m3
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m24
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m224
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m7
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39mmodels/model_final_8657a5.pkl
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m./ffiModel
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.0002
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mfull_model
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupPolyLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m160
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39mADAMW
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0e-06
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m1500
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m3584
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m384
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m640
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m896
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m40
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[01/28 11:41:32] detectron2 INFO: Full config saved to ./ffiModel/config.yaml
[01/28 11:41:32] d2.utils.env INFO: Using a generated random seed 33210241
[01/28 11:41:37] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): BasePixelDecoder(
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_2): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_3): Conv2d(
        384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_4): Conv2d(
        768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (predictor): TransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList()
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (3): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (4): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (5): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (query_embed): Embedding(100, 256)
      (input_proj): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (class_embed): Linear(in_features=256, out_features=13, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 1.0
  )
)
[01/28 11:41:37] mask_former.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerSemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2048, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[512, 512], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7fd9becc1f10>, RandomFlip()]
[01/28 11:41:37] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:41:37] d2.data.build INFO: Using training sampler TrainingSampler
[01/28 11:41:37] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:41:37] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:41:37] fvcore.common.checkpoint INFO: [Checkpointer] Loading from models/model_final_8657a5.pkl ...
[01/28 11:41:37] fvcore.common.checkpoint INFO: Reading a file from 'MaskFormer Model Zoo'
[01/28 11:41:37] mask_former.modeling.heads.mask_former_head WARNING: Weight format of MaskFormerHead have changed! Please upgrade your models. Applying automatic conversion now ...
[01/28 11:41:37] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (151, 256) in the checkpoint but (13, 256) in the model! You might want to double check if this is expected.
[01/28 11:41:37] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/28 11:41:37] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/28 11:41:37] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[01/28 11:41:37] d2.engine.train_loop INFO: Starting training from iteration 0
[01/28 11:41:46] d2.utils.events INFO:  eta: 0:01:03  iter: 19  total_loss: 19  loss_ce: 2.671  loss_mask: 0.1727  loss_dice: 0.367  loss_ce_0: 2.519  loss_mask_0: 0.195  loss_dice_0: 0.356  loss_ce_1: 2.548  loss_mask_1: 0.1859  loss_dice_1: 0.3571  loss_ce_2: 2.675  loss_mask_2: 0.1959  loss_dice_2: 0.3652  loss_ce_3: 2.65  loss_mask_3: 0.1655  loss_dice_3: 0.3638  loss_ce_4: 2.677  loss_mask_4: 0.1785  loss_dice_4: 0.3588  time: 0.4511  data_time: 0.0840  lr: 2.2611e-06  max_mem: 5321M
[01/28 11:41:55] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:41:55] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/28 11:41:55] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:41:55] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:41:55] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:41:55] d2.evaluation.evaluator INFO: Start inference on 6 batches
[01/28 11:41:56] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.098809 (0.098809 s / iter per device, on 1 devices)
[01/28 11:41:56] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.043378 s / iter per device, on 1 devices)
[01/28 11:41:56] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 5.598628017644969, 'fwIoU': 24.697903616203526, 'IoU-Grass': nan, 'IoU-CameraEdge': 0.07785079894382416, 'IoU-Vehicle': 0.0, 'IoU-Person': nan, 'IoU-Bush': 0.0, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 0.0, 'IoU-Large_stone': 44.2343435557024, 'IoU-Forrest': nan, 'IoU-Gravel': 0.47682978651352764, 'IoU-Car': nan, 'mACC': 10.039406489648746, 'pACC': 24.881276311951712, 'ACC-Grass': nan, 'ACC-CameraEdge': 0.07785079894382416, 'ACC-Vehicle': 0.0, 'ACC-Person': nan, 'ACC-Bush': 0.0, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 0.0, 'ACC-Large_stone': 44.30833940079549, 'ACC-Forrest': nan, 'ACC-Gravel': 15.850248738153164, 'ACC-Car': nan})])
[01/28 11:41:56] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 150, in train
    self.after_step()
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 180, in after_step
    h.after_step()
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/hooks.py", line 552, in after_step
    self._do_eval()
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/hooks.py", line 525, in _do_eval
    results = self._func()
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 453, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "trainMaskSemantic.py", line 365, in test
    write_to_csv(results_train, trainName)
  File "trainMaskSemantic.py", line 77, in write_to_csv
    writer_object.writerow(new_data)
  File "/usr/lib/python3.8/csv.py", line 154, in writerow
    return self.writer.writerow(self._dict_to_list(rowdict))
  File "/usr/lib/python3.8/csv.py", line 149, in _dict_to_list
    raise ValueError("dict contains fields not in fieldnames: "
ValueError: dict contains fields not in fieldnames: 'ACC-Car', 'IoU-Car'
[01/28 11:41:56] d2.engine.hooks INFO: Overall training speed: 37 iterations in 0:00:17 (0.4624 s / it)
[01/28 11:41:56] d2.engine.hooks INFO: Total training time: 0:00:17 (0:00:00 on hooks)
[01/28 11:41:56] d2.utils.events INFO:  eta: 0:00:53  iter: 39  total_loss: 15.52  loss_ce: 1.999  loss_mask: 0.1403  loss_dice: 0.3113  loss_ce_0: 2.155  loss_mask_0: 0.142  loss_dice_0: 0.3191  loss_ce_1: 2.085  loss_mask_1: 0.1469  loss_dice_1: 0.313  loss_ce_2: 2.132  loss_mask_2: 0.1456  loss_dice_2: 0.3164  loss_ce_3: 2.067  loss_mask_3: 0.135  loss_dice_3: 0.3167  loss_ce_4: 2.09  loss_mask_4: 0.1405  loss_dice_4: 0.3202  time: 0.4502  data_time: 0.0733  lr: 4.0441e-06  max_mem: 5321M
[01/28 11:42:17] detectron2 INFO: Rank of current process: 0. World size: 1
[01/28 11:42:18] detectron2 INFO: Environment info:
----------------------  ------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]
numpy                   1.20.3
detectron2              0.6 @/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 9.3
CUDA compiler           CUDA 11.4
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.1+cu102 @/usr/local/lib/python3.8/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   GRID RTX8000-8Q (arch=7.5)
Driver version          470.63.01
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.1+cu102 @/usr/local/lib/python3.8/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.4
----------------------  ------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/28 11:42:18] detectron2 INFO: Command line arguments: Namespace(config_file='', dist_url='tcp://127.0.0.1:54076', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/28 11:42:18] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m  [39m-[38;5;15m [39mffi_train_stuffonly
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mabsolute
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39mmask_former_semantic
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mbitmask
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m256
[38;5;15m  [39m-[38;5;15m [39m307
[38;5;15m  [39m-[38;5;15m [39m358
[38;5;15m  [39m-[38;5;15m [39m409
[38;5;15m  [39m-[38;5;15m [39m460
[38;5;15m  [39m-[38;5;15m [39m512
[38;5;15m  [39m-[38;5;15m [39m563
[38;5;15m  [39m-[38;5;15m [39m614
[38;5;15m  [39m-[38;5;15m [39m665
[38;5;15m  [39m-[38;5;15m [39m716
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m819
[38;5;15m  [39m-[38;5;15m [39m870
[38;5;15m  [39m-[38;5;15m [39m921
[38;5;15m  [39m-[38;5;15m [39m972
[38;5;15m  [39m-[38;5;15m [39m1024
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m      [39m-[38;5;15m [39m64
[38;5;15m      [39m-[38;5;15m [39m128
[38;5;15m      [39m-[38;5;15m [39m256
[38;5;15m      [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mD2SwinTransformer
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m6
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m20.0
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m32
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39mres5
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mMaskFormer
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m123.675
[38;5;15m  [39m-[38;5;15m [39m116.28
[38;5;15m  [39m-[38;5;15m [39m103.53
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m58.395
[38;5;15m  [39m-[38;5;15m [39m57.12
[38;5;15m  [39m-[38;5;15m [39m57.375
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39mbasic
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id003[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRes5ROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id003[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m6000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m12000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m18
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39mhard_pixel_mining
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskFormerHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m12
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39mBasePixelDecoder
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m48
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.3
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m96
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m4.0
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m3
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m24
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m224
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m7
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39mmodels/model_final_8657a5.pkl
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m./ffiModel
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.0002
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mfull_model
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupPolyLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m160
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39mADAMW
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0e-06
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m1500
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m3584
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m384
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m640
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m896
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m40
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[01/28 11:42:18] detectron2 INFO: Full config saved to ./ffiModel/config.yaml
[01/28 11:42:18] d2.utils.env INFO: Using a generated random seed 18671146
[01/28 11:42:22] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): BasePixelDecoder(
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_2): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_3): Conv2d(
        384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_4): Conv2d(
        768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (predictor): TransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList()
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (3): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (4): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (5): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (query_embed): Embedding(100, 256)
      (input_proj): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (class_embed): Linear(in_features=256, out_features=13, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 1.0
  )
)
[01/28 11:42:22] mask_former.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerSemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2048, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[512, 512], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7fb2929ef310>, RandomFlip()]
[01/28 11:42:22] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:42:22] d2.data.build INFO: Using training sampler TrainingSampler
[01/28 11:42:22] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:42:22] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:42:22] fvcore.common.checkpoint INFO: [Checkpointer] Loading from models/model_final_8657a5.pkl ...
[01/28 11:42:22] fvcore.common.checkpoint INFO: Reading a file from 'MaskFormer Model Zoo'
[01/28 11:42:22] mask_former.modeling.heads.mask_former_head WARNING: Weight format of MaskFormerHead have changed! Please upgrade your models. Applying automatic conversion now ...
[01/28 11:42:22] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (151, 256) in the checkpoint but (13, 256) in the model! You might want to double check if this is expected.
[01/28 11:42:22] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/28 11:42:22] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/28 11:42:22] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[01/28 11:42:22] d2.engine.train_loop INFO: Starting training from iteration 0
[01/28 11:42:32] d2.utils.events INFO:  eta: 0:01:04  iter: 19  total_loss: 16.66  loss_ce: 2.135  loss_mask: 0.1808  loss_dice: 0.3639  loss_ce_0: 2.117  loss_mask_0: 0.1898  loss_dice_0: 0.3404  loss_ce_1: 2.289  loss_mask_1: 0.1878  loss_dice_1: 0.3566  loss_ce_2: 2.256  loss_mask_2: 0.1972  loss_dice_2: 0.3435  loss_ce_3: 2.25  loss_mask_3: 0.1736  loss_dice_3: 0.3526  loss_ce_4: 2.303  loss_mask_4: 0.1789  loss_dice_4: 0.3609  time: 0.4635  data_time: 0.0797  lr: 2.2611e-06  max_mem: 5401M
[01/28 11:42:41] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:42:41] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/28 11:42:41] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:42:41] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:42:41] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:42:41] d2.evaluation.evaluator INFO: Start inference on 6 batches
[01/28 11:42:41] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.099463 (0.099463 s / iter per device, on 1 devices)
[01/28 11:42:41] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.044465 s / iter per device, on 1 devices)
[01/28 11:42:41] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 0.0, 'fwIoU': 0.0, 'IoU-Grass': nan, 'IoU-CameraEdge': 0.0, 'IoU-Vehicle': 0.0, 'IoU-Person': nan, 'IoU-Bush': 0.0, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 0.0, 'IoU-Large_stone': 0.0, 'IoU-Forrest': nan, 'IoU-Gravel': 0.0, 'mACC': 0.0, 'pACC': 0.0, 'ACC-Grass': nan, 'ACC-CameraEdge': 0.0, 'ACC-Vehicle': 0.0, 'ACC-Person': nan, 'ACC-Bush': 0.0, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 0.0, 'ACC-Large_stone': 0.0, 'ACC-Forrest': nan, 'ACC-Gravel': 0.0})])
[01/28 11:42:41] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:42:41] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/28 11:42:41] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:42:41] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:42:41] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:42:41] d2.evaluation.evaluator INFO: Start inference on 6 batches
[01/28 11:42:42] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.097660 (0.097660 s / iter per device, on 1 devices)
[01/28 11:42:42] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.044462 s / iter per device, on 1 devices)
[01/28 11:42:42] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 0.0, 'fwIoU': 0.0, 'IoU-Grass': nan, 'IoU-CameraEdge': 0.0, 'IoU-Vehicle': 0.0, 'IoU-Person': nan, 'IoU-Bush': 0.0, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 0.0, 'IoU-Large_stone': 0.0, 'IoU-Forrest': nan, 'IoU-Gravel': 0.0, 'mACC': 0.0, 'pACC': 0.0, 'ACC-Grass': nan, 'ACC-CameraEdge': 0.0, 'ACC-Vehicle': 0.0, 'ACC-Person': nan, 'ACC-Bush': 0.0, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 0.0, 'ACC-Large_stone': 0.0, 'ACC-Forrest': nan, 'ACC-Gravel': 0.0})])
[01/28 11:42:42] d2.utils.events INFO:  eta: 0:00:55  iter: 39  total_loss: 13.64  loss_ce: 1.678  loss_mask: 0.1581  loss_dice: 0.3268  loss_ce_0: 1.867  loss_mask_0: 0.1612  loss_dice_0: 0.3139  loss_ce_1: 1.949  loss_mask_1: 0.1602  loss_dice_1: 0.3211  loss_ce_2: 1.858  loss_mask_2: 0.1597  loss_dice_2: 0.3189  loss_ce_3: 1.818  loss_mask_3: 0.1506  loss_dice_3: 0.3297  loss_ce_4: 1.802  loss_mask_4: 0.1608  loss_dice_4: 0.3281  time: 0.4577  data_time: 0.0706  lr: 4.0441e-06  max_mem: 5401M
[01/28 11:42:51] d2.utils.events INFO:  eta: 0:00:45  iter: 59  total_loss: 10.86  loss_ce: 1.3  loss_mask: 0.1107  loss_dice: 0.2806  loss_ce_0: 1.537  loss_mask_0: 0.1292  loss_dice_0: 0.2727  loss_ce_1: 1.506  loss_mask_1: 0.125  loss_dice_1: 0.2651  loss_ce_2: 1.41  loss_mask_2: 0.1201  loss_dice_2: 0.2693  loss_ce_3: 1.33  loss_mask_3: 0.1136  loss_dice_3: 0.271  loss_ce_4: 1.32  loss_mask_4: 0.1186  loss_dice_4: 0.2692  time: 0.4545  data_time: 0.0749  lr: 5.1998e-06  max_mem: 5434M
[01/28 11:43:00] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:43:00] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/28 11:43:00] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:43:00] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:43:00] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:43:00] d2.evaluation.evaluator INFO: Start inference on 6 batches
[01/28 11:43:01] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.099616 (0.099616 s / iter per device, on 1 devices)
[01/28 11:43:01] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.044633 s / iter per device, on 1 devices)
[01/28 11:43:01] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 55.3617743996332, 'fwIoU': 87.06231712690676, 'IoU-Grass': nan, 'IoU-CameraEdge': 83.37143691887083, 'IoU-Vehicle': 77.35586369505417, 'IoU-Person': nan, 'IoU-Bush': 0.0, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 76.0002623352207, 'IoU-Large_stone': 95.44308344865347, 'IoU-Forrest': nan, 'IoU-Gravel': 0.0, 'mACC': 59.65595482979161, 'pACC': 93.00700779385895, 'ACC-Grass': nan, 'ACC-CameraEdge': 91.08413725095855, 'ACC-Vehicle': 78.5795752640343, 'ACC-Person': nan, 'ACC-Bush': 0.0, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 88.83505689411535, 'ACC-Large_stone': 99.43695956964143, 'ACC-Forrest': nan, 'ACC-Gravel': 0.0})])
[01/28 11:43:01] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:43:01] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/28 11:43:01] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:43:01] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:43:01] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:43:01] d2.evaluation.evaluator INFO: Start inference on 6 batches
[01/28 11:43:01] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.104604 (0.104604 s / iter per device, on 1 devices)
[01/28 11:43:01] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.044672 s / iter per device, on 1 devices)
[01/28 11:43:01] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 55.3617743996332, 'fwIoU': 87.06231712690676, 'IoU-Grass': nan, 'IoU-CameraEdge': 83.37143691887083, 'IoU-Vehicle': 77.35586369505417, 'IoU-Person': nan, 'IoU-Bush': 0.0, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 76.0002623352207, 'IoU-Large_stone': 95.44308344865347, 'IoU-Forrest': nan, 'IoU-Gravel': 0.0, 'mACC': 59.65595482979161, 'pACC': 93.00700779385895, 'ACC-Grass': nan, 'ACC-CameraEdge': 91.08413725095855, 'ACC-Vehicle': 78.5795752640343, 'ACC-Person': nan, 'ACC-Bush': 0.0, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 88.83505689411535, 'ACC-Large_stone': 99.43695956964143, 'ACC-Forrest': nan, 'ACC-Gravel': 0.0})])
[01/28 11:43:01] d2.utils.events INFO:  eta: 0:00:36  iter: 79  total_loss: 8.788  loss_ce: 1.084  loss_mask: 0.1012  loss_dice: 0.1982  loss_ce_0: 1.266  loss_mask_0: 0.1032  loss_dice_0: 0.1989  loss_ce_1: 1.241  loss_mask_1: 0.1105  loss_dice_1: 0.1976  loss_ce_2: 1.212  loss_mask_2: 0.103  loss_dice_2: 0.2075  loss_ce_3: 1.144  loss_mask_3: 0.09982  loss_dice_3: 0.2061  loss_ce_4: 1.088  loss_mask_4: 0.1015  loss_dice_4: 0.1969  time: 0.4561  data_time: 0.0785  lr: 5.7082e-06  max_mem: 5434M
[01/28 11:43:10] d2.utils.events INFO:  eta: 0:00:27  iter: 99  total_loss: 7.178  loss_ce: 0.8331  loss_mask: 0.08358  loss_dice: 0.1692  loss_ce_0: 1.072  loss_mask_0: 0.09878  loss_dice_0: 0.1749  loss_ce_1: 1.015  loss_mask_1: 0.09589  loss_dice_1: 0.1551  loss_ce_2: 0.9299  loss_mask_2: 0.1  loss_dice_2: 0.1646  loss_ce_3: 0.8812  loss_mask_3: 0.09618  loss_dice_3: 0.1646  loss_ce_4: 0.8527  loss_mask_4: 0.08884  loss_dice_4: 0.1623  time: 0.4541  data_time: 0.0686  lr: 5.542e-06  max_mem: 5434M
[01/28 11:43:11] d2.engine.hooks INFO: Overall training speed: 99 iterations in 0:00:45 (0.4577 s / it)
[01/28 11:43:11] d2.engine.hooks INFO: Total training time: 0:00:47 (0:00:02 on hooks)
[01/28 11:43:11] d2.utils.events INFO:  eta: 0:00:26  iter: 101  total_loss: 7.008  loss_ce: 0.819  loss_mask: 0.0836  loss_dice: 0.1683  loss_ce_0: 1.044  loss_mask_0: 0.09631  loss_dice_0: 0.1672  loss_ce_1: 0.98  loss_mask_1: 0.09758  loss_dice_1: 0.153  loss_ce_2: 0.8862  loss_mask_2: 0.09206  loss_dice_2: 0.1646  loss_ce_3: 0.8538  loss_mask_3: 0.09338  loss_dice_3: 0.1617  loss_ce_4: 0.8348  loss_mask_4: 0.08833  loss_dice_4: 0.1592  time: 0.4540  data_time: 0.0681  lr: 5.5153e-06  max_mem: 5434M
[01/28 11:43:13] detectron2 INFO: Rank of current process: 0. World size: 1
[01/28 11:43:14] detectron2 INFO: Environment info:
----------------------  ------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]
numpy                   1.20.3
detectron2              0.6 @/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 9.3
CUDA compiler           CUDA 11.4
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.1+cu102 @/usr/local/lib/python3.8/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   GRID RTX8000-8Q (arch=7.5)
Driver version          470.63.01
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.1+cu102 @/usr/local/lib/python3.8/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.4
----------------------  ------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/28 11:43:14] detectron2 INFO: Command line arguments: Namespace(config_file='', dist_url='tcp://127.0.0.1:54076', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/28 11:43:14] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m  [39m-[38;5;15m [39mffi_train_stuffonly
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mabsolute
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39mmask_former_semantic
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mbitmask
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m256
[38;5;15m  [39m-[38;5;15m [39m307
[38;5;15m  [39m-[38;5;15m [39m358
[38;5;15m  [39m-[38;5;15m [39m409
[38;5;15m  [39m-[38;5;15m [39m460
[38;5;15m  [39m-[38;5;15m [39m512
[38;5;15m  [39m-[38;5;15m [39m563
[38;5;15m  [39m-[38;5;15m [39m614
[38;5;15m  [39m-[38;5;15m [39m665
[38;5;15m  [39m-[38;5;15m [39m716
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m819
[38;5;15m  [39m-[38;5;15m [39m870
[38;5;15m  [39m-[38;5;15m [39m921
[38;5;15m  [39m-[38;5;15m [39m972
[38;5;15m  [39m-[38;5;15m [39m1024
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m      [39m-[38;5;15m [39m64
[38;5;15m      [39m-[38;5;15m [39m128
[38;5;15m      [39m-[38;5;15m [39m256
[38;5;15m      [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mD2SwinTransformer
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m6
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m20.0
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m32
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39mres5
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mMaskFormer
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m123.675
[38;5;15m  [39m-[38;5;15m [39m116.28
[38;5;15m  [39m-[38;5;15m [39m103.53
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m58.395
[38;5;15m  [39m-[38;5;15m [39m57.12
[38;5;15m  [39m-[38;5;15m [39m57.375
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39mbasic
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id003[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRes5ROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id003[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m6000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m12000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m18
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39mhard_pixel_mining
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskFormerHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m12
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39mBasePixelDecoder
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m48
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.3
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m96
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m4.0
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m3
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m24
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m224
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m7
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39mmodels/model_final_8657a5.pkl
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m./ffiModel
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.0002
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mfull_model
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupPolyLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m1600
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39mADAMW
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0e-06
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m1500
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m3584
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m384
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m640
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m896
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m400
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[01/28 11:43:14] detectron2 INFO: Full config saved to ./ffiModel/config.yaml
[01/28 11:43:14] d2.utils.env INFO: Using a generated random seed 14865179
[01/28 11:43:18] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): BasePixelDecoder(
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_2): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_3): Conv2d(
        384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_4): Conv2d(
        768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (predictor): TransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList()
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (3): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (4): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (5): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (query_embed): Embedding(100, 256)
      (input_proj): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (class_embed): Linear(in_features=256, out_features=13, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 1.0
  )
)
[01/28 11:43:18] mask_former.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerSemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2048, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[512, 512], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f2633cd10d0>, RandomFlip()]
[01/28 11:43:18] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:43:18] d2.data.build INFO: Using training sampler TrainingSampler
[01/28 11:43:18] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:43:18] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:43:18] fvcore.common.checkpoint INFO: [Checkpointer] Loading from models/model_final_8657a5.pkl ...
[01/28 11:43:18] fvcore.common.checkpoint INFO: Reading a file from 'MaskFormer Model Zoo'
[01/28 11:43:18] mask_former.modeling.heads.mask_former_head WARNING: Weight format of MaskFormerHead have changed! Please upgrade your models. Applying automatic conversion now ...
[01/28 11:43:18] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (151, 256) in the checkpoint but (13, 256) in the model! You might want to double check if this is expected.
[01/28 11:43:18] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/28 11:43:18] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/28 11:43:18] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[01/28 11:43:18] d2.engine.train_loop INFO: Starting training from iteration 0
[01/28 11:43:28] d2.utils.events INFO:  eta: 0:11:43  iter: 19  total_loss: 17.71  loss_ce: 2.484  loss_mask: 0.182  loss_dice: 0.3419  loss_ce_0: 2.403  loss_mask_0: 0.1907  loss_dice_0: 0.3259  loss_ce_1: 2.346  loss_mask_1: 0.1781  loss_dice_1: 0.3371  loss_ce_2: 2.447  loss_mask_2: 0.2005  loss_dice_2: 0.3469  loss_ce_3: 2.422  loss_mask_3: 0.1747  loss_dice_3: 0.3401  loss_ce_4: 2.487  loss_mask_4: 0.1822  loss_dice_4: 0.3434  time: 0.4481  data_time: 0.0764  lr: 2.5064e-06  max_mem: 5436M
[01/28 11:43:37] d2.utils.events INFO:  eta: 0:11:36  iter: 39  total_loss: 14.23  loss_ce: 1.762  loss_mask: 0.1555  loss_dice: 0.3152  loss_ce_0: 2.027  loss_mask_0: 0.1561  loss_dice_0: 0.3075  loss_ce_1: 1.915  loss_mask_1: 0.1476  loss_dice_1: 0.3219  loss_ce_2: 1.926  loss_mask_2: 0.17  loss_dice_2: 0.3151  loss_ce_3: 1.819  loss_mask_3: 0.1497  loss_dice_3: 0.3189  loss_ce_4: 1.813  loss_mask_4: 0.1569  loss_dice_4: 0.3213  time: 0.4486  data_time: 0.0750  lr: 5.086e-06  max_mem: 5436M
[01/28 11:43:46] d2.utils.events INFO:  eta: 0:11:31  iter: 59  total_loss: 10.66  loss_ce: 1.301  loss_mask: 0.123  loss_dice: 0.2845  loss_ce_0: 1.521  loss_mask_0: 0.1198  loss_dice_0: 0.2856  loss_ce_1: 1.412  loss_mask_1: 0.1297  loss_dice_1: 0.2867  loss_ce_2: 1.374  loss_mask_2: 0.1286  loss_dice_2: 0.2832  loss_ce_3: 1.332  loss_mask_3: 0.1237  loss_dice_3: 0.2796  loss_ce_4: 1.318  loss_mask_4: 0.1255  loss_dice_4: 0.2866  time: 0.4514  data_time: 0.0770  lr: 7.6053e-06  max_mem: 5436M
[01/28 11:43:55] d2.utils.events INFO:  eta: 0:11:22  iter: 79  total_loss: 8.313  loss_ce: 1.038  loss_mask: 0.09311  loss_dice: 0.2034  loss_ce_0: 1.213  loss_mask_0: 0.1008  loss_dice_0: 0.2054  loss_ce_1: 1.109  loss_mask_1: 0.1026  loss_dice_1: 0.1967  loss_ce_2: 1.092  loss_mask_2: 0.09879  loss_dice_2: 0.2017  loss_ce_3: 1.073  loss_mask_3: 0.09694  loss_dice_3: 0.2019  loss_ce_4: 1.048  loss_mask_4: 0.09654  loss_dice_4: 0.1961  time: 0.4511  data_time: 0.0770  lr: 1.0064e-05  max_mem: 5436M
[01/28 11:44:04] d2.utils.events INFO:  eta: 0:11:14  iter: 99  total_loss: 6.456  loss_ce: 0.7486  loss_mask: 0.09624  loss_dice: 0.1677  loss_ce_0: 0.9901  loss_mask_0: 0.09524  loss_dice_0: 0.1789  loss_ce_1: 0.8983  loss_mask_1: 0.0957  loss_dice_1: 0.1652  loss_ce_2: 0.8276  loss_mask_2: 0.1039  loss_dice_2: 0.1633  loss_ce_3: 0.7861  loss_mask_3: 0.1019  loss_dice_3: 0.167  loss_ce_4: 0.7804  loss_mask_4: 0.09504  loss_dice_4: 0.165  time: 0.4511  data_time: 0.0756  lr: 1.2463e-05  max_mem: 5436M
[01/28 11:44:13] d2.utils.events INFO:  eta: 0:11:04  iter: 119  total_loss: 5.029  loss_ce: 0.4137  loss_mask: 0.09657  loss_dice: 0.1693  loss_ce_0: 0.7453  loss_mask_0: 0.09448  loss_dice_0: 0.1687  loss_ce_1: 0.6526  loss_mask_1: 0.1023  loss_dice_1: 0.159  loss_ce_2: 0.5507  loss_mask_2: 0.1013  loss_dice_2: 0.165  loss_ce_3: 0.4583  loss_mask_3: 0.1021  loss_dice_3: 0.1723  loss_ce_4: 0.4321  loss_mask_4: 0.09974  loss_dice_4: 0.1695  time: 0.4504  data_time: 0.0696  lr: 1.4801e-05  max_mem: 5436M
[01/28 11:44:22] d2.utils.events INFO:  eta: 0:10:54  iter: 139  total_loss: 3.199  loss_ce: 0.1858  loss_mask: 0.0925  loss_dice: 0.1672  loss_ce_0: 0.5029  loss_mask_0: 0.08716  loss_dice_0: 0.157  loss_ce_1: 0.3705  loss_mask_1: 0.09644  loss_dice_1: 0.1561  loss_ce_2: 0.2734  loss_mask_2: 0.09319  loss_dice_2: 0.1574  loss_ce_3: 0.2193  loss_mask_3: 0.08611  loss_dice_3: 0.1636  loss_ce_4: 0.1933  loss_mask_4: 0.08965  loss_dice_4: 0.1659  time: 0.4498  data_time: 0.0689  lr: 1.7078e-05  max_mem: 5436M
[01/28 11:44:31] d2.utils.events INFO:  eta: 0:10:44  iter: 159  total_loss: 2.22  loss_ce: 0.07379  loss_mask: 0.0836  loss_dice: 0.1459  loss_ce_0: 0.2915  loss_mask_0: 0.08811  loss_dice_0: 0.1406  loss_ce_1: 0.1746  loss_mask_1: 0.08695  loss_dice_1: 0.1382  loss_ce_2: 0.1125  loss_mask_2: 0.08477  loss_dice_2: 0.145  loss_ce_3: 0.08443  loss_mask_3: 0.08397  loss_dice_3: 0.1435  loss_ce_4: 0.0809  loss_mask_4: 0.08352  loss_dice_4: 0.1454  time: 0.4493  data_time: 0.0689  lr: 1.9294e-05  max_mem: 5436M
[01/28 11:44:40] d2.utils.events INFO:  eta: 0:10:35  iter: 179  total_loss: 1.691  loss_ce: 0.02894  loss_mask: 0.07599  loss_dice: 0.1323  loss_ce_0: 0.1712  loss_mask_0: 0.07803  loss_dice_0: 0.1377  loss_ce_1: 0.08976  loss_mask_1: 0.07914  loss_dice_1: 0.1364  loss_ce_2: 0.0525  loss_mask_2: 0.07593  loss_dice_2: 0.1347  loss_ce_3: 0.03946  loss_mask_3: 0.07561  loss_dice_3: 0.1339  loss_ce_4: 0.03364  loss_mask_4: 0.0787  loss_dice_4: 0.1294  time: 0.4493  data_time: 0.0730  lr: 2.145e-05  max_mem: 5436M
[01/28 11:44:49] d2.utils.events INFO:  eta: 0:10:27  iter: 199  total_loss: 1.417  loss_ce: 0.01755  loss_mask: 0.07187  loss_dice: 0.1254  loss_ce_0: 0.09313  loss_mask_0: 0.06751  loss_dice_0: 0.1248  loss_ce_1: 0.04579  loss_mask_1: 0.0702  loss_dice_1: 0.1228  loss_ce_2: 0.02764  loss_mask_2: 0.06796  loss_dice_2: 0.1261  loss_ce_3: 0.02164  loss_mask_3: 0.06867  loss_dice_3: 0.1234  loss_ce_4: 0.0188  loss_mask_4: 0.07113  loss_dice_4: 0.1229  time: 0.4497  data_time: 0.0753  lr: 2.3544e-05  max_mem: 5436M
[01/28 11:44:58] d2.utils.events INFO:  eta: 0:10:19  iter: 219  total_loss: 1.248  loss_ce: 0.01603  loss_mask: 0.06786  loss_dice: 0.1147  loss_ce_0: 0.05861  loss_mask_0: 0.06676  loss_dice_0: 0.1137  loss_ce_1: 0.0345  loss_mask_1: 0.06783  loss_dice_1: 0.1111  loss_ce_2: 0.02326  loss_mask_2: 0.06835  loss_dice_2: 0.114  loss_ce_3: 0.01822  loss_mask_3: 0.06871  loss_dice_3: 0.1131  loss_ce_4: 0.01727  loss_mask_4: 0.06814  loss_dice_4: 0.1136  time: 0.4501  data_time: 0.0762  lr: 2.5577e-05  max_mem: 5436M
[01/28 11:45:07] d2.utils.events INFO:  eta: 0:10:10  iter: 239  total_loss: 1.335  loss_ce: 0.01801  loss_mask: 0.06336  loss_dice: 0.1234  loss_ce_0: 0.04787  loss_mask_0: 0.06348  loss_dice_0: 0.124  loss_ce_1: 0.02904  loss_mask_1: 0.06448  loss_dice_1: 0.1227  loss_ce_2: 0.01985  loss_mask_2: 0.06483  loss_dice_2: 0.1247  loss_ce_3: 0.01705  loss_mask_3: 0.06209  loss_dice_3: 0.1212  loss_ce_4: 0.01691  loss_mask_4: 0.06363  loss_dice_4: 0.1224  time: 0.4504  data_time: 0.0750  lr: 2.7549e-05  max_mem: 5436M
[01/28 11:45:16] d2.utils.events INFO:  eta: 0:10:02  iter: 259  total_loss: 1.149  loss_ce: 0.008544  loss_mask: 0.06296  loss_dice: 0.1044  loss_ce_0: 0.03199  loss_mask_0: 0.06395  loss_dice_0: 0.105  loss_ce_1: 0.01649  loss_mask_1: 0.06277  loss_dice_1: 0.1021  loss_ce_2: 0.01242  loss_mask_2: 0.06371  loss_dice_2: 0.1049  loss_ce_3: 0.01073  loss_mask_3: 0.06455  loss_dice_3: 0.1039  loss_ce_4: 0.009283  loss_mask_4: 0.06361  loss_dice_4: 0.1032  time: 0.4508  data_time: 0.0807  lr: 2.9459e-05  max_mem: 5436M
[01/28 11:45:25] d2.utils.events INFO:  eta: 0:09:54  iter: 279  total_loss: 1.07  loss_ce: 0.007505  loss_mask: 0.0584  loss_dice: 0.1029  loss_ce_0: 0.02338  loss_mask_0: 0.06002  loss_dice_0: 0.1057  loss_ce_1: 0.01447  loss_mask_1: 0.06258  loss_dice_1: 0.1034  loss_ce_2: 0.01032  loss_mask_2: 0.06085  loss_dice_2: 0.1023  loss_ce_3: 0.008908  loss_mask_3: 0.05781  loss_dice_3: 0.1032  loss_ce_4: 0.007973  loss_mask_4: 0.05848  loss_dice_4: 0.1024  time: 0.4514  data_time: 0.0820  lr: 3.1308e-05  max_mem: 5436M
[01/28 11:45:34] d2.utils.events INFO:  eta: 0:09:44  iter: 299  total_loss: 1.075  loss_ce: 0.007825  loss_mask: 0.06195  loss_dice: 0.09906  loss_ce_0: 0.0206  loss_mask_0: 0.05966  loss_dice_0: 0.101  loss_ce_1: 0.01268  loss_mask_1: 0.0615  loss_dice_1: 0.09874  loss_ce_2: 0.01103  loss_mask_2: 0.06134  loss_dice_2: 0.09887  loss_ce_3: 0.00884  loss_mask_3: 0.06196  loss_dice_3: 0.0998  loss_ce_4: 0.008368  loss_mask_4: 0.06161  loss_dice_4: 0.09869  time: 0.4510  data_time: 0.0751  lr: 3.3094e-05  max_mem: 5436M
[01/28 11:45:43] d2.utils.events INFO:  eta: 0:09:36  iter: 319  total_loss: 1.127  loss_ce: 0.007782  loss_mask: 0.06958  loss_dice: 0.1091  loss_ce_0: 0.01664  loss_mask_0: 0.06554  loss_dice_0: 0.1107  loss_ce_1: 0.01194  loss_mask_1: 0.06433  loss_dice_1: 0.1087  loss_ce_2: 0.009942  loss_mask_2: 0.06539  loss_dice_2: 0.1089  loss_ce_3: 0.008743  loss_mask_3: 0.0657  loss_dice_3: 0.1107  loss_ce_4: 0.008047  loss_mask_4: 0.06764  loss_dice_4: 0.1093  time: 0.4510  data_time: 0.0743  lr: 3.4819e-05  max_mem: 5436M
[01/28 11:45:52] d2.utils.events INFO:  eta: 0:09:26  iter: 339  total_loss: 1.019  loss_ce: 0.005907  loss_mask: 0.05717  loss_dice: 0.1006  loss_ce_0: 0.01461  loss_mask_0: 0.05866  loss_dice_0: 0.1012  loss_ce_1: 0.01005  loss_mask_1: 0.05785  loss_dice_1: 0.0989  loss_ce_2: 0.007959  loss_mask_2: 0.05782  loss_dice_2: 0.09958  loss_ce_3: 0.007051  loss_mask_3: 0.05757  loss_dice_3: 0.09963  loss_ce_4: 0.006886  loss_mask_4: 0.05807  loss_dice_4: 0.1009  time: 0.4508  data_time: 0.0700  lr: 3.6482e-05  max_mem: 5436M
[01/28 11:46:01] d2.utils.events INFO:  eta: 0:09:17  iter: 359  total_loss: 0.9747  loss_ce: 0.002984  loss_mask: 0.05563  loss_dice: 0.09361  loss_ce_0: 0.01171  loss_mask_0: 0.05578  loss_dice_0: 0.09344  loss_ce_1: 0.00682  loss_mask_1: 0.05468  loss_dice_1: 0.09565  loss_ce_2: 0.005239  loss_mask_2: 0.05532  loss_dice_2: 0.09565  loss_ce_3: 0.00392  loss_mask_3: 0.05429  loss_dice_3: 0.09487  loss_ce_4: 0.003537  loss_mask_4: 0.05514  loss_dice_4: 0.09448  time: 0.4508  data_time: 0.0729  lr: 3.8082e-05  max_mem: 5436M
[01/28 11:46:11] d2.utils.events INFO:  eta: 0:09:08  iter: 379  total_loss: 1.001  loss_ce: 0.004746  loss_mask: 0.05941  loss_dice: 0.1007  loss_ce_0: 0.0128  loss_mask_0: 0.05734  loss_dice_0: 0.1007  loss_ce_1: 0.008562  loss_mask_1: 0.05743  loss_dice_1: 0.1007  loss_ce_2: 0.005442  loss_mask_2: 0.05771  loss_dice_2: 0.09937  loss_ce_3: 0.005352  loss_mask_3: 0.05631  loss_dice_3: 0.09971  loss_ce_4: 0.004689  loss_mask_4: 0.05796  loss_dice_4: 0.1005  time: 0.4507  data_time: 0.0728  lr: 3.962e-05  max_mem: 5436M
[01/28 11:46:19] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:46:19] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/28 11:46:19] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:46:19] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:46:19] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:46:19] d2.evaluation.evaluator INFO: Start inference on 6 batches
[01/28 11:46:20] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.100535 (0.100535 s / iter per device, on 1 devices)
[01/28 11:46:20] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.044091 s / iter per device, on 1 devices)
[01/28 11:46:20] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 93.26432147332147, 'fwIoU': 96.63821531836618, 'IoU-Grass': nan, 'IoU-CameraEdge': 94.54278123797083, 'IoU-Vehicle': 89.69592176125288, 'IoU-Person': nan, 'IoU-Bush': 94.27906203226343, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 95.46910300652945, 'IoU-Large_stone': 98.46623274840387, 'IoU-Forrest': nan, 'IoU-Gravel': 87.13282805350843, 'mACC': 96.11349205404966, 'pACC': 98.27794013352367, 'ACC-Grass': nan, 'ACC-CameraEdge': 97.19737123802233, 'ACC-Vehicle': 92.88875202445311, 'ACC-Person': nan, 'ACC-Bush': 98.55702364394993, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 98.26212944720845, 'ACC-Large_stone': 99.18778243785616, 'ACC-Forrest': nan, 'ACC-Gravel': 90.58789353280801})])
[01/28 11:46:20] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:46:20] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/28 11:46:20] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:46:20] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:46:20] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:46:20] d2.evaluation.evaluator INFO: Start inference on 6 batches
[01/28 11:46:21] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.105420 (0.105420 s / iter per device, on 1 devices)
[01/28 11:46:21] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.043445 s / iter per device, on 1 devices)
[01/28 11:46:21] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 93.26432147332147, 'fwIoU': 96.63821531836618, 'IoU-Grass': nan, 'IoU-CameraEdge': 94.54278123797083, 'IoU-Vehicle': 89.69592176125288, 'IoU-Person': nan, 'IoU-Bush': 94.27906203226343, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 95.46910300652945, 'IoU-Large_stone': 98.46623274840387, 'IoU-Forrest': nan, 'IoU-Gravel': 87.13282805350843, 'mACC': 96.11349205404966, 'pACC': 98.27794013352367, 'ACC-Grass': nan, 'ACC-CameraEdge': 97.19737123802233, 'ACC-Vehicle': 92.88875202445311, 'ACC-Person': nan, 'ACC-Bush': 98.55702364394993, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 98.26212944720845, 'ACC-Large_stone': 99.18778243785616, 'ACC-Forrest': nan, 'ACC-Gravel': 90.58789353280801})])
[01/28 11:46:21] d2.utils.events INFO:  eta: 0:08:59  iter: 399  total_loss: 0.9897  loss_ce: 0.003261  loss_mask: 0.05512  loss_dice: 0.09292  loss_ce_0: 0.009849  loss_mask_0: 0.05268  loss_dice_0: 0.09399  loss_ce_1: 0.007276  loss_mask_1: 0.05451  loss_dice_1: 0.09147  loss_ce_2: 0.005391  loss_mask_2: 0.05699  loss_dice_2: 0.08976  loss_ce_3: 0.004466  loss_mask_3: 0.05567  loss_dice_3: 0.08967  loss_ce_4: 0.004048  loss_mask_4: 0.05477  loss_dice_4: 0.09304  time: 0.4504  data_time: 0.0703  lr: 4.1095e-05  max_mem: 5436M
[01/28 11:46:29] d2.utils.events INFO:  eta: 0:08:49  iter: 419  total_loss: 0.9289  loss_ce: 0.003086  loss_mask: 0.05267  loss_dice: 0.09079  loss_ce_0: 0.008663  loss_mask_0: 0.05189  loss_dice_0: 0.09162  loss_ce_1: 0.006104  loss_mask_1: 0.05236  loss_dice_1: 0.0908  loss_ce_2: 0.005262  loss_mask_2: 0.0528  loss_dice_2: 0.09006  loss_ce_3: 0.004385  loss_mask_3: 0.05267  loss_dice_3: 0.09002  loss_ce_4: 0.003874  loss_mask_4: 0.05207  loss_dice_4: 0.09075  time: 0.4501  data_time: 0.0697  lr: 4.2508e-05  max_mem: 5436M
[01/28 11:46:38] d2.utils.events INFO:  eta: 0:08:40  iter: 439  total_loss: 0.8838  loss_ce: 0.003552  loss_mask: 0.05257  loss_dice: 0.08992  loss_ce_0: 0.01033  loss_mask_0: 0.05433  loss_dice_0: 0.08683  loss_ce_1: 0.006023  loss_mask_1: 0.0526  loss_dice_1: 0.08907  loss_ce_2: 0.004489  loss_mask_2: 0.05195  loss_dice_2: 0.09003  loss_ce_3: 0.004177  loss_mask_3: 0.05161  loss_dice_3: 0.09045  loss_ce_4: 0.003839  loss_mask_4: 0.0521  loss_dice_4: 0.08981  time: 0.4499  data_time: 0.0718  lr: 4.3858e-05  max_mem: 5436M
[01/28 11:46:47] d2.utils.events INFO:  eta: 0:08:30  iter: 459  total_loss: 0.8766  loss_ce: 0.002038  loss_mask: 0.05057  loss_dice: 0.08721  loss_ce_0: 0.00699  loss_mask_0: 0.04846  loss_dice_0: 0.08769  loss_ce_1: 0.004395  loss_mask_1: 0.04983  loss_dice_1: 0.08652  loss_ce_2: 0.003502  loss_mask_2: 0.04935  loss_dice_2: 0.08767  loss_ce_3: 0.002842  loss_mask_3: 0.05018  loss_dice_3: 0.08721  loss_ce_4: 0.002456  loss_mask_4: 0.0494  loss_dice_4: 0.08718  time: 0.4497  data_time: 0.0728  lr: 4.5144e-05  max_mem: 5436M
[01/28 11:46:56] d2.utils.events INFO:  eta: 0:08:21  iter: 479  total_loss: 0.8434  loss_ce: 0.0016  loss_mask: 0.04827  loss_dice: 0.08654  loss_ce_0: 0.004744  loss_mask_0: 0.04692  loss_dice_0: 0.08575  loss_ce_1: 0.003213  loss_mask_1: 0.04858  loss_dice_1: 0.08362  loss_ce_2: 0.002476  loss_mask_2: 0.04823  loss_dice_2: 0.08321  loss_ce_3: 0.001985  loss_mask_3: 0.0486  loss_dice_3: 0.08439  loss_ce_4: 0.001815  loss_mask_4: 0.04775  loss_dice_4: 0.0852  time: 0.4497  data_time: 0.0714  lr: 4.6367e-05  max_mem: 5436M
[01/28 11:47:05] d2.utils.events INFO:  eta: 0:08:12  iter: 499  total_loss: 0.8063  loss_ce: 0.002503  loss_mask: 0.04589  loss_dice: 0.0801  loss_ce_0: 0.007756  loss_mask_0: 0.04634  loss_dice_0: 0.07974  loss_ce_1: 0.005393  loss_mask_1: 0.04522  loss_dice_1: 0.07857  loss_ce_2: 0.004245  loss_mask_2: 0.04486  loss_dice_2: 0.0794  loss_ce_3: 0.003688  loss_mask_3: 0.04464  loss_dice_3: 0.07939  loss_ce_4: 0.003156  loss_mask_4: 0.04443  loss_dice_4: 0.0805  time: 0.4492  data_time: 0.0683  lr: 4.7527e-05  max_mem: 5436M
[01/28 11:47:14] d2.utils.events INFO:  eta: 0:08:03  iter: 519  total_loss: 0.8308  loss_ce: 0.001577  loss_mask: 0.04547  loss_dice: 0.0822  loss_ce_0: 0.00428  loss_mask_0: 0.04585  loss_dice_0: 0.08352  loss_ce_1: 0.002897  loss_mask_1: 0.04578  loss_dice_1: 0.08265  loss_ce_2: 0.002435  loss_mask_2: 0.04601  loss_dice_2: 0.08081  loss_ce_3: 0.002118  loss_mask_3: 0.04582  loss_dice_3: 0.08258  loss_ce_4: 0.001854  loss_mask_4: 0.04606  loss_dice_4: 0.08227  time: 0.4489  data_time: 0.0672  lr: 4.8623e-05  max_mem: 5436M
[01/28 11:47:23] d2.utils.events INFO:  eta: 0:07:54  iter: 539  total_loss: 0.8442  loss_ce: 0.001342  loss_mask: 0.04711  loss_dice: 0.08107  loss_ce_0: 0.004139  loss_mask_0: 0.04636  loss_dice_0: 0.0799  loss_ce_1: 0.00285  loss_mask_1: 0.04643  loss_dice_1: 0.08001  loss_ce_2: 0.002327  loss_mask_2: 0.04745  loss_dice_2: 0.08  loss_ce_3: 0.001879  loss_mask_3: 0.04693  loss_dice_3: 0.08147  loss_ce_4: 0.001639  loss_mask_4: 0.04738  loss_dice_4: 0.08173  time: 0.4487  data_time: 0.0705  lr: 4.9655e-05  max_mem: 5436M
[01/28 11:47:32] d2.utils.events INFO:  eta: 0:07:45  iter: 559  total_loss: 0.7971  loss_ce: 0.001711  loss_mask: 0.04702  loss_dice: 0.07418  loss_ce_0: 0.005701  loss_mask_0: 0.04719  loss_dice_0: 0.07527  loss_ce_1: 0.003817  loss_mask_1: 0.04604  loss_dice_1: 0.07679  loss_ce_2: 0.003321  loss_mask_2: 0.04621  loss_dice_2: 0.07415  loss_ce_3: 0.002944  loss_mask_3: 0.04548  loss_dice_3: 0.07415  loss_ce_4: 0.002165  loss_mask_4: 0.04642  loss_dice_4: 0.0741  time: 0.4484  data_time: 0.0670  lr: 5.0623e-05  max_mem: 5436M
[01/28 11:47:41] d2.utils.events INFO:  eta: 0:07:36  iter: 579  total_loss: 0.7868  loss_ce: 0.002024  loss_mask: 0.0394  loss_dice: 0.07908  loss_ce_0: 0.003938  loss_mask_0: 0.04205  loss_dice_0: 0.07825  loss_ce_1: 0.003085  loss_mask_1: 0.04109  loss_dice_1: 0.08003  loss_ce_2: 0.002991  loss_mask_2: 0.03987  loss_dice_2: 0.07778  loss_ce_3: 0.002539  loss_mask_3: 0.03964  loss_dice_3: 0.07902  loss_ce_4: 0.002523  loss_mask_4: 0.03935  loss_dice_4: 0.07912  time: 0.4484  data_time: 0.0684  lr: 5.1527e-05  max_mem: 5436M
[01/28 11:47:50] d2.utils.events INFO:  eta: 0:07:27  iter: 599  total_loss: 0.7284  loss_ce: 0.002681  loss_mask: 0.04445  loss_dice: 0.07266  loss_ce_0: 0.004835  loss_mask_0: 0.04319  loss_dice_0: 0.07352  loss_ce_1: 0.004769  loss_mask_1: 0.0436  loss_dice_1: 0.0729  loss_ce_2: 0.002943  loss_mask_2: 0.04475  loss_dice_2: 0.07259  loss_ce_3: 0.002545  loss_mask_3: 0.04456  loss_dice_3: 0.07227  loss_ce_4: 0.002778  loss_mask_4: 0.04469  loss_dice_4: 0.07215  time: 0.4483  data_time: 0.0721  lr: 5.2366e-05  max_mem: 5436M
[01/28 11:47:59] d2.utils.events INFO:  eta: 0:07:18  iter: 619  total_loss: 0.7266  loss_ce: 0.00148  loss_mask: 0.04352  loss_dice: 0.0759  loss_ce_0: 0.003686  loss_mask_0: 0.04478  loss_dice_0: 0.0751  loss_ce_1: 0.002677  loss_mask_1: 0.04419  loss_dice_1: 0.07494  loss_ce_2: 0.002095  loss_mask_2: 0.0438  loss_dice_2: 0.07642  loss_ce_3: 0.001724  loss_mask_3: 0.04412  loss_dice_3: 0.07566  loss_ce_4: 0.001765  loss_mask_4: 0.04357  loss_dice_4: 0.07558  time: 0.4485  data_time: 0.0754  lr: 5.314e-05  max_mem: 5436M
[01/28 11:48:08] d2.utils.events INFO:  eta: 0:07:09  iter: 639  total_loss: 0.7089  loss_ce: 0.00106  loss_mask: 0.0439  loss_dice: 0.07139  loss_ce_0: 0.002741  loss_mask_0: 0.04313  loss_dice_0: 0.07187  loss_ce_1: 0.00196  loss_mask_1: 0.04336  loss_dice_1: 0.07103  loss_ce_2: 0.001638  loss_mask_2: 0.04341  loss_dice_2: 0.07092  loss_ce_3: 0.001426  loss_mask_3: 0.04354  loss_dice_3: 0.0709  loss_ce_4: 0.001276  loss_mask_4: 0.04307  loss_dice_4: 0.07119  time: 0.4486  data_time: 0.0691  lr: 5.385e-05  max_mem: 5436M
[01/28 11:48:17] d2.utils.events INFO:  eta: 0:07:00  iter: 659  total_loss: 0.6842  loss_ce: 0.000897  loss_mask: 0.04189  loss_dice: 0.06846  loss_ce_0: 0.002599  loss_mask_0: 0.04216  loss_dice_0: 0.06928  loss_ce_1: 0.001767  loss_mask_1: 0.04139  loss_dice_1: 0.06789  loss_ce_2: 0.001475  loss_mask_2: 0.04104  loss_dice_2: 0.06832  loss_ce_3: 0.001162  loss_mask_3: 0.04153  loss_dice_3: 0.06783  loss_ce_4: 0.001077  loss_mask_4: 0.04159  loss_dice_4: 0.06833  time: 0.4488  data_time: 0.0750  lr: 5.4494e-05  max_mem: 5436M
[01/28 11:48:26] d2.utils.events INFO:  eta: 0:06:51  iter: 679  total_loss: 0.6557  loss_ce: 0.0008281  loss_mask: 0.03933  loss_dice: 0.06589  loss_ce_0: 0.002122  loss_mask_0: 0.03906  loss_dice_0: 0.0673  loss_ce_1: 0.001508  loss_mask_1: 0.03884  loss_dice_1: 0.06662  loss_ce_2: 0.001287  loss_mask_2: 0.03938  loss_dice_2: 0.06609  loss_ce_3: 0.001031  loss_mask_3: 0.03953  loss_dice_3: 0.06612  loss_ce_4: 0.000969  loss_mask_4: 0.0396  loss_dice_4: 0.0655  time: 0.4489  data_time: 0.0707  lr: 5.5072e-05  max_mem: 5436M
[01/28 11:48:35] d2.utils.events INFO:  eta: 0:06:42  iter: 699  total_loss: 0.6931  loss_ce: 0.0007326  loss_mask: 0.04088  loss_dice: 0.07054  loss_ce_0: 0.001863  loss_mask_0: 0.03907  loss_dice_0: 0.06993  loss_ce_1: 0.001364  loss_mask_1: 0.03957  loss_dice_1: 0.0702  loss_ce_2: 0.001157  loss_mask_2: 0.04008  loss_dice_2: 0.06951  loss_ce_3: 0.0009412  loss_mask_3: 0.04027  loss_dice_3: 0.07065  loss_ce_4: 0.0008744  loss_mask_4: 0.04016  loss_dice_4: 0.07036  time: 0.4490  data_time: 0.0743  lr: 5.5585e-05  max_mem: 5436M
[01/28 11:48:44] d2.utils.events INFO:  eta: 0:06:33  iter: 719  total_loss: 0.7161  loss_ce: 0.0006494  loss_mask: 0.04287  loss_dice: 0.06843  loss_ce_0: 0.001662  loss_mask_0: 0.04309  loss_dice_0: 0.06882  loss_ce_1: 0.001132  loss_mask_1: 0.04353  loss_dice_1: 0.06876  loss_ce_2: 0.001052  loss_mask_2: 0.04316  loss_dice_2: 0.06923  loss_ce_3: 0.0008456  loss_mask_3: 0.04333  loss_dice_3: 0.07016  loss_ce_4: 0.0007907  loss_mask_4: 0.04301  loss_dice_4: 0.06978  time: 0.4491  data_time: 0.0782  lr: 5.6032e-05  max_mem: 5436M
[01/28 11:48:53] d2.utils.events INFO:  eta: 0:06:24  iter: 739  total_loss: 0.619  loss_ce: 0.0006418  loss_mask: 0.03688  loss_dice: 0.06019  loss_ce_0: 0.001626  loss_mask_0: 0.03727  loss_dice_0: 0.06018  loss_ce_1: 0.001167  loss_mask_1: 0.03683  loss_dice_1: 0.06124  loss_ce_2: 0.0009885  loss_mask_2: 0.03725  loss_dice_2: 0.06072  loss_ce_3: 0.0008708  loss_mask_3: 0.03663  loss_dice_3: 0.05992  loss_ce_4: 0.0007898  loss_mask_4: 0.03704  loss_dice_4: 0.06005  time: 0.4492  data_time: 0.0772  lr: 5.6413e-05  max_mem: 5436M
[01/28 11:49:02] d2.utils.events INFO:  eta: 0:06:16  iter: 759  total_loss: 0.6429  loss_ce: 0.0005938  loss_mask: 0.03632  loss_dice: 0.06393  loss_ce_0: 0.001625  loss_mask_0: 0.03764  loss_dice_0: 0.06458  loss_ce_1: 0.001185  loss_mask_1: 0.03648  loss_dice_1: 0.06415  loss_ce_2: 0.001017  loss_mask_2: 0.03653  loss_dice_2: 0.06387  loss_ce_3: 0.0008376  loss_mask_3: 0.03653  loss_dice_3: 0.06382  loss_ce_4: 0.0007339  loss_mask_4: 0.03706  loss_dice_4: 0.06321  time: 0.4493  data_time: 0.0746  lr: 5.6727e-05  max_mem: 5436M
[01/28 11:49:12] d2.utils.events INFO:  eta: 0:06:07  iter: 779  total_loss: 0.6351  loss_ce: 0.0005353  loss_mask: 0.03548  loss_dice: 0.06461  loss_ce_0: 0.001389  loss_mask_0: 0.03549  loss_dice_0: 0.0661  loss_ce_1: 0.001012  loss_mask_1: 0.03524  loss_dice_1: 0.06612  loss_ce_2: 0.0008833  loss_mask_2: 0.03604  loss_dice_2: 0.0649  loss_ce_3: 0.0007517  loss_mask_3: 0.03547  loss_dice_3: 0.06495  loss_ce_4: 0.0006819  loss_mask_4: 0.03588  loss_dice_4: 0.06445  time: 0.4493  data_time: 0.0710  lr: 5.6974e-05  max_mem: 5436M
[01/28 11:49:20] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:49:20] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/28 11:49:20] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:49:20] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:49:20] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:49:20] d2.evaluation.evaluator INFO: Start inference on 6 batches
[01/28 11:49:21] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.101117 (0.101117 s / iter per device, on 1 devices)
[01/28 11:49:21] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.043965 s / iter per device, on 1 devices)
[01/28 11:49:21] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 95.15900201026973, 'fwIoU': 97.65340566065798, 'IoU-Grass': nan, 'IoU-CameraEdge': 96.24576923856428, 'IoU-Vehicle': 93.47331425867934, 'IoU-Person': nan, 'IoU-Bush': 95.75370514820592, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 97.32064225855373, 'IoU-Large_stone': 98.78835813912582, 'IoU-Forrest': nan, 'IoU-Gravel': 89.37222301848932, 'mACC': 96.54483609010516, 'pACC': 98.80831591090413, 'ACC-Grass': nan, 'ACC-CameraEdge': 98.58739725316431, 'ACC-Vehicle': 94.64175733935537, 'ACC-Person': nan, 'ACC-Bush': 97.56109676137493, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 98.55113571028848, 'ACC-Large_stone': 99.35789201321403, 'ACC-Forrest': nan, 'ACC-Gravel': 90.56973746323396})])
[01/28 11:49:21] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:49:21] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/28 11:49:21] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:49:21] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:49:21] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:49:21] d2.evaluation.evaluator INFO: Start inference on 6 batches
[01/28 11:49:22] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.112949 (0.112949 s / iter per device, on 1 devices)
[01/28 11:49:22] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.046822 s / iter per device, on 1 devices)
[01/28 11:49:22] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 95.15900201026973, 'fwIoU': 97.65340566065798, 'IoU-Grass': nan, 'IoU-CameraEdge': 96.24576923856428, 'IoU-Vehicle': 93.47331425867934, 'IoU-Person': nan, 'IoU-Bush': 95.75370514820592, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 97.32064225855373, 'IoU-Large_stone': 98.78835813912582, 'IoU-Forrest': nan, 'IoU-Gravel': 89.37222301848932, 'mACC': 96.54483609010516, 'pACC': 98.80831591090413, 'ACC-Grass': nan, 'ACC-CameraEdge': 98.58739725316431, 'ACC-Vehicle': 94.64175733935537, 'ACC-Person': nan, 'ACC-Bush': 97.56109676137493, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 98.55113571028848, 'ACC-Large_stone': 99.35789201321403, 'ACC-Forrest': nan, 'ACC-Gravel': 90.56973746323396})])
[01/28 11:49:22] d2.utils.events INFO:  eta: 0:05:58  iter: 799  total_loss: 0.6009  loss_ce: 0.0005404  loss_mask: 0.03515  loss_dice: 0.06107  loss_ce_0: 0.001172  loss_mask_0: 0.03451  loss_dice_0: 0.06221  loss_ce_1: 0.0008999  loss_mask_1: 0.03448  loss_dice_1: 0.06065  loss_ce_2: 0.0008227  loss_mask_2: 0.03439  loss_dice_2: 0.06089  loss_ce_3: 0.0007157  loss_mask_3: 0.03499  loss_dice_3: 0.06036  loss_ce_4: 0.000659  loss_mask_4: 0.03485  loss_dice_4: 0.06149  time: 0.4492  data_time: 0.0713  lr: 5.7154e-05  max_mem: 5436M
[01/28 11:49:31] d2.utils.events INFO:  eta: 0:05:49  iter: 819  total_loss: 0.6136  loss_ce: 0.0005389  loss_mask: 0.03831  loss_dice: 0.06034  loss_ce_0: 0.00125  loss_mask_0: 0.0385  loss_dice_0: 0.06062  loss_ce_1: 0.0009535  loss_mask_1: 0.03854  loss_dice_1: 0.06054  loss_ce_2: 0.0007604  loss_mask_2: 0.03788  loss_dice_2: 0.06042  loss_ce_3: 0.0006817  loss_mask_3: 0.03855  loss_dice_3: 0.06029  loss_ce_4: 0.0006527  loss_mask_4: 0.03769  loss_dice_4: 0.06012  time: 0.4493  data_time: 0.0743  lr: 5.7267e-05  max_mem: 5436M
[01/28 11:49:40] d2.utils.events INFO:  eta: 0:05:40  iter: 839  total_loss: 0.6146  loss_ce: 0.0004281  loss_mask: 0.03644  loss_dice: 0.06187  loss_ce_0: 0.001099  loss_mask_0: 0.03689  loss_dice_0: 0.06285  loss_ce_1: 0.0007992  loss_mask_1: 0.03553  loss_dice_1: 0.06259  loss_ce_2: 0.0006969  loss_mask_2: 0.0357  loss_dice_2: 0.06345  loss_ce_3: 0.0006124  loss_mask_3: 0.03606  loss_dice_3: 0.0626  loss_ce_4: 0.0005382  loss_mask_4: 0.0365  loss_dice_4: 0.06188  time: 0.4493  data_time: 0.0741  lr: 5.7311e-05  max_mem: 5436M
[01/28 11:49:49] d2.utils.events INFO:  eta: 0:05:31  iter: 859  total_loss: 0.5806  loss_ce: 0.0004464  loss_mask: 0.03736  loss_dice: 0.06249  loss_ce_0: 0.001212  loss_mask_0: 0.0357  loss_dice_0: 0.06222  loss_ce_1: 0.0008236  loss_mask_1: 0.0359  loss_dice_1: 0.06175  loss_ce_2: 0.0007284  loss_mask_2: 0.03668  loss_dice_2: 0.06065  loss_ce_3: 0.0006277  loss_mask_3: 0.03666  loss_dice_3: 0.06148  loss_ce_4: 0.0005296  loss_mask_4: 0.0368  loss_dice_4: 0.06212  time: 0.4492  data_time: 0.0742  lr: 5.7288e-05  max_mem: 5436M
[01/28 11:49:58] d2.utils.events INFO:  eta: 0:05:22  iter: 879  total_loss: 0.5486  loss_ce: 0.0004222  loss_mask: 0.03228  loss_dice: 0.0564  loss_ce_0: 0.00106  loss_mask_0: 0.03259  loss_dice_0: 0.05635  loss_ce_1: 0.0008036  loss_mask_1: 0.03254  loss_dice_1: 0.05633  loss_ce_2: 0.0006753  loss_mask_2: 0.03266  loss_dice_2: 0.05583  loss_ce_3: 0.0005981  loss_mask_3: 0.03201  loss_dice_3: 0.05588  loss_ce_4: 0.0005155  loss_mask_4: 0.03229  loss_dice_4: 0.05617  time: 0.4493  data_time: 0.0750  lr: 5.7195e-05  max_mem: 5436M
[01/28 11:50:07] d2.utils.events INFO:  eta: 0:05:13  iter: 899  total_loss: 0.6023  loss_ce: 0.0003825  loss_mask: 0.03704  loss_dice: 0.0592  loss_ce_0: 0.0009119  loss_mask_0: 0.03846  loss_dice_0: 0.05997  loss_ce_1: 0.0006766  loss_mask_1: 0.03688  loss_dice_1: 0.0596  loss_ce_2: 0.0005751  loss_mask_2: 0.03726  loss_dice_2: 0.05863  loss_ce_3: 0.0005193  loss_mask_3: 0.03744  loss_dice_3: 0.05923  loss_ce_4: 0.0004477  loss_mask_4: 0.03722  loss_dice_4: 0.05913  time: 0.4494  data_time: 0.0724  lr: 5.7034e-05  max_mem: 5436M
[01/28 11:50:16] d2.utils.events INFO:  eta: 0:05:04  iter: 919  total_loss: 0.5825  loss_ce: 0.0005549  loss_mask: 0.03102  loss_dice: 0.05822  loss_ce_0: 0.00103  loss_mask_0: 0.03143  loss_dice_0: 0.05788  loss_ce_1: 0.0007965  loss_mask_1: 0.0309  loss_dice_1: 0.05812  loss_ce_2: 0.0007302  loss_mask_2: 0.03102  loss_dice_2: 0.05823  loss_ce_3: 0.0006717  loss_mask_3: 0.03108  loss_dice_3: 0.05818  loss_ce_4: 0.000606  loss_mask_4: 0.03054  loss_dice_4: 0.05812  time: 0.4495  data_time: 0.0719  lr: 5.6804e-05  max_mem: 5436M
[01/28 11:50:25] d2.utils.events INFO:  eta: 0:04:55  iter: 939  total_loss: 0.5951  loss_ce: 0.0008992  loss_mask: 0.03486  loss_dice: 0.0633  loss_ce_0: 0.001358  loss_mask_0: 0.03507  loss_dice_0: 0.06426  loss_ce_1: 0.001035  loss_mask_1: 0.03515  loss_dice_1: 0.06339  loss_ce_2: 0.0009314  loss_mask_2: 0.03577  loss_dice_2: 0.06236  loss_ce_3: 0.0009795  loss_mask_3: 0.03605  loss_dice_3: 0.06291  loss_ce_4: 0.0009404  loss_mask_4: 0.03478  loss_dice_4: 0.063  time: 0.4496  data_time: 0.0705  lr: 5.6504e-05  max_mem: 5436M
[01/28 11:50:34] d2.utils.events INFO:  eta: 0:04:46  iter: 959  total_loss: 0.5421  loss_ce: 0.0005324  loss_mask: 0.03191  loss_dice: 0.05724  loss_ce_0: 0.001168  loss_mask_0: 0.03192  loss_dice_0: 0.05794  loss_ce_1: 0.001047  loss_mask_1: 0.03195  loss_dice_1: 0.05788  loss_ce_2: 0.0007791  loss_mask_2: 0.03205  loss_dice_2: 0.05728  loss_ce_3: 0.0007934  loss_mask_3: 0.03158  loss_dice_3: 0.05734  loss_ce_4: 0.0006736  loss_mask_4: 0.03197  loss_dice_4: 0.05708  time: 0.4496  data_time: 0.0693  lr: 5.6133e-05  max_mem: 5436M
[01/28 11:50:43] d2.utils.events INFO:  eta: 0:04:37  iter: 979  total_loss: 0.5532  loss_ce: 0.000542  loss_mask: 0.03276  loss_dice: 0.05243  loss_ce_0: 0.001304  loss_mask_0: 0.03181  loss_dice_0: 0.05237  loss_ce_1: 0.001066  loss_mask_1: 0.0317  loss_dice_1: 0.05338  loss_ce_2: 0.0009847  loss_mask_2: 0.03204  loss_dice_2: 0.05286  loss_ce_3: 0.0008637  loss_mask_3: 0.0325  loss_dice_3: 0.05301  loss_ce_4: 0.0007151  loss_mask_4: 0.03281  loss_dice_4: 0.05268  time: 0.4495  data_time: 0.0720  lr: 5.5692e-05  max_mem: 5436M
[01/28 11:50:52] d2.utils.events INFO:  eta: 0:04:28  iter: 999  total_loss: 0.5288  loss_ce: 0.0003854  loss_mask: 0.03386  loss_dice: 0.05613  loss_ce_0: 0.0008968  loss_mask_0: 0.03521  loss_dice_0: 0.05599  loss_ce_1: 0.0007407  loss_mask_1: 0.03436  loss_dice_1: 0.05538  loss_ce_2: 0.0006243  loss_mask_2: 0.03372  loss_dice_2: 0.05519  loss_ce_3: 0.0005802  loss_mask_3: 0.03333  loss_dice_3: 0.05581  loss_ce_4: 0.0004788  loss_mask_4: 0.03354  loss_dice_4: 0.05564  time: 0.4495  data_time: 0.0722  lr: 5.518e-05  max_mem: 5436M
[01/28 11:51:01] d2.utils.events INFO:  eta: 0:04:19  iter: 1019  total_loss: 0.4999  loss_ce: 0.0003171  loss_mask: 0.03029  loss_dice: 0.05102  loss_ce_0: 0.0007807  loss_mask_0: 0.03084  loss_dice_0: 0.05055  loss_ce_1: 0.0006482  loss_mask_1: 0.03059  loss_dice_1: 0.05096  loss_ce_2: 0.00053  loss_mask_2: 0.0307  loss_dice_2: 0.05065  loss_ce_3: 0.0004612  loss_mask_3: 0.03068  loss_dice_3: 0.05097  loss_ce_4: 0.0003945  loss_mask_4: 0.0303  loss_dice_4: 0.05098  time: 0.4494  data_time: 0.0706  lr: 5.4596e-05  max_mem: 5436M
[01/28 11:51:10] d2.utils.events INFO:  eta: 0:04:10  iter: 1039  total_loss: 0.5243  loss_ce: 0.0002827  loss_mask: 0.03025  loss_dice: 0.05538  loss_ce_0: 0.0007865  loss_mask_0: 0.03021  loss_dice_0: 0.056  loss_ce_1: 0.0006255  loss_mask_1: 0.03003  loss_dice_1: 0.05501  loss_ce_2: 0.0004845  loss_mask_2: 0.03018  loss_dice_2: 0.05545  loss_ce_3: 0.0004008  loss_mask_3: 0.03032  loss_dice_3: 0.0551  loss_ce_4: 0.000342  loss_mask_4: 0.03054  loss_dice_4: 0.05526  time: 0.4495  data_time: 0.0696  lr: 5.394e-05  max_mem: 5436M
[01/28 11:51:19] d2.utils.events INFO:  eta: 0:04:01  iter: 1059  total_loss: 0.4612  loss_ce: 0.0002543  loss_mask: 0.02801  loss_dice: 0.04888  loss_ce_0: 0.0006806  loss_mask_0: 0.02774  loss_dice_0: 0.04953  loss_ce_1: 0.0005321  loss_mask_1: 0.02791  loss_dice_1: 0.04911  loss_ce_2: 0.0004801  loss_mask_2: 0.02744  loss_dice_2: 0.04951  loss_ce_3: 0.0003799  loss_mask_3: 0.0277  loss_dice_3: 0.04881  loss_ce_4: 0.0003205  loss_mask_4: 0.02767  loss_dice_4: 0.04887  time: 0.4494  data_time: 0.0711  lr: 5.3211e-05  max_mem: 5436M
[01/28 11:51:28] d2.utils.events INFO:  eta: 0:03:52  iter: 1079  total_loss: 0.5108  loss_ce: 0.0002492  loss_mask: 0.02934  loss_dice: 0.05194  loss_ce_0: 0.0007076  loss_mask_0: 0.02975  loss_dice_0: 0.05279  loss_ce_1: 0.0005483  loss_mask_1: 0.02959  loss_dice_1: 0.05127  loss_ce_2: 0.0004655  loss_mask_2: 0.03  loss_dice_2: 0.05201  loss_ce_3: 0.0003819  loss_mask_3: 0.02988  loss_dice_3: 0.05205  loss_ce_4: 0.0003115  loss_mask_4: 0.02958  loss_dice_4: 0.05186  time: 0.4493  data_time: 0.0704  lr: 5.2409e-05  max_mem: 5436M
[01/28 11:51:37] d2.utils.events INFO:  eta: 0:03:43  iter: 1099  total_loss: 0.5464  loss_ce: 0.0004933  loss_mask: 0.02858  loss_dice: 0.0564  loss_ce_0: 0.0008412  loss_mask_0: 0.02904  loss_dice_0: 0.05705  loss_ce_1: 0.0007342  loss_mask_1: 0.02838  loss_dice_1: 0.05724  loss_ce_2: 0.000628  loss_mask_2: 0.02856  loss_dice_2: 0.0566  loss_ce_3: 0.0005536  loss_mask_3: 0.02883  loss_dice_3: 0.05708  loss_ce_4: 0.0005596  loss_mask_4: 0.02856  loss_dice_4: 0.05674  time: 0.4493  data_time: 0.0755  lr: 5.1533e-05  max_mem: 5436M
[01/28 11:51:46] d2.utils.events INFO:  eta: 0:03:34  iter: 1119  total_loss: 0.4599  loss_ce: 0.0004642  loss_mask: 0.02782  loss_dice: 0.04617  loss_ce_0: 0.0007611  loss_mask_0: 0.02892  loss_dice_0: 0.04577  loss_ce_1: 0.0006423  loss_mask_1: 0.02774  loss_dice_1: 0.046  loss_ce_2: 0.0005769  loss_mask_2: 0.02822  loss_dice_2: 0.04594  loss_ce_3: 0.0004992  loss_mask_3: 0.02818  loss_dice_3: 0.04587  loss_ce_4: 0.0005353  loss_mask_4: 0.02814  loss_dice_4: 0.04627  time: 0.4494  data_time: 0.0739  lr: 5.0581e-05  max_mem: 5436M
[01/28 11:51:55] d2.utils.events INFO:  eta: 0:03:26  iter: 1139  total_loss: 0.4594  loss_ce: 0.0003089  loss_mask: 0.02779  loss_dice: 0.04678  loss_ce_0: 0.0007429  loss_mask_0: 0.02712  loss_dice_0: 0.04718  loss_ce_1: 0.0006033  loss_mask_1: 0.0272  loss_dice_1: 0.04728  loss_ce_2: 0.0005084  loss_mask_2: 0.02746  loss_dice_2: 0.04699  loss_ce_3: 0.0004218  loss_mask_3: 0.02778  loss_dice_3: 0.04692  loss_ce_4: 0.0003644  loss_mask_4: 0.02771  loss_dice_4: 0.04681  time: 0.4496  data_time: 0.0757  lr: 4.9555e-05  max_mem: 5436M
[01/28 11:52:04] d2.utils.events INFO:  eta: 0:03:17  iter: 1159  total_loss: 0.4634  loss_ce: 0.0003463  loss_mask: 0.0267  loss_dice: 0.04682  loss_ce_0: 0.0006236  loss_mask_0: 0.02737  loss_dice_0: 0.04688  loss_ce_1: 0.0005124  loss_mask_1: 0.02735  loss_dice_1: 0.04687  loss_ce_2: 0.0004717  loss_mask_2: 0.02672  loss_dice_2: 0.04702  loss_ce_3: 0.0004106  loss_mask_3: 0.02657  loss_dice_3: 0.04672  loss_ce_4: 0.0003752  loss_mask_4: 0.02648  loss_dice_4: 0.04689  time: 0.4496  data_time: 0.0740  lr: 4.8452e-05  max_mem: 5436M
[01/28 11:52:14] d2.utils.events INFO:  eta: 0:03:08  iter: 1179  total_loss: 0.4798  loss_ce: 0.0002904  loss_mask: 0.02765  loss_dice: 0.04902  loss_ce_0: 0.0006012  loss_mask_0: 0.02785  loss_dice_0: 0.0496  loss_ce_1: 0.0004796  loss_mask_1: 0.02762  loss_dice_1: 0.04858  loss_ce_2: 0.0004179  loss_mask_2: 0.02795  loss_dice_2: 0.04883  loss_ce_3: 0.0003622  loss_mask_3: 0.02787  loss_dice_3: 0.04897  loss_ce_4: 0.0003266  loss_mask_4: 0.02777  loss_dice_4: 0.04897  time: 0.4497  data_time: 0.0772  lr: 4.7271e-05  max_mem: 5436M
[01/28 11:52:22] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:52:22] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/28 11:52:22] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:52:22] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:52:22] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:52:22] d2.evaluation.evaluator INFO: Start inference on 6 batches
[01/28 11:52:23] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.101987 (0.101987 s / iter per device, on 1 devices)
[01/28 11:52:23] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.044042 s / iter per device, on 1 devices)
[01/28 11:52:23] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 96.567605350989, 'fwIoU': 98.43283364566736, 'IoU-Grass': nan, 'IoU-CameraEdge': 97.5629847319834, 'IoU-Vehicle': 95.72750607943799, 'IoU-Person': nan, 'IoU-Bush': 96.66138275820022, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 98.21047746804243, 'IoU-Large_stone': 99.17978900477793, 'IoU-Forrest': nan, 'IoU-Gravel': 92.06349206349206, 'mACC': 97.76600772997345, 'pACC': 99.20843043072138, 'ACC-Grass': nan, 'ACC-CameraEdge': 98.81381332675927, 'ACC-Vehicle': 96.97871758023678, 'ACC-Person': nan, 'ACC-Bush': 98.44029405920922, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 98.96586353078261, 'ACC-Large_stone': 99.67572674156222, 'ACC-Forrest': nan, 'ACC-Gravel': 93.72163114129053})])
[01/28 11:52:23] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:52:23] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/28 11:52:23] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:52:23] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:52:23] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:52:23] d2.evaluation.evaluator INFO: Start inference on 6 batches
[01/28 11:52:24] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.104366 (0.104366 s / iter per device, on 1 devices)
[01/28 11:52:24] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.044400 s / iter per device, on 1 devices)
[01/28 11:52:24] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 96.567605350989, 'fwIoU': 98.43283364566736, 'IoU-Grass': nan, 'IoU-CameraEdge': 97.5629847319834, 'IoU-Vehicle': 95.72750607943799, 'IoU-Person': nan, 'IoU-Bush': 96.66138275820022, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 98.21047746804243, 'IoU-Large_stone': 99.17978900477793, 'IoU-Forrest': nan, 'IoU-Gravel': 92.06349206349206, 'mACC': 97.76600772997345, 'pACC': 99.20843043072138, 'ACC-Grass': nan, 'ACC-CameraEdge': 98.81381332675927, 'ACC-Vehicle': 96.97871758023678, 'ACC-Person': nan, 'ACC-Bush': 98.44029405920922, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 98.96586353078261, 'ACC-Large_stone': 99.67572674156222, 'ACC-Forrest': nan, 'ACC-Gravel': 93.72163114129053})])
[01/28 11:52:24] d2.utils.events INFO:  eta: 0:02:59  iter: 1199  total_loss: 0.4594  loss_ce: 0.0002492  loss_mask: 0.02684  loss_dice: 0.04975  loss_ce_0: 0.0006111  loss_mask_0: 0.02672  loss_dice_0: 0.04986  loss_ce_1: 0.000488  loss_mask_1: 0.0268  loss_dice_1: 0.05011  loss_ce_2: 0.0004207  loss_mask_2: 0.02619  loss_dice_2: 0.04986  loss_ce_3: 0.000332  loss_mask_3: 0.02625  loss_dice_3: 0.05013  loss_ce_4: 0.0002945  loss_mask_4: 0.02672  loss_dice_4: 0.04992  time: 0.4496  data_time: 0.0711  lr: 4.6013e-05  max_mem: 5436M
[01/28 11:52:33] d2.utils.events INFO:  eta: 0:02:50  iter: 1219  total_loss: 0.4481  loss_ce: 0.0002487  loss_mask: 0.02628  loss_dice: 0.04518  loss_ce_0: 0.0005811  loss_mask_0: 0.02702  loss_dice_0: 0.04537  loss_ce_1: 0.0004187  loss_mask_1: 0.0263  loss_dice_1: 0.04509  loss_ce_2: 0.0003826  loss_mask_2: 0.02655  loss_dice_2: 0.04537  loss_ce_3: 0.0003164  loss_mask_3: 0.0261  loss_dice_3: 0.0451  loss_ce_4: 0.0002871  loss_mask_4: 0.02644  loss_dice_4: 0.04518  time: 0.4496  data_time: 0.0766  lr: 4.4675e-05  max_mem: 5436M
[01/28 11:52:42] d2.utils.events INFO:  eta: 0:02:41  iter: 1239  total_loss: 0.4467  loss_ce: 0.0003314  loss_mask: 0.02635  loss_dice: 0.04622  loss_ce_0: 0.0006124  loss_mask_0: 0.02668  loss_dice_0: 0.04681  loss_ce_1: 0.0004767  loss_mask_1: 0.02657  loss_dice_1: 0.04641  loss_ce_2: 0.0004302  loss_mask_2: 0.02678  loss_dice_2: 0.04594  loss_ce_3: 0.0003779  loss_mask_3: 0.02653  loss_dice_3: 0.04625  loss_ce_4: 0.0003482  loss_mask_4: 0.02639  loss_dice_4: 0.04617  time: 0.4497  data_time: 0.0748  lr: 4.3257e-05  max_mem: 5436M
[01/28 11:52:51] d2.utils.events INFO:  eta: 0:02:32  iter: 1259  total_loss: 0.4688  loss_ce: 0.0002663  loss_mask: 0.02805  loss_dice: 0.04965  loss_ce_0: 0.0006374  loss_mask_0: 0.02768  loss_dice_0: 0.04977  loss_ce_1: 0.0004808  loss_mask_1: 0.02797  loss_dice_1: 0.0501  loss_ce_2: 0.0004202  loss_mask_2: 0.02797  loss_dice_2: 0.04953  loss_ce_3: 0.0003743  loss_mask_3: 0.02825  loss_dice_3: 0.04956  loss_ce_4: 0.0002991  loss_mask_4: 0.02795  loss_dice_4: 0.04953  time: 0.4496  data_time: 0.0715  lr: 4.1758e-05  max_mem: 5436M
[01/28 11:53:00] d2.utils.events INFO:  eta: 0:02:23  iter: 1279  total_loss: 0.4828  loss_ce: 0.0002265  loss_mask: 0.0267  loss_dice: 0.04898  loss_ce_0: 0.000558  loss_mask_0: 0.02608  loss_dice_0: 0.0493  loss_ce_1: 0.0004259  loss_mask_1: 0.02666  loss_dice_1: 0.04932  loss_ce_2: 0.0004088  loss_mask_2: 0.02671  loss_dice_2: 0.04891  loss_ce_3: 0.0003316  loss_mask_3: 0.02617  loss_dice_3: 0.04917  loss_ce_4: 0.0002664  loss_mask_4: 0.02663  loss_dice_4: 0.04882  time: 0.4496  data_time: 0.0705  lr: 4.0175e-05  max_mem: 5436M
[01/28 11:53:09] d2.utils.events INFO:  eta: 0:02:14  iter: 1299  total_loss: 0.4285  loss_ce: 0.0002062  loss_mask: 0.02486  loss_dice: 0.04567  loss_ce_0: 0.0005269  loss_mask_0: 0.02529  loss_dice_0: 0.04609  loss_ce_1: 0.0003718  loss_mask_1: 0.02549  loss_dice_1: 0.04548  loss_ce_2: 0.0003274  loss_mask_2: 0.02498  loss_dice_2: 0.04557  loss_ce_3: 0.0002852  loss_mask_3: 0.02507  loss_dice_3: 0.04531  loss_ce_4: 0.0002414  loss_mask_4: 0.02496  loss_dice_4: 0.04549  time: 0.4497  data_time: 0.0722  lr: 3.8508e-05  max_mem: 5436M
[01/28 11:53:18] d2.utils.events INFO:  eta: 0:02:05  iter: 1319  total_loss: 0.4101  loss_ce: 0.0002363  loss_mask: 0.02404  loss_dice: 0.04265  loss_ce_0: 0.0004404  loss_mask_0: 0.0236  loss_dice_0: 0.04303  loss_ce_1: 0.0003524  loss_mask_1: 0.02381  loss_dice_1: 0.04287  loss_ce_2: 0.0003418  loss_mask_2: 0.02386  loss_dice_2: 0.04303  loss_ce_3: 0.000289  loss_mask_3: 0.02388  loss_dice_3: 0.04312  loss_ce_4: 0.0002635  loss_mask_4: 0.02404  loss_dice_4: 0.04272  time: 0.4495  data_time: 0.0696  lr: 3.6755e-05  max_mem: 5436M
[01/28 11:53:27] d2.utils.events INFO:  eta: 0:01:56  iter: 1339  total_loss: 0.4705  loss_ce: 0.0002579  loss_mask: 0.02698  loss_dice: 0.04939  loss_ce_0: 0.000475  loss_mask_0: 0.0273  loss_dice_0: 0.04964  loss_ce_1: 0.0003758  loss_mask_1: 0.02766  loss_dice_1: 0.04914  loss_ce_2: 0.0003484  loss_mask_2: 0.02717  loss_dice_2: 0.0495  loss_ce_3: 0.0003018  loss_mask_3: 0.02666  loss_dice_3: 0.04949  loss_ce_4: 0.0002694  loss_mask_4: 0.02695  loss_dice_4: 0.04949  time: 0.4496  data_time: 0.0720  lr: 3.4913e-05  max_mem: 5436M
[01/28 11:53:36] d2.utils.events INFO:  eta: 0:01:47  iter: 1359  total_loss: 0.4228  loss_ce: 0.0002408  loss_mask: 0.02321  loss_dice: 0.04513  loss_ce_0: 0.0004565  loss_mask_0: 0.02357  loss_dice_0: 0.04551  loss_ce_1: 0.0003419  loss_mask_1: 0.02322  loss_dice_1: 0.04561  loss_ce_2: 0.0003201  loss_mask_2: 0.02344  loss_dice_2: 0.04519  loss_ce_3: 0.0002864  loss_mask_3: 0.02309  loss_dice_3: 0.04515  loss_ce_4: 0.0002584  loss_mask_4: 0.02326  loss_dice_4: 0.04488  time: 0.4495  data_time: 0.0714  lr: 3.2981e-05  max_mem: 5436M
[01/28 11:53:45] d2.utils.events INFO:  eta: 0:01:38  iter: 1379  total_loss: 0.452  loss_ce: 0.0002155  loss_mask: 0.02495  loss_dice: 0.04749  loss_ce_0: 0.0004487  loss_mask_0: 0.02544  loss_dice_0: 0.04786  loss_ce_1: 0.0003773  loss_mask_1: 0.02568  loss_dice_1: 0.04824  loss_ce_2: 0.000341  loss_mask_2: 0.02516  loss_dice_2: 0.04809  loss_ce_3: 0.000282  loss_mask_3: 0.02525  loss_dice_3: 0.04803  loss_ce_4: 0.0002438  loss_mask_4: 0.02492  loss_dice_4: 0.0478  time: 0.4496  data_time: 0.0753  lr: 3.0956e-05  max_mem: 5436M
[01/28 11:53:54] d2.utils.events INFO:  eta: 0:01:29  iter: 1399  total_loss: 0.3886  loss_ce: 0.0001825  loss_mask: 0.0232  loss_dice: 0.04029  loss_ce_0: 0.0004094  loss_mask_0: 0.02353  loss_dice_0: 0.04055  loss_ce_1: 0.0003176  loss_mask_1: 0.02321  loss_dice_1: 0.04042  loss_ce_2: 0.0002858  loss_mask_2: 0.02308  loss_dice_2: 0.04051  loss_ce_3: 0.000243  loss_mask_3: 0.02278  loss_dice_3: 0.04052  loss_ce_4: 0.0002146  loss_mask_4: 0.02303  loss_dice_4: 0.04054  time: 0.4497  data_time: 0.0794  lr: 2.8835e-05  max_mem: 5436M
[01/28 11:54:03] d2.utils.events INFO:  eta: 0:01:20  iter: 1419  total_loss: 0.3981  loss_ce: 0.0001643  loss_mask: 0.02308  loss_dice: 0.04278  loss_ce_0: 0.0003933  loss_mask_0: 0.02273  loss_dice_0: 0.04323  loss_ce_1: 0.0003061  loss_mask_1: 0.02258  loss_dice_1: 0.04346  loss_ce_2: 0.0002831  loss_mask_2: 0.0225  loss_dice_2: 0.04303  loss_ce_3: 0.0002304  loss_mask_3: 0.02276  loss_dice_3: 0.04311  loss_ce_4: 0.0001918  loss_mask_4: 0.02291  loss_dice_4: 0.04305  time: 0.4498  data_time: 0.0736  lr: 2.6615e-05  max_mem: 5436M
[01/28 11:54:12] d2.utils.events INFO:  eta: 0:01:11  iter: 1439  total_loss: 0.4072  loss_ce: 0.0001556  loss_mask: 0.02485  loss_dice: 0.04347  loss_ce_0: 0.0003867  loss_mask_0: 0.02476  loss_dice_0: 0.04402  loss_ce_1: 0.0003187  loss_mask_1: 0.02488  loss_dice_1: 0.04331  loss_ce_2: 0.0002701  loss_mask_2: 0.02489  loss_dice_2: 0.04343  loss_ce_3: 0.0002285  loss_mask_3: 0.02476  loss_dice_3: 0.04357  loss_ce_4: 0.000188  loss_mask_4: 0.02503  loss_dice_4: 0.04354  time: 0.4498  data_time: 0.0765  lr: 2.429e-05  max_mem: 5436M
[01/28 11:54:21] d2.utils.events INFO:  eta: 0:01:02  iter: 1459  total_loss: 0.3838  loss_ce: 0.0001659  loss_mask: 0.02359  loss_dice: 0.04118  loss_ce_0: 0.0003752  loss_mask_0: 0.02346  loss_dice_0: 0.04166  loss_ce_1: 0.0002797  loss_mask_1: 0.0237  loss_dice_1: 0.04147  loss_ce_2: 0.0002564  loss_mask_2: 0.02361  loss_dice_2: 0.04116  loss_ce_3: 0.0002153  loss_mask_3: 0.02379  loss_dice_3: 0.041  loss_ce_4: 0.0001864  loss_mask_4: 0.02344  loss_dice_4: 0.04106  time: 0.4498  data_time: 0.0724  lr: 2.1857e-05  max_mem: 5436M
[01/28 11:54:30] d2.utils.events INFO:  eta: 0:00:53  iter: 1479  total_loss: 0.3902  loss_ce: 0.0002124  loss_mask: 0.02172  loss_dice: 0.04253  loss_ce_0: 0.0003936  loss_mask_0: 0.02208  loss_dice_0: 0.04368  loss_ce_1: 0.0002837  loss_mask_1: 0.02204  loss_dice_1: 0.04276  loss_ce_2: 0.0002636  loss_mask_2: 0.02187  loss_dice_2: 0.04274  loss_ce_3: 0.0002485  loss_mask_3: 0.02214  loss_dice_3: 0.0423  loss_ce_4: 0.0002188  loss_mask_4: 0.02192  loss_dice_4: 0.04255  time: 0.4498  data_time: 0.0733  lr: 1.9307e-05  max_mem: 5436M
[01/28 11:54:39] d2.utils.events INFO:  eta: 0:00:44  iter: 1499  total_loss: 0.3803  loss_ce: 0.0002447  loss_mask: 0.02141  loss_dice: 0.04005  loss_ce_0: 0.0003859  loss_mask_0: 0.02138  loss_dice_0: 0.04046  loss_ce_1: 0.000309  loss_mask_1: 0.02131  loss_dice_1: 0.03997  loss_ce_2: 0.000294  loss_mask_2: 0.02171  loss_dice_2: 0.04012  loss_ce_3: 0.000265  loss_mask_3: 0.02135  loss_dice_3: 0.03989  loss_ce_4: 0.0002444  loss_mask_4: 0.02126  loss_dice_4: 0.0399  time: 0.4498  data_time: 0.0755  lr: 1.6631e-05  max_mem: 5436M
[01/28 11:54:48] d2.utils.events INFO:  eta: 0:00:35  iter: 1519  total_loss: 0.3874  loss_ce: 0.0002107  loss_mask: 0.0235  loss_dice: 0.0407  loss_ce_0: 0.0004018  loss_mask_0: 0.02315  loss_dice_0: 0.04116  loss_ce_1: 0.0003096  loss_mask_1: 0.02319  loss_dice_1: 0.04085  loss_ce_2: 0.0003054  loss_mask_2: 0.02312  loss_dice_2: 0.04078  loss_ce_3: 0.0002652  loss_mask_3: 0.02324  loss_dice_3: 0.04034  loss_ce_4: 0.000238  loss_mask_4: 0.02346  loss_dice_4: 0.04037  time: 0.4498  data_time: 0.0720  lr: 1.3645e-05  max_mem: 5436M
[01/28 11:54:57] d2.utils.events INFO:  eta: 0:00:26  iter: 1539  total_loss: 0.3809  loss_ce: 0.0001998  loss_mask: 0.02115  loss_dice: 0.04267  loss_ce_0: 0.0003676  loss_mask_0: 0.02161  loss_dice_0: 0.04235  loss_ce_1: 0.0002917  loss_mask_1: 0.02131  loss_dice_1: 0.04294  loss_ce_2: 0.0002786  loss_mask_2: 0.02126  loss_dice_2: 0.0428  loss_ce_3: 0.0002513  loss_mask_3: 0.02103  loss_dice_3: 0.0425  loss_ce_4: 0.0002174  loss_mask_4: 0.02103  loss_dice_4: 0.04289  time: 0.4499  data_time: 0.0733  lr: 1.0571e-05  max_mem: 5436M
[01/28 11:55:06] d2.utils.events INFO:  eta: 0:00:17  iter: 1559  total_loss: 0.362  loss_ce: 0.0001918  loss_mask: 0.02115  loss_dice: 0.03841  loss_ce_0: 0.0003861  loss_mask_0: 0.02162  loss_dice_0: 0.0387  loss_ce_1: 0.0003119  loss_mask_1: 0.02115  loss_dice_1: 0.0389  loss_ce_2: 0.0003015  loss_mask_2: 0.02097  loss_dice_2: 0.03879  loss_ce_3: 0.0002547  loss_mask_3: 0.02136  loss_dice_3: 0.03885  loss_ce_4: 0.0002113  loss_mask_4: 0.02108  loss_dice_4: 0.03857  time: 0.4499  data_time: 0.0683  lr: 7.3931e-06  max_mem: 5436M
[01/28 11:55:15] d2.utils.events INFO:  eta: 0:00:08  iter: 1579  total_loss: 0.3459  loss_ce: 0.0001683  loss_mask: 0.02124  loss_dice: 0.03635  loss_ce_0: 0.000355  loss_mask_0: 0.02083  loss_dice_0: 0.03678  loss_ce_1: 0.0002826  loss_mask_1: 0.02093  loss_dice_1: 0.0367  loss_ce_2: 0.0002566  loss_mask_2: 0.02101  loss_dice_2: 0.03618  loss_ce_3: 0.000232  loss_mask_3: 0.0208  loss_dice_3: 0.03666  loss_ce_4: 0.0002008  loss_mask_4: 0.02109  loss_dice_4: 0.03627  time: 0.4498  data_time: 0.0707  lr: 4.0487e-06  max_mem: 5436M
[01/28 11:55:24] fvcore.common.checkpoint INFO: Saving checkpoint to ./ffiModel/model_final.pth
[01/28 11:55:26] d2.utils.events INFO:  eta: 0:00:00  iter: 1599  total_loss: 0.3911  loss_ce: 0.0001852  loss_mask: 0.02357  loss_dice: 0.04147  loss_ce_0: 0.000421  loss_mask_0: 0.02352  loss_dice_0: 0.04173  loss_ce_1: 0.0003228  loss_mask_1: 0.0235  loss_dice_1: 0.04182  loss_ce_2: 0.0002956  loss_mask_2: 0.02396  loss_dice_2: 0.04247  loss_ce_3: 0.000247  loss_mask_3: 0.02361  loss_dice_3: 0.04185  loss_ce_4: 0.0002103  loss_mask_4: 0.02342  loss_dice_4: 0.04152  time: 0.4497  data_time: 0.0686  lr: 2.6141e-07  max_mem: 5436M
[01/28 11:55:26] d2.engine.hooks INFO: Overall training speed: 1598 iterations in 0:11:58 (0.4498 s / it)
[01/28 11:55:26] d2.engine.hooks INFO: Total training time: 0:12:06 (0:00:07 on hooks)
[01/28 11:55:26] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:55:26] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/28 11:55:26] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:55:26] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:55:26] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:55:26] d2.evaluation.evaluator INFO: Start inference on 6 batches
[01/28 11:55:27] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.102984 (0.102984 s / iter per device, on 1 devices)
[01/28 11:55:27] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.046130 s / iter per device, on 1 devices)
[01/28 11:55:27] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 97.10633992307703, 'fwIoU': 98.68024960305812, 'IoU-Grass': nan, 'IoU-CameraEdge': 97.94577230762884, 'IoU-Vehicle': 96.25564588979223, 'IoU-Person': nan, 'IoU-Bush': 97.23855728707242, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 98.60127263132257, 'IoU-Large_stone': 99.29138205021928, 'IoU-Forrest': nan, 'IoU-Gravel': 93.30540937242688, 'mACC': 98.03642599246473, 'pACC': 99.33526817674851, 'ACC-Grass': nan, 'ACC-CameraEdge': 98.58895426914319, 'ACC-Vehicle': 97.22393302766943, 'ACC-Person': nan, 'ACC-Bush': 98.56199086032188, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 99.30750930773928, 'ACC-Large_stone': 99.8958402281767, 'ACC-Forrest': nan, 'ACC-Gravel': 94.64032826173789})])
[01/28 11:55:27] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:55:27] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/28 11:55:27] d2.data.common INFO: Serializing 6 elements to byte tensors and concatenating them all ...
[01/28 11:55:27] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/28 11:55:27] d2.data.datasets.coco INFO: Loaded 6 images with semantic segmentation from ../../../data/dataset/train/images
[01/28 11:55:27] d2.evaluation.evaluator INFO: Start inference on 6 batches
[01/28 11:55:27] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.103621 (0.103621 s / iter per device, on 1 devices)
[01/28 11:55:27] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.044870 s / iter per device, on 1 devices)
[01/28 11:55:27] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 97.10633992307703, 'fwIoU': 98.68024960305812, 'IoU-Grass': nan, 'IoU-CameraEdge': 97.94577230762884, 'IoU-Vehicle': 96.25564588979223, 'IoU-Person': nan, 'IoU-Bush': 97.23855728707242, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 98.60127263132257, 'IoU-Large_stone': 99.29138205021928, 'IoU-Forrest': nan, 'IoU-Gravel': 93.30540937242688, 'mACC': 98.03642599246473, 'pACC': 99.33526817674851, 'ACC-Grass': nan, 'ACC-CameraEdge': 98.58895426914319, 'ACC-Vehicle': 97.22393302766943, 'ACC-Person': nan, 'ACC-Bush': 98.56199086032188, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 99.30750930773928, 'ACC-Large_stone': 99.8958402281767, 'ACC-Forrest': nan, 'ACC-Gravel': 94.64032826173789})])
[01/29 14:37:44] detectron2 INFO: Rank of current process: 0. World size: 1
[01/29 14:37:44] detectron2 INFO: Environment info:
----------------------  ------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]
numpy                   1.20.3
detectron2              0.6 @/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 9.3
CUDA compiler           CUDA 11.4
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.1+cu102 @/usr/local/lib/python3.8/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   GRID RTX8000-8Q (arch=7.5)
Driver version          470.63.01
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.1+cu102 @/usr/local/lib/python3.8/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.4
----------------------  ------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/29 14:37:44] detectron2 INFO: Command line arguments: Namespace(config_file='', dist_url='tcp://127.0.0.1:54076', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/29 14:37:44] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m  [39m-[38;5;15m [39mffi_train_stuffonly
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mabsolute
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39mmask_former_semantic
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mbitmask
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m256
[38;5;15m  [39m-[38;5;15m [39m307
[38;5;15m  [39m-[38;5;15m [39m358
[38;5;15m  [39m-[38;5;15m [39m409
[38;5;15m  [39m-[38;5;15m [39m460
[38;5;15m  [39m-[38;5;15m [39m512
[38;5;15m  [39m-[38;5;15m [39m563
[38;5;15m  [39m-[38;5;15m [39m614
[38;5;15m  [39m-[38;5;15m [39m665
[38;5;15m  [39m-[38;5;15m [39m716
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m819
[38;5;15m  [39m-[38;5;15m [39m870
[38;5;15m  [39m-[38;5;15m [39m921
[38;5;15m  [39m-[38;5;15m [39m972
[38;5;15m  [39m-[38;5;15m [39m1024
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m      [39m-[38;5;15m [39m64
[38;5;15m      [39m-[38;5;15m [39m128
[38;5;15m      [39m-[38;5;15m [39m256
[38;5;15m      [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mD2SwinTransformer
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m6
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m20.0
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m32
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39mres5
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mMaskFormer
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m123.675
[38;5;15m  [39m-[38;5;15m [39m116.28
[38;5;15m  [39m-[38;5;15m [39m103.53
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m58.395
[38;5;15m  [39m-[38;5;15m [39m57.12
[38;5;15m  [39m-[38;5;15m [39m57.375
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39mbasic
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id003[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRes5ROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id003[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m6000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m12000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m18
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39mhard_pixel_mining
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskFormerHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m12
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39mBasePixelDecoder
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m48
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.3
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m96
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m4.0
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m3
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m24
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m224
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m7
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39mmodels/model_final_8657a5.pkl
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m./ffiModel
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.0002
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mfull_model
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupPolyLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m1600
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39mADAMW
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0e-06
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m1500
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m3584
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m384
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m640
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m896
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m400
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[01/29 14:37:44] detectron2 INFO: Full config saved to ./ffiModel/config.yaml
[01/29 14:37:44] d2.utils.env INFO: Using a generated random seed 45303650
[01/29 14:37:49] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): BasePixelDecoder(
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_2): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_3): Conv2d(
        384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_4): Conv2d(
        768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (predictor): TransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList()
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (3): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (4): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (5): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (query_embed): Embedding(100, 256)
      (input_proj): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (class_embed): Linear(in_features=256, out_features=13, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 1.0
  )
)
[01/29 14:37:49] mask_former.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerSemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2048, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[512, 512], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7fe62b5ac3a0>, RandomFlip()]
[01/29 14:37:49] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:37:49] d2.data.build INFO: Using training sampler TrainingSampler
[01/29 14:37:49] d2.data.common INFO: Serializing 3 elements to byte tensors and concatenating them all ...
[01/29 14:37:49] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 14:37:49] fvcore.common.checkpoint INFO: [Checkpointer] Loading from models/model_final_8657a5.pkl ...
[01/29 14:37:49] fvcore.common.checkpoint INFO: Reading a file from 'MaskFormer Model Zoo'
[01/29 14:37:49] mask_former.modeling.heads.mask_former_head WARNING: Weight format of MaskFormerHead have changed! Please upgrade your models. Applying automatic conversion now ...
[01/29 14:37:49] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (151, 256) in the checkpoint but (13, 256) in the model! You might want to double check if this is expected.
[01/29 14:37:49] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/29 14:37:49] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/29 14:37:49] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[01/29 14:37:49] d2.engine.train_loop INFO: Starting training from iteration 0
[01/29 14:37:58] d2.utils.events INFO:  eta: 0:11:30  iter: 19  total_loss: 14.69  loss_ce: 1.892  loss_mask: 0.168  loss_dice: 0.2368  loss_ce_0: 2.131  loss_mask_0: 0.2006  loss_dice_0: 0.2441  loss_ce_1: 2.084  loss_mask_1: 0.16  loss_dice_1: 0.237  loss_ce_2: 2.017  loss_mask_2: 0.1836  loss_dice_2: 0.2436  loss_ce_3: 2.046  loss_mask_3: 0.1719  loss_dice_3: 0.2458  loss_ce_4: 1.998  loss_mask_4: 0.1757  loss_dice_4: 0.2429  time: 0.4378  data_time: 0.0772  lr: 2.5064e-06  max_mem: 4976M
[01/29 14:38:07] d2.utils.events INFO:  eta: 0:11:35  iter: 39  total_loss: 11.74  loss_ce: 1.414  loss_mask: 0.1129  loss_dice: 0.2157  loss_ce_0: 1.789  loss_mask_0: 0.124  loss_dice_0: 0.2215  loss_ce_1: 1.733  loss_mask_1: 0.1108  loss_dice_1: 0.2238  loss_ce_2: 1.668  loss_mask_2: 0.1219  loss_dice_2: 0.2217  loss_ce_3: 1.57  loss_mask_3: 0.1143  loss_dice_3: 0.2221  loss_ce_4: 1.47  loss_mask_4: 0.1121  loss_dice_4: 0.2259  time: 0.4474  data_time: 0.0737  lr: 5.086e-06  max_mem: 4976M
[01/29 14:38:12] d2.engine.hooks INFO: Overall training speed: 48 iterations in 0:00:21 (0.4558 s / it)
[01/29 14:38:12] d2.engine.hooks INFO: Total training time: 0:00:21 (0:00:00 on hooks)
[01/29 14:38:12] d2.utils.events INFO:  eta: 0:11:30  iter: 50  total_loss: 9.766  loss_ce: 1.191  loss_mask: 0.1007  loss_dice: 0.1565  loss_ce_0: 1.514  loss_mask_0: 0.09991  loss_dice_0: 0.157  loss_ce_1: 1.453  loss_mask_1: 0.09713  loss_dice_1: 0.1575  loss_ce_2: 1.389  loss_mask_2: 0.1042  loss_dice_2: 0.1591  loss_ce_3: 1.309  loss_mask_3: 0.1014  loss_dice_3: 0.1551  loss_ce_4: 1.229  loss_mask_4: 0.09466  loss_dice_4: 0.1658  time: 0.4474  data_time: 0.0723  lr: 6.3532e-06  max_mem: 4976M
[01/29 14:38:14] detectron2 INFO: Rank of current process: 0. World size: 1
[01/29 14:38:14] detectron2 INFO: Environment info:
----------------------  ------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]
numpy                   1.20.3
detectron2              0.6 @/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 9.3
CUDA compiler           CUDA 11.4
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.1+cu102 @/usr/local/lib/python3.8/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   GRID RTX8000-8Q (arch=7.5)
Driver version          470.63.01
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.1+cu102 @/usr/local/lib/python3.8/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.4
----------------------  ------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/29 14:38:14] detectron2 INFO: Command line arguments: Namespace(config_file='', dist_url='tcp://127.0.0.1:54076', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/29 14:38:15] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m  [39m-[38;5;15m [39mffi_train_stuffonly
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mabsolute
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39mmask_former_semantic
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mbitmask
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m256
[38;5;15m  [39m-[38;5;15m [39m307
[38;5;15m  [39m-[38;5;15m [39m358
[38;5;15m  [39m-[38;5;15m [39m409
[38;5;15m  [39m-[38;5;15m [39m460
[38;5;15m  [39m-[38;5;15m [39m512
[38;5;15m  [39m-[38;5;15m [39m563
[38;5;15m  [39m-[38;5;15m [39m614
[38;5;15m  [39m-[38;5;15m [39m665
[38;5;15m  [39m-[38;5;15m [39m716
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m819
[38;5;15m  [39m-[38;5;15m [39m870
[38;5;15m  [39m-[38;5;15m [39m921
[38;5;15m  [39m-[38;5;15m [39m972
[38;5;15m  [39m-[38;5;15m [39m1024
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m      [39m-[38;5;15m [39m64
[38;5;15m      [39m-[38;5;15m [39m128
[38;5;15m      [39m-[38;5;15m [39m256
[38;5;15m      [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mD2SwinTransformer
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m6
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m20.0
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m32
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39mres5
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mMaskFormer
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m123.675
[38;5;15m  [39m-[38;5;15m [39m116.28
[38;5;15m  [39m-[38;5;15m [39m103.53
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m58.395
[38;5;15m  [39m-[38;5;15m [39m57.12
[38;5;15m  [39m-[38;5;15m [39m57.375
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39mbasic
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id003[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRes5ROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id003[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m6000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m12000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m18
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39mhard_pixel_mining
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskFormerHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m12
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39mBasePixelDecoder
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m48
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.3
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m96
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m4.0
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m3
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m24
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m224
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m7
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39mmodels/model_final_8657a5.pkl
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m./ffiModel
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.0002
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mfull_model
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupPolyLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m160
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39mADAMW
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0e-06
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m1500
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m3584
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m384
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m640
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m896
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m40
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[01/29 14:38:15] detectron2 INFO: Full config saved to ./ffiModel/config.yaml
[01/29 14:38:15] d2.utils.env INFO: Using a generated random seed 15541757
[01/29 14:38:19] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): BasePixelDecoder(
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_2): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_3): Conv2d(
        384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_4): Conv2d(
        768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (predictor): TransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList()
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (3): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (4): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (5): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (query_embed): Embedding(100, 256)
      (input_proj): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (class_embed): Linear(in_features=256, out_features=13, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 1.0
  )
)
[01/29 14:38:19] mask_former.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerSemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2048, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[512, 512], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f79f5226310>, RandomFlip()]
[01/29 14:38:19] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:38:19] d2.data.build INFO: Using training sampler TrainingSampler
[01/29 14:38:19] d2.data.common INFO: Serializing 3 elements to byte tensors and concatenating them all ...
[01/29 14:38:19] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 14:38:19] fvcore.common.checkpoint INFO: [Checkpointer] Loading from models/model_final_8657a5.pkl ...
[01/29 14:38:19] fvcore.common.checkpoint INFO: Reading a file from 'MaskFormer Model Zoo'
[01/29 14:38:19] mask_former.modeling.heads.mask_former_head WARNING: Weight format of MaskFormerHead have changed! Please upgrade your models. Applying automatic conversion now ...
[01/29 14:38:19] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (151, 256) in the checkpoint but (13, 256) in the model! You might want to double check if this is expected.
[01/29 14:38:19] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/29 14:38:19] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/29 14:38:19] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[01/29 14:38:19] d2.engine.train_loop INFO: Starting training from iteration 0
[01/29 14:38:28] d2.utils.events INFO:  eta: 0:01:01  iter: 19  total_loss: 15.41  loss_ce: 2.183  loss_mask: 0.1558  loss_dice: 0.2481  loss_ce_0: 2.152  loss_mask_0: 0.1715  loss_dice_0: 0.2336  loss_ce_1: 2.128  loss_mask_1: 0.1451  loss_dice_1: 0.2363  loss_ce_2: 2.153  loss_mask_2: 0.1618  loss_dice_2: 0.2382  loss_ce_3: 2.036  loss_mask_3: 0.1499  loss_dice_3: 0.2465  loss_ce_4: 1.981  loss_mask_4: 0.1716  loss_dice_4: 0.25  time: 0.4387  data_time: 0.0782  lr: 2.2611e-06  max_mem: 4913M
[01/29 14:38:37] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:38:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/29 14:38:37] d2.data.common INFO: Serializing 3 elements to byte tensors and concatenating them all ...
[01/29 14:38:37] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 14:38:37] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:38:37] d2.evaluation.evaluator INFO: Start inference on 3 batches
[01/29 14:38:37] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.094840 (0.094840 s / iter per device, on 1 devices)
[01/29 14:38:37] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.044275 s / iter per device, on 1 devices)
[01/29 14:38:37] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 5.431678533823111, 'fwIoU': 10.603255207632984, 'IoU-Grass': nan, 'IoU-CameraEdge': nan, 'IoU-Vehicle': 0.0, 'IoU-Person': nan, 'IoU-Bush': 0.0, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 0.0, 'IoU-Large_stone': 32.59007120293867, 'IoU-Forrest': nan, 'IoU-Gravel': 0.0, 'mACC': 20.0, 'pACC': 32.53523179377676, 'ACC-Grass': nan, 'ACC-CameraEdge': nan, 'ACC-Vehicle': 0.0, 'ACC-Person': nan, 'ACC-Bush': 0.0, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 0.0, 'ACC-Large_stone': 100.0, 'ACC-Forrest': nan, 'ACC-Gravel': 0.0})])
[01/29 14:38:37] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:38:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/29 14:38:37] d2.data.common INFO: Serializing 3 elements to byte tensors and concatenating them all ...
[01/29 14:38:37] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 14:38:37] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:38:37] d2.evaluation.evaluator INFO: Start inference on 3 batches
[01/29 14:38:38] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.102178 (0.102178 s / iter per device, on 1 devices)
[01/29 14:38:38] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.050665 s / iter per device, on 1 devices)
[01/29 14:38:38] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 5.431678533823111, 'fwIoU': 10.603255207632984, 'IoU-Grass': nan, 'IoU-CameraEdge': nan, 'IoU-Vehicle': 0.0, 'IoU-Person': nan, 'IoU-Bush': 0.0, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 0.0, 'IoU-Large_stone': 32.59007120293867, 'IoU-Forrest': nan, 'IoU-Gravel': 0.0, 'mACC': 20.0, 'pACC': 32.53523179377676, 'ACC-Grass': nan, 'ACC-CameraEdge': nan, 'ACC-Vehicle': 0.0, 'ACC-Person': nan, 'ACC-Bush': 0.0, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 0.0, 'ACC-Large_stone': 100.0, 'ACC-Forrest': nan, 'ACC-Gravel': 0.0})])
[01/29 14:38:38] d2.utils.events INFO:  eta: 0:00:52  iter: 39  total_loss: 12.31  loss_ce: 1.627  loss_mask: 0.1473  loss_dice: 0.2023  loss_ce_0: 1.755  loss_mask_0: 0.1589  loss_dice_0: 0.204  loss_ce_1: 1.745  loss_mask_1: 0.1497  loss_dice_1: 0.2001  loss_ce_2: 1.727  loss_mask_2: 0.1741  loss_dice_2: 0.188  loss_ce_3: 1.575  loss_mask_3: 0.1529  loss_dice_3: 0.212  loss_ce_4: 1.534  loss_mask_4: 0.1362  loss_dice_4: 0.2041  time: 0.4414  data_time: 0.0733  lr: 4.0441e-06  max_mem: 4967M
[01/29 14:38:46] d2.utils.events INFO:  eta: 0:00:43  iter: 59  total_loss: 9.181  loss_ce: 1.174  loss_mask: 0.09683  loss_dice: 0.2092  loss_ce_0: 1.333  loss_mask_0: 0.1209  loss_dice_0: 0.193  loss_ce_1: 1.292  loss_mask_1: 0.1083  loss_dice_1: 0.1822  loss_ce_2: 1.24  loss_mask_2: 0.1067  loss_dice_2: 0.1947  loss_ce_3: 1.174  loss_mask_3: 0.1045  loss_dice_3: 0.1994  loss_ce_4: 1.147  loss_mask_4: 0.107  loss_dice_4: 0.1997  time: 0.4401  data_time: 0.0723  lr: 5.1998e-06  max_mem: 4967M
[01/29 14:38:55] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:38:55] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/29 14:38:55] d2.data.common INFO: Serializing 3 elements to byte tensors and concatenating them all ...
[01/29 14:38:55] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 14:38:55] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:38:55] d2.evaluation.evaluator INFO: Start inference on 3 batches
[01/29 14:38:56] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.105147 (0.105147 s / iter per device, on 1 devices)
[01/29 14:38:56] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.052770 s / iter per device, on 1 devices)
[01/29 14:38:56] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 6.5070463587553515, 'fwIoU': 10.58541307874782, 'IoU-Grass': nan, 'IoU-CameraEdge': nan, 'IoU-Vehicle': 0.0, 'IoU-Person': nan, 'IoU-Bush': 0.0, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 0.0, 'IoU-Large_stone': 32.53523179377676, 'IoU-Forrest': nan, 'IoU-Gravel': 0.0, 'mACC': 20.0, 'pACC': 32.53523179377676, 'ACC-Grass': nan, 'ACC-CameraEdge': nan, 'ACC-Vehicle': 0.0, 'ACC-Person': nan, 'ACC-Bush': 0.0, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 0.0, 'ACC-Large_stone': 100.0, 'ACC-Forrest': nan, 'ACC-Gravel': 0.0})])
[01/29 14:38:56] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:38:56] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/29 14:38:56] d2.data.common INFO: Serializing 3 elements to byte tensors and concatenating them all ...
[01/29 14:38:56] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 14:38:56] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:38:56] d2.evaluation.evaluator INFO: Start inference on 3 batches
[01/29 14:38:56] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.099980 (0.099980 s / iter per device, on 1 devices)
[01/29 14:38:56] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.045043 s / iter per device, on 1 devices)
[01/29 14:38:56] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 6.5070463587553515, 'fwIoU': 10.58541307874782, 'IoU-Grass': nan, 'IoU-CameraEdge': nan, 'IoU-Vehicle': 0.0, 'IoU-Person': nan, 'IoU-Bush': 0.0, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 0.0, 'IoU-Large_stone': 32.53523179377676, 'IoU-Forrest': nan, 'IoU-Gravel': 0.0, 'mACC': 20.0, 'pACC': 32.53523179377676, 'ACC-Grass': nan, 'ACC-CameraEdge': nan, 'ACC-Vehicle': 0.0, 'ACC-Person': nan, 'ACC-Bush': 0.0, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 0.0, 'ACC-Large_stone': 100.0, 'ACC-Forrest': nan, 'ACC-Gravel': 0.0})])
[01/29 14:38:56] d2.utils.events INFO:  eta: 0:00:35  iter: 79  total_loss: 7.339  loss_ce: 0.9678  loss_mask: 0.06569  loss_dice: 0.1189  loss_ce_0: 1.13  loss_mask_0: 0.07803  loss_dice_0: 0.1307  loss_ce_1: 1.089  loss_mask_1: 0.07233  loss_dice_1: 0.1287  loss_ce_2: 1.048  loss_mask_2: 0.06852  loss_dice_2: 0.1183  loss_ce_3: 0.9735  loss_mask_3: 0.06763  loss_dice_3: 0.1205  loss_ce_4: 0.9602  loss_mask_4: 0.06363  loss_dice_4: 0.1178  time: 0.4406  data_time: 0.0734  lr: 5.7082e-06  max_mem: 4967M
[01/29 14:39:05] d2.utils.events INFO:  eta: 0:00:26  iter: 99  total_loss: 6.434  loss_ce: 0.8101  loss_mask: 0.06043  loss_dice: 0.09441  loss_ce_0: 1.034  loss_mask_0: 0.05679  loss_dice_0: 0.09483  loss_ce_1: 0.9798  loss_mask_1: 0.0596  loss_dice_1: 0.08738  loss_ce_2: 0.9203  loss_mask_2: 0.0615  loss_dice_2: 0.08302  loss_ce_3: 0.8667  loss_mask_3: 0.06151  loss_dice_3: 0.09418  loss_ce_4: 0.8402  loss_mask_4: 0.0633  loss_dice_4: 0.09019  time: 0.4408  data_time: 0.0706  lr: 5.542e-06  max_mem: 4967M
[01/29 14:39:14] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:39:14] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/29 14:39:14] d2.data.common INFO: Serializing 3 elements to byte tensors and concatenating them all ...
[01/29 14:39:14] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 14:39:14] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:39:14] d2.evaluation.evaluator INFO: Start inference on 3 batches
[01/29 14:39:14] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.102136 (0.102136 s / iter per device, on 1 devices)
[01/29 14:39:14] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.046250 s / iter per device, on 1 devices)
[01/29 14:39:14] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 73.65715787121154, 'fwIoU': 93.95021033802836, 'IoU-Grass': nan, 'IoU-CameraEdge': nan, 'IoU-Vehicle': 89.34670991858043, 'IoU-Person': nan, 'IoU-Bush': 0.0, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 88.27790809990341, 'IoU-Large_stone': 95.85806585628256, 'IoU-Forrest': nan, 'IoU-Gravel': 94.80310548129123, 'mACC': 76.20581147053855, 'pACC': 96.88658222549503, 'ACC-Grass': nan, 'ACC-CameraEdge': nan, 'ACC-Vehicle': 96.0463719920558, 'ACC-Person': nan, 'ACC-Bush': 0.0, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 88.9829828437535, 'ACC-Large_stone': 96.52388742099521, 'ACC-Forrest': nan, 'ACC-Gravel': 99.47581509588824})])
[01/29 14:39:14] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:39:14] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/29 14:39:14] d2.data.common INFO: Serializing 3 elements to byte tensors and concatenating them all ...
[01/29 14:39:14] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 14:39:14] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:39:14] d2.evaluation.evaluator INFO: Start inference on 3 batches
[01/29 14:39:14] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.102645 (0.102645 s / iter per device, on 1 devices)
[01/29 14:39:14] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.046718 s / iter per device, on 1 devices)
[01/29 14:39:14] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 73.65715787121154, 'fwIoU': 93.95021033802836, 'IoU-Grass': nan, 'IoU-CameraEdge': nan, 'IoU-Vehicle': 89.34670991858043, 'IoU-Person': nan, 'IoU-Bush': 0.0, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 88.27790809990341, 'IoU-Large_stone': 95.85806585628256, 'IoU-Forrest': nan, 'IoU-Gravel': 94.80310548129123, 'mACC': 76.20581147053855, 'pACC': 96.88658222549503, 'ACC-Grass': nan, 'ACC-CameraEdge': nan, 'ACC-Vehicle': 96.0463719920558, 'ACC-Person': nan, 'ACC-Bush': 0.0, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 88.9829828437535, 'ACC-Large_stone': 96.52388742099521, 'ACC-Forrest': nan, 'ACC-Gravel': 99.47581509588824})])
[01/29 14:39:14] d2.utils.events INFO:  eta: 0:00:17  iter: 119  total_loss: 5.299  loss_ce: 0.61  loss_mask: 0.06423  loss_dice: 0.08324  loss_ce_0: 0.8422  loss_mask_0: 0.06176  loss_dice_0: 0.09433  loss_ce_1: 0.8295  loss_mask_1: 0.05744  loss_dice_1: 0.0783  loss_ce_2: 0.7393  loss_mask_2: 0.05639  loss_dice_2: 0.07711  loss_ce_3: 0.6716  loss_mask_3: 0.05607  loss_dice_3: 0.07903  loss_ce_4: 0.6482  loss_mask_4: 0.06035  loss_dice_4: 0.07938  time: 0.4412  data_time: 0.0719  lr: 4.659e-06  max_mem: 5026M
[01/29 14:39:23] d2.utils.events INFO:  eta: 0:00:08  iter: 139  total_loss: 4.405  loss_ce: 0.478  loss_mask: 0.05246  loss_dice: 0.08599  loss_ce_0: 0.7468  loss_mask_0: 0.05055  loss_dice_0: 0.08184  loss_ce_1: 0.6932  loss_mask_1: 0.05055  loss_dice_1: 0.07834  loss_ce_2: 0.6064  loss_mask_2: 0.05378  loss_dice_2: 0.08537  loss_ce_3: 0.5391  loss_mask_3: 0.05059  loss_dice_3: 0.08365  loss_ce_4: 0.5083  loss_mask_4: 0.05269  loss_dice_4: 0.08589  time: 0.4417  data_time: 0.0699  lr: 2.9802e-06  max_mem: 5026M
[01/29 14:39:32] fvcore.common.checkpoint INFO: Saving checkpoint to ./ffiModel/model_final.pth
[01/29 14:39:34] d2.utils.events INFO:  eta: 0:00:00  iter: 159  total_loss: 4.42  loss_ce: 0.4649  loss_mask: 0.05048  loss_dice: 0.08091  loss_ce_0: 0.7504  loss_mask_0: 0.05106  loss_dice_0: 0.09169  loss_ce_1: 0.6742  loss_mask_1: 0.04915  loss_dice_1: 0.07791  loss_ce_2: 0.5962  loss_mask_2: 0.05627  loss_dice_2: 0.07031  loss_ce_3: 0.5485  loss_mask_3: 0.04981  loss_dice_3: 0.0749  loss_ce_4: 0.4935  loss_mask_4: 0.04899  loss_dice_4: 0.07294  time: 0.4432  data_time: 0.0716  lr: 2.2011e-07  max_mem: 5026M
[01/29 14:39:34] d2.engine.hooks INFO: Overall training speed: 158 iterations in 0:01:10 (0.4433 s / it)
[01/29 14:39:34] d2.engine.hooks INFO: Total training time: 0:01:14 (0:00:04 on hooks)
[01/29 14:39:34] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:39:34] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/29 14:39:34] d2.data.common INFO: Serializing 3 elements to byte tensors and concatenating them all ...
[01/29 14:39:34] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 14:39:34] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:39:34] d2.evaluation.evaluator INFO: Start inference on 3 batches
[01/29 14:39:35] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.105671 (0.105671 s / iter per device, on 1 devices)
[01/29 14:39:35] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.048657 s / iter per device, on 1 devices)
[01/29 14:39:35] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 75.67650163597538, 'fwIoU': 95.36041932477046, 'IoU-Grass': nan, 'IoU-CameraEdge': nan, 'IoU-Vehicle': 93.21624342767647, 'IoU-Person': nan, 'IoU-Bush': 0.0, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 92.88191585707229, 'IoU-Large_stone': 96.36412139472115, 'IoU-Forrest': nan, 'IoU-Gravel': 95.92022750040702, 'mACC': 77.71945245753017, 'pACC': 97.62373580600573, 'ACC-Grass': nan, 'ACC-CameraEdge': nan, 'ACC-Vehicle': 96.21495542931042, 'ACC-Person': nan, 'ACC-Bush': 0.0, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 96.56233115246965, 'ACC-Large_stone': 96.94123404364478, 'ACC-Forrest': nan, 'ACC-Gravel': 98.87874166222598})])
[01/29 14:39:35] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:39:35] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/29 14:39:35] d2.data.common INFO: Serializing 3 elements to byte tensors and concatenating them all ...
[01/29 14:39:35] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 14:39:35] d2.data.datasets.coco INFO: Loaded 3 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 14:39:35] d2.evaluation.evaluator INFO: Start inference on 3 batches
[01/29 14:39:35] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.104821 (0.104821 s / iter per device, on 1 devices)
[01/29 14:39:35] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.048949 s / iter per device, on 1 devices)
[01/29 14:39:35] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 75.67650163597538, 'fwIoU': 95.36041932477046, 'IoU-Grass': nan, 'IoU-CameraEdge': nan, 'IoU-Vehicle': 93.21624342767647, 'IoU-Person': nan, 'IoU-Bush': 0.0, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 92.88191585707229, 'IoU-Large_stone': 96.36412139472115, 'IoU-Forrest': nan, 'IoU-Gravel': 95.92022750040702, 'mACC': 77.71945245753017, 'pACC': 97.62373580600573, 'ACC-Grass': nan, 'ACC-CameraEdge': nan, 'ACC-Vehicle': 96.21495542931042, 'ACC-Person': nan, 'ACC-Bush': 0.0, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 96.56233115246965, 'ACC-Large_stone': 96.94123404364478, 'ACC-Forrest': nan, 'ACC-Gravel': 98.87874166222598})])
[01/29 15:01:49] detectron2 INFO: Rank of current process: 0. World size: 1
[01/29 15:01:50] detectron2 INFO: Environment info:
----------------------  ------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]
numpy                   1.20.3
detectron2              0.6 @/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 9.3
CUDA compiler           CUDA 11.4
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.1+cu102 @/usr/local/lib/python3.8/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   GRID RTX8000-8Q (arch=7.5)
Driver version          470.63.01
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.1+cu102 @/usr/local/lib/python3.8/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.4
----------------------  ------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/29 15:01:50] detectron2 INFO: Command line arguments: Namespace(config_file='', dist_url='tcp://127.0.0.1:54076', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/29 15:01:50] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m  [39m-[38;5;15m [39mffi_train_stuffonly
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mabsolute
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39mmask_former_semantic
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mbitmask
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m256
[38;5;15m  [39m-[38;5;15m [39m307
[38;5;15m  [39m-[38;5;15m [39m358
[38;5;15m  [39m-[38;5;15m [39m409
[38;5;15m  [39m-[38;5;15m [39m460
[38;5;15m  [39m-[38;5;15m [39m512
[38;5;15m  [39m-[38;5;15m [39m563
[38;5;15m  [39m-[38;5;15m [39m614
[38;5;15m  [39m-[38;5;15m [39m665
[38;5;15m  [39m-[38;5;15m [39m716
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m819
[38;5;15m  [39m-[38;5;15m [39m870
[38;5;15m  [39m-[38;5;15m [39m921
[38;5;15m  [39m-[38;5;15m [39m972
[38;5;15m  [39m-[38;5;15m [39m1024
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m      [39m-[38;5;15m [39m64
[38;5;15m      [39m-[38;5;15m [39m128
[38;5;15m      [39m-[38;5;15m [39m256
[38;5;15m      [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mD2SwinTransformer
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m6
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m20.0
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m32
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39mres5
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mMaskFormer
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m123.675
[38;5;15m  [39m-[38;5;15m [39m116.28
[38;5;15m  [39m-[38;5;15m [39m103.53
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m58.395
[38;5;15m  [39m-[38;5;15m [39m57.12
[38;5;15m  [39m-[38;5;15m [39m57.375
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39mbasic
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id003[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRes5ROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id003[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m6000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m12000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m18
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39mhard_pixel_mining
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskFormerHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m12
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39mBasePixelDecoder
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m48
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.3
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m96
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m4.0
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m3
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m24
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m224
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m7
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39mmodels/model_final_8657a5.pkl
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m./ffiModel
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.0002
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mfull_model
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupPolyLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m1600
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39mADAMW
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0e-06
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m1500
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m3584
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m384
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m640
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m896
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m400
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[01/29 15:01:50] detectron2 INFO: Full config saved to ./ffiModel/config.yaml
[01/29 15:01:50] d2.utils.env INFO: Using a generated random seed 50991418
[01/29 15:01:55] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): BasePixelDecoder(
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_2): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_3): Conv2d(
        384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_4): Conv2d(
        768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (predictor): TransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList()
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (3): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (4): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (5): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (query_embed): Embedding(100, 256)
      (input_proj): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (class_embed): Linear(in_features=256, out_features=13, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 1.0
  )
)
[01/29 15:01:55] mask_former.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerSemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2048, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[512, 512], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f5b35e83130>, RandomFlip()]
[01/29 15:01:55] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:01:55] d2.data.build INFO: Using training sampler TrainingSampler
[01/29 15:01:55] d2.data.common INFO: Serializing 9 elements to byte tensors and concatenating them all ...
[01/29 15:01:55] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 15:01:55] fvcore.common.checkpoint INFO: [Checkpointer] Loading from models/model_final_8657a5.pkl ...
[01/29 15:01:55] fvcore.common.checkpoint INFO: Reading a file from 'MaskFormer Model Zoo'
[01/29 15:01:55] mask_former.modeling.heads.mask_former_head WARNING: Weight format of MaskFormerHead have changed! Please upgrade your models. Applying automatic conversion now ...
[01/29 15:01:55] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (151, 256) in the checkpoint but (13, 256) in the model! You might want to double check if this is expected.
[01/29 15:01:55] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/29 15:01:55] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/29 15:01:55] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[01/29 15:01:55] d2.engine.train_loop INFO: Starting training from iteration 0
[01/29 15:01:56] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/asbjotof/2022/masterToft/LiDARsegmentation/maskFormer/train/mask_former/mask_former_model.py", line 180, in forward
    losses = self.criterion(outputs, targets)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/asbjotof/2022/masterToft/LiDARsegmentation/maskFormer/train/mask_former/modeling/criterion.py", line 183, in forward
    l_dict = self.get_loss(loss, aux_outputs, targets, indices, num_masks)
  File "/work/asbjotof/2022/masterToft/LiDARsegmentation/maskFormer/train/mask_former/modeling/criterion.py", line 150, in get_loss
    return loss_map[loss](outputs, targets, indices, num_masks)
  File "/work/asbjotof/2022/masterToft/LiDARsegmentation/maskFormer/train/mask_former/modeling/criterion.py", line 130, in loss_masks
    "loss_mask": sigmoid_focal_loss(src_masks, target_masks, num_masks),
  File "/work/asbjotof/2022/masterToft/LiDARsegmentation/maskFormer/train/mask_former/modeling/criterion.py", line 49, in sigmoid_focal_loss
    prob = inputs.sigmoid()
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 8.00 GiB total capacity; 4.77 GiB already allocated; 32.40 MiB free; 4.88 GiB reserved in total by PyTorch)
[01/29 15:01:56] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[01/29 15:01:56] d2.utils.events INFO:  iter: 1  total_loss: 19.26  loss_ce: 2.537  loss_mask: 0.2369  loss_dice: 0.3966  loss_ce_0: 2.925  loss_mask_0: 0.1806  loss_dice_0: 0.4087  loss_ce_1: 2.608  loss_mask_1: 0.2341  loss_dice_1: 0.4154  loss_ce_2: 2.537  loss_mask_2: 0.2282  loss_dice_2: 0.4116  loss_ce_3: 2.389  loss_mask_3: 0.1918  loss_dice_3: 0.4124  loss_ce_4: 2.544  loss_mask_4: 0.196  loss_dice_4: 0.4096  data_time: 0.1765  lr: 2e-10  max_mem: 4911M
[01/29 15:02:11] detectron2 INFO: Rank of current process: 0. World size: 1
[01/29 15:02:12] detectron2 INFO: Environment info:
----------------------  ------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]
numpy                   1.20.3
detectron2              0.6 @/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 9.3
CUDA compiler           CUDA 11.4
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.1+cu102 @/usr/local/lib/python3.8/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   GRID RTX8000-8Q (arch=7.5)
Driver version          470.63.01
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.1+cu102 @/usr/local/lib/python3.8/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.4
----------------------  ------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/29 15:02:12] detectron2 INFO: Command line arguments: Namespace(config_file='', dist_url='tcp://127.0.0.1:54076', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/29 15:02:12] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m  [39m-[38;5;15m [39mffi_train_stuffonly
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mabsolute
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39mmask_former_semantic
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mbitmask
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m256
[38;5;15m  [39m-[38;5;15m [39m307
[38;5;15m  [39m-[38;5;15m [39m358
[38;5;15m  [39m-[38;5;15m [39m409
[38;5;15m  [39m-[38;5;15m [39m460
[38;5;15m  [39m-[38;5;15m [39m512
[38;5;15m  [39m-[38;5;15m [39m563
[38;5;15m  [39m-[38;5;15m [39m614
[38;5;15m  [39m-[38;5;15m [39m665
[38;5;15m  [39m-[38;5;15m [39m716
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m819
[38;5;15m  [39m-[38;5;15m [39m870
[38;5;15m  [39m-[38;5;15m [39m921
[38;5;15m  [39m-[38;5;15m [39m972
[38;5;15m  [39m-[38;5;15m [39m1024
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m      [39m-[38;5;15m [39m64
[38;5;15m      [39m-[38;5;15m [39m128
[38;5;15m      [39m-[38;5;15m [39m256
[38;5;15m      [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mD2SwinTransformer
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m6
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m20.0
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m32
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39mres5
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mMaskFormer
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m123.675
[38;5;15m  [39m-[38;5;15m [39m116.28
[38;5;15m  [39m-[38;5;15m [39m103.53
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m58.395
[38;5;15m  [39m-[38;5;15m [39m57.12
[38;5;15m  [39m-[38;5;15m [39m57.375
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39mbasic
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id003[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRes5ROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id003[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m6000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m12000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m18
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39mhard_pixel_mining
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskFormerHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m12
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39mBasePixelDecoder
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m48
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.3
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m96
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m4.0
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m3
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m24
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m224
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m7
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39mmodels/model_final_8657a5.pkl
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m./ffiModel
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.0002
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mfull_model
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupPolyLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m1600
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39mADAMW
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0e-06
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m1500
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m3584
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m384
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m640
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m896
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m400
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[01/29 15:02:12] detectron2 INFO: Full config saved to ./ffiModel/config.yaml
[01/29 15:02:12] d2.utils.env INFO: Using a generated random seed 12918833
[01/29 15:02:16] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): BasePixelDecoder(
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_2): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_3): Conv2d(
        384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_4): Conv2d(
        768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (predictor): TransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList()
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (3): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (4): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (5): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (query_embed): Embedding(100, 256)
      (input_proj): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (class_embed): Linear(in_features=256, out_features=13, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 1.0
  )
)
[01/29 15:02:16] mask_former.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerSemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2048, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[512, 512], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f136eadb0a0>, RandomFlip()]
[01/29 15:02:16] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:02:16] d2.data.build INFO: Using training sampler TrainingSampler
[01/29 15:02:16] d2.data.common INFO: Serializing 9 elements to byte tensors and concatenating them all ...
[01/29 15:02:16] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 15:02:16] fvcore.common.checkpoint INFO: [Checkpointer] Loading from models/model_final_8657a5.pkl ...
[01/29 15:02:16] fvcore.common.checkpoint INFO: Reading a file from 'MaskFormer Model Zoo'
[01/29 15:02:16] mask_former.modeling.heads.mask_former_head WARNING: Weight format of MaskFormerHead have changed! Please upgrade your models. Applying automatic conversion now ...
[01/29 15:02:16] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (151, 256) in the checkpoint but (13, 256) in the model! You might want to double check if this is expected.
[01/29 15:02:16] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/29 15:02:16] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/29 15:02:16] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[01/29 15:02:16] d2.engine.train_loop INFO: Starting training from iteration 0
[01/29 15:02:17] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 273, in run_step
    loss_dict = self.model(data)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/asbjotof/2022/masterToft/LiDARsegmentation/maskFormer/train/mask_former/mask_former_model.py", line 180, in forward
    losses = self.criterion(outputs, targets)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/work/asbjotof/2022/masterToft/LiDARsegmentation/maskFormer/train/mask_former/modeling/criterion.py", line 183, in forward
    l_dict = self.get_loss(loss, aux_outputs, targets, indices, num_masks)
  File "/work/asbjotof/2022/masterToft/LiDARsegmentation/maskFormer/train/mask_former/modeling/criterion.py", line 150, in get_loss
    return loss_map[loss](outputs, targets, indices, num_masks)
  File "/work/asbjotof/2022/masterToft/LiDARsegmentation/maskFormer/train/mask_former/modeling/criterion.py", line 130, in loss_masks
    "loss_mask": sigmoid_focal_loss(src_masks, target_masks, num_masks),
  File "/work/asbjotof/2022/masterToft/LiDARsegmentation/maskFormer/train/mask_former/modeling/criterion.py", line 50, in sigmoid_focal_loss
    ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction="none")
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py", line 2960, in binary_cross_entropy_with_logits
    return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)
RuntimeError: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 8.00 GiB total capacity; 4.85 GiB already allocated; 40.27 MiB free; 4.91 GiB reserved in total by PyTorch)
[01/29 15:02:17] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[01/29 15:02:17] d2.utils.events INFO:  iter: 1  total_loss: 17.53  loss_ce: 2.527  loss_mask: 0.1844  loss_dice: 0.2793  loss_ce_0: 2.406  loss_mask_0: 0.1544  loss_dice_0: 0.2667  loss_ce_1: 2.444  loss_mask_1: 0.1564  loss_dice_1: 0.2828  loss_ce_2: 2.491  loss_mask_2: 0.192  loss_dice_2: 0.2791  loss_ce_3: 2.439  loss_mask_3: 0.1724  loss_dice_3: 0.2849  loss_ce_4: 2.527  loss_mask_4: 0.1669  loss_dice_4: 0.2744  data_time: 0.1753  lr: 2e-10  max_mem: 4963M
[01/29 15:02:24] detectron2 INFO: Rank of current process: 0. World size: 1
[01/29 15:02:24] detectron2 INFO: Environment info:
----------------------  ------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]
numpy                   1.20.3
detectron2              0.6 @/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 9.3
CUDA compiler           CUDA 11.4
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.1+cu102 @/usr/local/lib/python3.8/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   GRID RTX8000-8Q (arch=7.5)
Driver version          470.63.01
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.1+cu102 @/usr/local/lib/python3.8/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.4
----------------------  ------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/29 15:02:24] detectron2 INFO: Command line arguments: Namespace(config_file='', dist_url='tcp://127.0.0.1:54076', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/29 15:02:24] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m  [39m-[38;5;15m [39mffi_train_stuffonly
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mabsolute
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39mmask_former_semantic
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mbitmask
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m256
[38;5;15m  [39m-[38;5;15m [39m307
[38;5;15m  [39m-[38;5;15m [39m358
[38;5;15m  [39m-[38;5;15m [39m409
[38;5;15m  [39m-[38;5;15m [39m460
[38;5;15m  [39m-[38;5;15m [39m512
[38;5;15m  [39m-[38;5;15m [39m563
[38;5;15m  [39m-[38;5;15m [39m614
[38;5;15m  [39m-[38;5;15m [39m665
[38;5;15m  [39m-[38;5;15m [39m716
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m819
[38;5;15m  [39m-[38;5;15m [39m870
[38;5;15m  [39m-[38;5;15m [39m921
[38;5;15m  [39m-[38;5;15m [39m972
[38;5;15m  [39m-[38;5;15m [39m1024
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m      [39m-[38;5;15m [39m64
[38;5;15m      [39m-[38;5;15m [39m128
[38;5;15m      [39m-[38;5;15m [39m256
[38;5;15m      [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mD2SwinTransformer
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m6
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m20.0
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m32
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39mres5
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mMaskFormer
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m123.675
[38;5;15m  [39m-[38;5;15m [39m116.28
[38;5;15m  [39m-[38;5;15m [39m103.53
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m58.395
[38;5;15m  [39m-[38;5;15m [39m57.12
[38;5;15m  [39m-[38;5;15m [39m57.375
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39mbasic
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id003[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRes5ROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id003[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m6000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m12000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m18
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39mhard_pixel_mining
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskFormerHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m12
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39mBasePixelDecoder
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m48
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.3
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m96
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m4.0
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m3
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m24
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m224
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m7
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39mmodels/model_final_8657a5.pkl
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m./ffiModel
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.0002
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mfull_model
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupPolyLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m1600
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39mADAMW
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0e-06
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m1500
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m3584
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m384
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m640
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m896
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m400
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[01/29 15:02:24] detectron2 INFO: Full config saved to ./ffiModel/config.yaml
[01/29 15:02:24] d2.utils.env INFO: Using a generated random seed 25315725
[01/29 15:02:29] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): BasePixelDecoder(
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_2): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_3): Conv2d(
        384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_4): Conv2d(
        768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (predictor): TransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList()
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (3): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (4): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (5): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (query_embed): Embedding(100, 256)
      (input_proj): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (class_embed): Linear(in_features=256, out_features=13, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 1.0
  )
)
[01/29 15:02:29] mask_former.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerSemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2048, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[512, 512], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f041b2340d0>, RandomFlip()]
[01/29 15:02:29] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:02:29] d2.data.build INFO: Using training sampler TrainingSampler
[01/29 15:02:29] d2.data.common INFO: Serializing 9 elements to byte tensors and concatenating them all ...
[01/29 15:02:29] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 15:02:29] fvcore.common.checkpoint INFO: [Checkpointer] Loading from models/model_final_8657a5.pkl ...
[01/29 15:02:29] fvcore.common.checkpoint INFO: Reading a file from 'MaskFormer Model Zoo'
[01/29 15:02:29] mask_former.modeling.heads.mask_former_head WARNING: Weight format of MaskFormerHead have changed! Please upgrade your models. Applying automatic conversion now ...
[01/29 15:02:29] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (151, 256) in the checkpoint but (13, 256) in the model! You might want to double check if this is expected.
[01/29 15:02:29] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/29 15:02:29] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/29 15:02:29] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[01/29 15:02:29] d2.engine.train_loop INFO: Starting training from iteration 0
[01/29 15:02:38] d2.utils.events INFO:  eta: 0:11:22  iter: 19  total_loss: 19.89  loss_ce: 2.739  loss_mask: 0.1807  loss_dice: 0.3405  loss_ce_0: 2.601  loss_mask_0: 0.1948  loss_dice_0: 0.3331  loss_ce_1: 2.852  loss_mask_1: 0.1831  loss_dice_1: 0.3366  loss_ce_2: 2.934  loss_mask_2: 0.1826  loss_dice_2: 0.3367  loss_ce_3: 2.87  loss_mask_3: 0.1748  loss_dice_3: 0.3384  loss_ce_4: 2.86  loss_mask_4: 0.1901  loss_dice_4: 0.3347  time: 0.4338  data_time: 0.0764  lr: 2.5064e-06  max_mem: 5276M
[01/29 15:02:47] d2.utils.events INFO:  eta: 0:11:24  iter: 39  total_loss: 15.89  loss_ce: 1.949  loss_mask: 0.1527  loss_dice: 0.3051  loss_ce_0: 2.203  loss_mask_0: 0.1549  loss_dice_0: 0.2991  loss_ce_1: 2.379  loss_mask_1: 0.1577  loss_dice_1: 0.2771  loss_ce_2: 2.291  loss_mask_2: 0.158  loss_dice_2: 0.3014  loss_ce_3: 2.142  loss_mask_3: 0.1449  loss_dice_3: 0.3084  loss_ce_4: 2.099  loss_mask_4: 0.153  loss_dice_4: 0.3035  time: 0.4391  data_time: 0.0748  lr: 5.086e-06  max_mem: 5315M
[01/29 15:02:56] d2.utils.events INFO:  eta: 0:11:20  iter: 59  total_loss: 11.04  loss_ce: 1.314  loss_mask: 0.122  loss_dice: 0.267  loss_ce_0: 1.649  loss_mask_0: 0.1328  loss_dice_0: 0.2727  loss_ce_1: 1.604  loss_mask_1: 0.1344  loss_dice_1: 0.2632  loss_ce_2: 1.427  loss_mask_2: 0.1306  loss_dice_2: 0.2593  loss_ce_3: 1.362  loss_mask_3: 0.1257  loss_dice_3: 0.273  loss_ce_4: 1.342  loss_mask_4: 0.1221  loss_dice_4: 0.261  time: 0.4411  data_time: 0.0767  lr: 7.6053e-06  max_mem: 5315M
[01/29 15:03:05] d2.utils.events INFO:  eta: 0:11:15  iter: 79  total_loss: 8.955  loss_ce: 1.098  loss_mask: 0.09963  loss_dice: 0.2161  loss_ce_0: 1.189  loss_mask_0: 0.106  loss_dice_0: 0.2306  loss_ce_1: 1.176  loss_mask_1: 0.09922  loss_dice_1: 0.2271  loss_ce_2: 1.153  loss_mask_2: 0.1049  loss_dice_2: 0.2171  loss_ce_3: 1.095  loss_mask_3: 0.09589  loss_dice_3: 0.2187  loss_ce_4: 1.106  loss_mask_4: 0.09335  loss_dice_4: 0.2156  time: 0.4442  data_time: 0.0794  lr: 1.0064e-05  max_mem: 5315M
[01/29 15:03:14] d2.utils.events INFO:  eta: 0:11:07  iter: 99  total_loss: 7.156  loss_ce: 0.8529  loss_mask: 0.08656  loss_dice: 0.1641  loss_ce_0: 1.031  loss_mask_0: 0.09116  loss_dice_0: 0.1748  loss_ce_1: 0.9806  loss_mask_1: 0.09571  loss_dice_1: 0.1628  loss_ce_2: 0.923  loss_mask_2: 0.09383  loss_dice_2: 0.1592  loss_ce_3: 0.8872  loss_mask_3: 0.09231  loss_dice_3: 0.1633  loss_ce_4: 0.8732  loss_mask_4: 0.08726  loss_dice_4: 0.1693  time: 0.4458  data_time: 0.0731  lr: 1.2463e-05  max_mem: 5315M
[01/29 15:03:23] d2.utils.events INFO:  eta: 0:10:58  iter: 119  total_loss: 5.442  loss_ce: 0.6095  loss_mask: 0.07915  loss_dice: 0.1386  loss_ce_0: 0.8341  loss_mask_0: 0.08487  loss_dice_0: 0.1471  loss_ce_1: 0.7495  loss_mask_1: 0.08471  loss_dice_1: 0.1477  loss_ce_2: 0.704  loss_mask_2: 0.08266  loss_dice_2: 0.138  loss_ce_3: 0.6418  loss_mask_3: 0.08295  loss_dice_3: 0.1413  loss_ce_4: 0.6101  loss_mask_4: 0.08517  loss_dice_4: 0.1412  time: 0.4456  data_time: 0.0739  lr: 1.4801e-05  max_mem: 5315M
[01/29 15:03:32] d2.utils.events INFO:  eta: 0:10:50  iter: 139  total_loss: 3.917  loss_ce: 0.3375  loss_mask: 0.07956  loss_dice: 0.1324  loss_ce_0: 0.5835  loss_mask_0: 0.07645  loss_dice_0: 0.1457  loss_ce_1: 0.4892  loss_mask_1: 0.08821  loss_dice_1: 0.1316  loss_ce_2: 0.4274  loss_mask_2: 0.07598  loss_dice_2: 0.1224  loss_ce_3: 0.3724  loss_mask_3: 0.0818  loss_dice_3: 0.128  loss_ce_4: 0.3395  loss_mask_4: 0.07719  loss_dice_4: 0.1286  time: 0.4464  data_time: 0.0775  lr: 1.7078e-05  max_mem: 5315M
[01/29 15:03:41] d2.utils.events INFO:  eta: 0:10:42  iter: 159  total_loss: 2.779  loss_ce: 0.171  loss_mask: 0.07809  loss_dice: 0.1291  loss_ce_0: 0.3791  loss_mask_0: 0.07625  loss_dice_0: 0.1296  loss_ce_1: 0.2722  loss_mask_1: 0.0815  loss_dice_1: 0.1229  loss_ce_2: 0.2209  loss_mask_2: 0.07937  loss_dice_2: 0.1212  loss_ce_3: 0.1793  loss_mask_3: 0.07828  loss_dice_3: 0.1251  loss_ce_4: 0.172  loss_mask_4: 0.07595  loss_dice_4: 0.1263  time: 0.4467  data_time: 0.0791  lr: 1.9294e-05  max_mem: 5315M
[01/29 15:03:50] d2.utils.events INFO:  eta: 0:10:34  iter: 179  total_loss: 2.07  loss_ce: 0.07667  loss_mask: 0.07293  loss_dice: 0.1261  loss_ce_0: 0.263  loss_mask_0: 0.06944  loss_dice_0: 0.123  loss_ce_1: 0.1585  loss_mask_1: 0.07616  loss_dice_1: 0.1208  loss_ce_2: 0.1351  loss_mask_2: 0.07428  loss_dice_2: 0.1268  loss_ce_3: 0.09639  loss_mask_3: 0.07216  loss_dice_3: 0.1259  loss_ce_4: 0.0848  loss_mask_4: 0.07398  loss_dice_4: 0.1247  time: 0.4471  data_time: 0.0771  lr: 2.145e-05  max_mem: 5315M
[01/29 15:03:59] d2.utils.events INFO:  eta: 0:10:25  iter: 199  total_loss: 1.609  loss_ce: 0.04243  loss_mask: 0.06709  loss_dice: 0.1076  loss_ce_0: 0.1576  loss_mask_0: 0.06789  loss_dice_0: 0.11  loss_ce_1: 0.09394  loss_mask_1: 0.06932  loss_dice_1: 0.1046  loss_ce_2: 0.07249  loss_mask_2: 0.07097  loss_dice_2: 0.1079  loss_ce_3: 0.05533  loss_mask_3: 0.06795  loss_dice_3: 0.1072  loss_ce_4: 0.04697  loss_mask_4: 0.06804  loss_dice_4: 0.107  time: 0.4469  data_time: 0.0771  lr: 2.3544e-05  max_mem: 5315M
[01/29 15:04:08] d2.utils.events INFO:  eta: 0:10:16  iter: 219  total_loss: 1.495  loss_ce: 0.03863  loss_mask: 0.06586  loss_dice: 0.1193  loss_ce_0: 0.1121  loss_mask_0: 0.06867  loss_dice_0: 0.1225  loss_ce_1: 0.07061  loss_mask_1: 0.07352  loss_dice_1: 0.1202  loss_ce_2: 0.05536  loss_mask_2: 0.0671  loss_dice_2: 0.1214  loss_ce_3: 0.04344  loss_mask_3: 0.06808  loss_dice_3: 0.1193  loss_ce_4: 0.04064  loss_mask_4: 0.06681  loss_dice_4: 0.1173  time: 0.4471  data_time: 0.0772  lr: 2.5577e-05  max_mem: 5315M
[01/29 15:04:17] d2.utils.events INFO:  eta: 0:10:07  iter: 239  total_loss: 1.306  loss_ce: 0.03032  loss_mask: 0.06404  loss_dice: 0.1045  loss_ce_0: 0.08793  loss_mask_0: 0.0628  loss_dice_0: 0.1101  loss_ce_1: 0.06064  loss_mask_1: 0.06461  loss_dice_1: 0.1056  loss_ce_2: 0.04579  loss_mask_2: 0.06113  loss_dice_2: 0.1032  loss_ce_3: 0.03661  loss_mask_3: 0.06275  loss_dice_3: 0.1028  loss_ce_4: 0.03256  loss_mask_4: 0.06462  loss_dice_4: 0.1053  time: 0.4471  data_time: 0.0761  lr: 2.7549e-05  max_mem: 5315M
[01/29 15:04:26] d2.utils.events INFO:  eta: 0:09:58  iter: 259  total_loss: 1.403  loss_ce: 0.032  loss_mask: 0.0667  loss_dice: 0.1231  loss_ce_0: 0.07038  loss_mask_0: 0.07088  loss_dice_0: 0.1163  loss_ce_1: 0.05227  loss_mask_1: 0.06996  loss_dice_1: 0.1218  loss_ce_2: 0.04199  loss_mask_2: 0.0665  loss_dice_2: 0.1247  loss_ce_3: 0.03521  loss_mask_3: 0.06557  loss_dice_3: 0.1224  loss_ce_4: 0.03236  loss_mask_4: 0.06673  loss_dice_4: 0.1224  time: 0.4472  data_time: 0.0759  lr: 2.9459e-05  max_mem: 5315M
[01/29 15:04:35] d2.utils.events INFO:  eta: 0:09:49  iter: 279  total_loss: 1.236  loss_ce: 0.01889  loss_mask: 0.05796  loss_dice: 0.102  loss_ce_0: 0.05045  loss_mask_0: 0.06071  loss_dice_0: 0.1035  loss_ce_1: 0.03364  loss_mask_1: 0.05966  loss_dice_1: 0.1009  loss_ce_2: 0.02946  loss_mask_2: 0.05855  loss_dice_2: 0.1033  loss_ce_3: 0.02198  loss_mask_3: 0.05864  loss_dice_3: 0.1027  loss_ce_4: 0.02101  loss_mask_4: 0.05802  loss_dice_4: 0.102  time: 0.4470  data_time: 0.0747  lr: 3.1308e-05  max_mem: 5315M
[01/29 15:04:44] d2.utils.events INFO:  eta: 0:09:40  iter: 299  total_loss: 1.039  loss_ce: 0.01282  loss_mask: 0.05773  loss_dice: 0.09826  loss_ce_0: 0.03595  loss_mask_0: 0.05798  loss_dice_0: 0.09969  loss_ce_1: 0.02409  loss_mask_1: 0.05736  loss_dice_1: 0.09908  loss_ce_2: 0.01994  loss_mask_2: 0.05651  loss_dice_2: 0.09872  loss_ce_3: 0.01513  loss_mask_3: 0.05779  loss_dice_3: 0.09971  loss_ce_4: 0.01398  loss_mask_4: 0.05638  loss_dice_4: 0.09806  time: 0.4471  data_time: 0.0772  lr: 3.3094e-05  max_mem: 5315M
[01/29 15:04:53] d2.utils.events INFO:  eta: 0:09:31  iter: 319  total_loss: 1.198  loss_ce: 0.02262  loss_mask: 0.05675  loss_dice: 0.1043  loss_ce_0: 0.04029  loss_mask_0: 0.05603  loss_dice_0: 0.1062  loss_ce_1: 0.03044  loss_mask_1: 0.05654  loss_dice_1: 0.1055  loss_ce_2: 0.02975  loss_mask_2: 0.05552  loss_dice_2: 0.1067  loss_ce_3: 0.02486  loss_mask_3: 0.0579  loss_dice_3: 0.1059  loss_ce_4: 0.02216  loss_mask_4: 0.05734  loss_dice_4: 0.1026  time: 0.4471  data_time: 0.0753  lr: 3.4819e-05  max_mem: 5315M
[01/29 15:05:02] d2.utils.events INFO:  eta: 0:09:22  iter: 339  total_loss: 1.102  loss_ce: 0.01081  loss_mask: 0.05616  loss_dice: 0.1012  loss_ce_0: 0.02813  loss_mask_0: 0.05837  loss_dice_0: 0.09972  loss_ce_1: 0.01592  loss_mask_1: 0.05611  loss_dice_1: 0.09994  loss_ce_2: 0.0143  loss_mask_2: 0.05697  loss_dice_2: 0.1003  loss_ce_3: 0.01176  loss_mask_3: 0.05641  loss_dice_3: 0.09983  loss_ce_4: 0.01227  loss_mask_4: 0.05751  loss_dice_4: 0.1008  time: 0.4470  data_time: 0.0760  lr: 3.6482e-05  max_mem: 5315M
[01/29 15:05:10] d2.utils.events INFO:  eta: 0:09:12  iter: 359  total_loss: 1.008  loss_ce: 0.01224  loss_mask: 0.0554  loss_dice: 0.09676  loss_ce_0: 0.02881  loss_mask_0: 0.05841  loss_dice_0: 0.09381  loss_ce_1: 0.01915  loss_mask_1: 0.05387  loss_dice_1: 0.09647  loss_ce_2: 0.01607  loss_mask_2: 0.05328  loss_dice_2: 0.09607  loss_ce_3: 0.01278  loss_mask_3: 0.05488  loss_dice_3: 0.0953  loss_ce_4: 0.01263  loss_mask_4: 0.05454  loss_dice_4: 0.09472  time: 0.4468  data_time: 0.0745  lr: 3.8082e-05  max_mem: 5315M
[01/29 15:05:19] d2.utils.events INFO:  eta: 0:09:03  iter: 379  total_loss: 0.9623  loss_ce: 0.008701  loss_mask: 0.05235  loss_dice: 0.08994  loss_ce_0: 0.02151  loss_mask_0: 0.0521  loss_dice_0: 0.09021  loss_ce_1: 0.01728  loss_mask_1: 0.05223  loss_dice_1: 0.09044  loss_ce_2: 0.01419  loss_mask_2: 0.051  loss_dice_2: 0.09039  loss_ce_3: 0.01069  loss_mask_3: 0.05267  loss_dice_3: 0.08847  loss_ce_4: 0.009597  loss_mask_4: 0.05165  loss_dice_4: 0.08949  time: 0.4467  data_time: 0.0756  lr: 3.962e-05  max_mem: 5315M
[01/29 15:05:28] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:05:28] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/29 15:05:28] d2.data.common INFO: Serializing 9 elements to byte tensors and concatenating them all ...
[01/29 15:05:28] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 15:05:28] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:05:28] d2.evaluation.evaluator INFO: Start inference on 9 batches
[01/29 15:05:29] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.344879 (0.086220 s / iter per device, on 1 devices)
[01/29 15:05:29] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.047564 s / iter per device, on 1 devices)
[01/29 15:05:29] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 89.15502100903994, 'fwIoU': 90.75581882774166, 'IoU-Grass': nan, 'IoU-CameraEdge': 75.12916188289323, 'IoU-Vehicle': 90.49546620293583, 'IoU-Person': nan, 'IoU-Bush': 93.19241597747668, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 95.31736203854358, 'IoU-Large_stone': 98.25542831770116, 'IoU-Forrest': nan, 'IoU-Gravel': 82.54029163468918, 'mACC': 93.76625538457435, 'pACC': 94.99502976629984, 'ACC-Grass': nan, 'ACC-CameraEdge': 76.75504894868985, 'ACC-Vehicle': 94.5587112536265, 'ACC-Person': nan, 'ACC-Bush': 95.08730194353427, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 98.36823629100593, 'ACC-Large_stone': 99.18119303177149, 'ACC-Forrest': nan, 'ACC-Gravel': 98.64704083881809})])
[01/29 15:05:29] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:05:29] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/29 15:05:29] d2.data.common INFO: Serializing 9 elements to byte tensors and concatenating them all ...
[01/29 15:05:29] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 15:05:29] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:05:29] d2.evaluation.evaluator INFO: Start inference on 9 batches
[01/29 15:05:30] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.335960 (0.083990 s / iter per device, on 1 devices)
[01/29 15:05:30] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.045236 s / iter per device, on 1 devices)
[01/29 15:05:30] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 89.15502100903994, 'fwIoU': 90.75581882774166, 'IoU-Grass': nan, 'IoU-CameraEdge': 75.12916188289323, 'IoU-Vehicle': 90.49546620293583, 'IoU-Person': nan, 'IoU-Bush': 93.19241597747668, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 95.31736203854358, 'IoU-Large_stone': 98.25542831770116, 'IoU-Forrest': nan, 'IoU-Gravel': 82.54029163468918, 'mACC': 93.76625538457435, 'pACC': 94.99502976629984, 'ACC-Grass': nan, 'ACC-CameraEdge': 76.75504894868985, 'ACC-Vehicle': 94.5587112536265, 'ACC-Person': nan, 'ACC-Bush': 95.08730194353427, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 98.36823629100593, 'ACC-Large_stone': 99.18119303177149, 'ACC-Forrest': nan, 'ACC-Gravel': 98.64704083881809})])
[01/29 15:05:30] d2.utils.events INFO:  eta: 0:08:55  iter: 399  total_loss: 0.9277  loss_ce: 0.007711  loss_mask: 0.049  loss_dice: 0.08341  loss_ce_0: 0.02056  loss_mask_0: 0.05236  loss_dice_0: 0.08244  loss_ce_1: 0.01389  loss_mask_1: 0.04968  loss_dice_1: 0.0821  loss_ce_2: 0.01117  loss_mask_2: 0.05052  loss_dice_2: 0.08485  loss_ce_3: 0.009438  loss_mask_3: 0.0489  loss_dice_3: 0.08343  loss_ce_4: 0.007841  loss_mask_4: 0.04885  loss_dice_4: 0.08436  time: 0.4465  data_time: 0.0750  lr: 4.1095e-05  max_mem: 5315M
[01/29 15:05:39] d2.utils.events INFO:  eta: 0:08:46  iter: 419  total_loss: 0.9668  loss_ce: 0.005107  loss_mask: 0.0559  loss_dice: 0.0871  loss_ce_0: 0.01294  loss_mask_0: 0.05265  loss_dice_0: 0.08691  loss_ce_1: 0.01002  loss_mask_1: 0.05338  loss_dice_1: 0.08532  loss_ce_2: 0.009312  loss_mask_2: 0.05388  loss_dice_2: 0.08608  loss_ce_3: 0.007426  loss_mask_3: 0.05544  loss_dice_3: 0.08639  loss_ce_4: 0.00557  loss_mask_4: 0.05495  loss_dice_4: 0.08633  time: 0.4466  data_time: 0.0744  lr: 4.2508e-05  max_mem: 5315M
[01/29 15:05:48] d2.utils.events INFO:  eta: 0:08:36  iter: 439  total_loss: 0.8487  loss_ce: 0.004953  loss_mask: 0.05024  loss_dice: 0.07877  loss_ce_0: 0.01556  loss_mask_0: 0.04829  loss_dice_0: 0.08387  loss_ce_1: 0.008777  loss_mask_1: 0.04799  loss_dice_1: 0.08076  loss_ce_2: 0.007892  loss_mask_2: 0.0478  loss_dice_2: 0.08026  loss_ce_3: 0.006703  loss_mask_3: 0.04689  loss_dice_3: 0.08018  loss_ce_4: 0.005774  loss_mask_4: 0.04726  loss_dice_4: 0.07988  time: 0.4466  data_time: 0.0795  lr: 4.3858e-05  max_mem: 5315M
[01/29 15:05:57] d2.utils.events INFO:  eta: 0:08:27  iter: 459  total_loss: 0.9523  loss_ce: 0.005044  loss_mask: 0.04928  loss_dice: 0.08807  loss_ce_0: 0.01208  loss_mask_0: 0.04937  loss_dice_0: 0.09323  loss_ce_1: 0.008312  loss_mask_1: 0.04877  loss_dice_1: 0.08765  loss_ce_2: 0.006623  loss_mask_2: 0.04976  loss_dice_2: 0.08534  loss_ce_3: 0.005598  loss_mask_3: 0.04886  loss_dice_3: 0.08844  loss_ce_4: 0.005258  loss_mask_4: 0.04884  loss_dice_4: 0.08964  time: 0.4463  data_time: 0.0755  lr: 4.5144e-05  max_mem: 5315M
[01/29 15:06:06] d2.utils.events INFO:  eta: 0:08:18  iter: 479  total_loss: 0.8557  loss_ce: 0.002533  loss_mask: 0.04679  loss_dice: 0.07857  loss_ce_0: 0.009506  loss_mask_0: 0.04792  loss_dice_0: 0.07747  loss_ce_1: 0.006464  loss_mask_1: 0.04836  loss_dice_1: 0.07794  loss_ce_2: 0.004435  loss_mask_2: 0.04697  loss_dice_2: 0.07786  loss_ce_3: 0.00327  loss_mask_3: 0.04622  loss_dice_3: 0.07838  loss_ce_4: 0.002873  loss_mask_4: 0.04715  loss_dice_4: 0.0793  time: 0.4463  data_time: 0.0758  lr: 4.6367e-05  max_mem: 5315M
[01/29 15:06:15] d2.utils.events INFO:  eta: 0:08:09  iter: 499  total_loss: 0.9037  loss_ce: 0.003149  loss_mask: 0.05111  loss_dice: 0.0905  loss_ce_0: 0.009501  loss_mask_0: 0.05093  loss_dice_0: 0.08965  loss_ce_1: 0.006171  loss_mask_1: 0.05187  loss_dice_1: 0.08806  loss_ce_2: 0.004872  loss_mask_2: 0.05022  loss_dice_2: 0.08945  loss_ce_3: 0.003439  loss_mask_3: 0.05005  loss_dice_3: 0.08825  loss_ce_4: 0.00328  loss_mask_4: 0.05089  loss_dice_4: 0.08992  time: 0.4463  data_time: 0.0749  lr: 4.7527e-05  max_mem: 5315M
[01/29 15:06:24] d2.utils.events INFO:  eta: 0:08:00  iter: 519  total_loss: 0.8506  loss_ce: 0.002631  loss_mask: 0.0488  loss_dice: 0.07875  loss_ce_0: 0.00904  loss_mask_0: 0.04773  loss_dice_0: 0.07978  loss_ce_1: 0.005305  loss_mask_1: 0.04585  loss_dice_1: 0.0775  loss_ce_2: 0.004401  loss_mask_2: 0.04562  loss_dice_2: 0.07702  loss_ce_3: 0.002898  loss_mask_3: 0.04742  loss_dice_3: 0.07892  loss_ce_4: 0.002995  loss_mask_4: 0.0479  loss_dice_4: 0.07908  time: 0.4465  data_time: 0.0781  lr: 4.8623e-05  max_mem: 5315M
[01/29 15:06:33] d2.utils.events INFO:  eta: 0:07:51  iter: 539  total_loss: 0.8292  loss_ce: 0.003322  loss_mask: 0.05352  loss_dice: 0.07545  loss_ce_0: 0.008066  loss_mask_0: 0.05075  loss_dice_0: 0.07666  loss_ce_1: 0.005555  loss_mask_1: 0.05138  loss_dice_1: 0.07662  loss_ce_2: 0.005058  loss_mask_2: 0.0525  loss_dice_2: 0.07611  loss_ce_3: 0.003578  loss_mask_3: 0.05276  loss_dice_3: 0.07567  loss_ce_4: 0.003643  loss_mask_4: 0.05258  loss_dice_4: 0.07564  time: 0.4466  data_time: 0.0779  lr: 4.9655e-05  max_mem: 5315M
[01/29 15:06:42] d2.utils.events INFO:  eta: 0:07:42  iter: 559  total_loss: 0.71  loss_ce: 0.002404  loss_mask: 0.04443  loss_dice: 0.0704  loss_ce_0: 0.006905  loss_mask_0: 0.04396  loss_dice_0: 0.07203  loss_ce_1: 0.004219  loss_mask_1: 0.04495  loss_dice_1: 0.0708  loss_ce_2: 0.003559  loss_mask_2: 0.04454  loss_dice_2: 0.07037  loss_ce_3: 0.002339  loss_mask_3: 0.04364  loss_dice_3: 0.07043  loss_ce_4: 0.002419  loss_mask_4: 0.04421  loss_dice_4: 0.06959  time: 0.4465  data_time: 0.0733  lr: 5.0623e-05  max_mem: 5315M
[01/29 15:06:51] d2.utils.events INFO:  eta: 0:07:34  iter: 579  total_loss: 0.8019  loss_ce: 0.002623  loss_mask: 0.04081  loss_dice: 0.08144  loss_ce_0: 0.007306  loss_mask_0: 0.04234  loss_dice_0: 0.08057  loss_ce_1: 0.004801  loss_mask_1: 0.04159  loss_dice_1: 0.08006  loss_ce_2: 0.004368  loss_mask_2: 0.03984  loss_dice_2: 0.08081  loss_ce_3: 0.00353  loss_mask_3: 0.04012  loss_dice_3: 0.08011  loss_ce_4: 0.003187  loss_mask_4: 0.04081  loss_dice_4: 0.08134  time: 0.4465  data_time: 0.0756  lr: 5.1527e-05  max_mem: 5315M
[01/29 15:07:00] d2.utils.events INFO:  eta: 0:07:25  iter: 599  total_loss: 0.7854  loss_ce: 0.004745  loss_mask: 0.04303  loss_dice: 0.07679  loss_ce_0: 0.007782  loss_mask_0: 0.04349  loss_dice_0: 0.07627  loss_ce_1: 0.005076  loss_mask_1: 0.04319  loss_dice_1: 0.07699  loss_ce_2: 0.005199  loss_mask_2: 0.04286  loss_dice_2: 0.07844  loss_ce_3: 0.00555  loss_mask_3: 0.04309  loss_dice_3: 0.07703  loss_ce_4: 0.005022  loss_mask_4: 0.04322  loss_dice_4: 0.07644  time: 0.4465  data_time: 0.0737  lr: 5.2366e-05  max_mem: 5315M
[01/29 15:07:09] d2.utils.events INFO:  eta: 0:07:16  iter: 619  total_loss: 0.744  loss_ce: 0.001374  loss_mask: 0.04533  loss_dice: 0.07248  loss_ce_0: 0.006085  loss_mask_0: 0.04515  loss_dice_0: 0.07225  loss_ce_1: 0.003999  loss_mask_1: 0.04574  loss_dice_1: 0.07155  loss_ce_2: 0.002584  loss_mask_2: 0.04494  loss_dice_2: 0.07182  loss_ce_3: 0.001587  loss_mask_3: 0.04628  loss_dice_3: 0.07246  loss_ce_4: 0.001552  loss_mask_4: 0.0469  loss_dice_4: 0.0721  time: 0.4465  data_time: 0.0744  lr: 5.314e-05  max_mem: 5315M
[01/29 15:07:18] d2.utils.events INFO:  eta: 0:07:07  iter: 639  total_loss: 0.7009  loss_ce: 0.001074  loss_mask: 0.04474  loss_dice: 0.06866  loss_ce_0: 0.004404  loss_mask_0: 0.04096  loss_dice_0: 0.07065  loss_ce_1: 0.002266  loss_mask_1: 0.04245  loss_dice_1: 0.06952  loss_ce_2: 0.001928  loss_mask_2: 0.04388  loss_dice_2: 0.06935  loss_ce_3: 0.001378  loss_mask_3: 0.04467  loss_dice_3: 0.069  loss_ce_4: 0.001327  loss_mask_4: 0.04485  loss_dice_4: 0.06888  time: 0.4466  data_time: 0.0750  lr: 5.385e-05  max_mem: 5315M
[01/29 15:07:27] d2.utils.events INFO:  eta: 0:06:58  iter: 659  total_loss: 0.693  loss_ce: 0.001492  loss_mask: 0.03811  loss_dice: 0.06589  loss_ce_0: 0.005233  loss_mask_0: 0.04048  loss_dice_0: 0.06399  loss_ce_1: 0.003571  loss_mask_1: 0.03864  loss_dice_1: 0.06352  loss_ce_2: 0.003115  loss_mask_2: 0.03838  loss_dice_2: 0.06475  loss_ce_3: 0.002188  loss_mask_3: 0.03737  loss_dice_3: 0.06654  loss_ce_4: 0.001849  loss_mask_4: 0.03844  loss_dice_4: 0.0666  time: 0.4464  data_time: 0.0735  lr: 5.4494e-05  max_mem: 5315M
[01/29 15:07:35] d2.utils.events INFO:  eta: 0:06:49  iter: 679  total_loss: 0.7199  loss_ce: 0.001115  loss_mask: 0.04058  loss_dice: 0.0714  loss_ce_0: 0.004372  loss_mask_0: 0.0409  loss_dice_0: 0.06918  loss_ce_1: 0.001953  loss_mask_1: 0.04314  loss_dice_1: 0.06919  loss_ce_2: 0.001869  loss_mask_2: 0.04171  loss_dice_2: 0.07012  loss_ce_3: 0.001385  loss_mask_3: 0.04179  loss_dice_3: 0.07018  loss_ce_4: 0.001292  loss_mask_4: 0.04157  loss_dice_4: 0.07045  time: 0.4464  data_time: 0.0736  lr: 5.5072e-05  max_mem: 5387M
[01/29 15:07:44] d2.utils.events INFO:  eta: 0:06:40  iter: 699  total_loss: 0.5948  loss_ce: 0.000689  loss_mask: 0.03623  loss_dice: 0.06193  loss_ce_0: 0.002308  loss_mask_0: 0.03662  loss_dice_0: 0.06116  loss_ce_1: 0.001422  loss_mask_1: 0.0363  loss_dice_1: 0.06046  loss_ce_2: 0.00115  loss_mask_2: 0.0364  loss_dice_2: 0.06139  loss_ce_3: 0.0008631  loss_mask_3: 0.03669  loss_dice_3: 0.06184  loss_ce_4: 0.0008055  loss_mask_4: 0.03614  loss_dice_4: 0.06167  time: 0.4463  data_time: 0.0746  lr: 5.5585e-05  max_mem: 5387M
[01/29 15:07:53] d2.utils.events INFO:  eta: 0:06:31  iter: 719  total_loss: 0.652  loss_ce: 0.0008607  loss_mask: 0.04022  loss_dice: 0.06157  loss_ce_0: 0.002473  loss_mask_0: 0.03917  loss_dice_0: 0.06138  loss_ce_1: 0.001613  loss_mask_1: 0.0397  loss_dice_1: 0.06127  loss_ce_2: 0.001383  loss_mask_2: 0.04048  loss_dice_2: 0.06138  loss_ce_3: 0.001102  loss_mask_3: 0.04067  loss_dice_3: 0.06092  loss_ce_4: 0.0009477  loss_mask_4: 0.04026  loss_dice_4: 0.06129  time: 0.4460  data_time: 0.0698  lr: 5.6032e-05  max_mem: 5424M
[01/29 15:08:02] d2.utils.events INFO:  eta: 0:06:22  iter: 739  total_loss: 0.708  loss_ce: 0.001014  loss_mask: 0.04296  loss_dice: 0.0647  loss_ce_0: 0.003192  loss_mask_0: 0.04358  loss_dice_0: 0.06715  loss_ce_1: 0.002244  loss_mask_1: 0.04069  loss_dice_1: 0.06751  loss_ce_2: 0.001573  loss_mask_2: 0.0422  loss_dice_2: 0.06576  loss_ce_3: 0.001212  loss_mask_3: 0.04177  loss_dice_3: 0.06508  loss_ce_4: 0.001109  loss_mask_4: 0.04183  loss_dice_4: 0.06498  time: 0.4457  data_time: 0.0699  lr: 5.6413e-05  max_mem: 5424M
[01/29 15:08:11] d2.utils.events INFO:  eta: 0:06:13  iter: 759  total_loss: 0.6185  loss_ce: 0.001489  loss_mask: 0.04019  loss_dice: 0.06074  loss_ce_0: 0.004149  loss_mask_0: 0.04068  loss_dice_0: 0.06054  loss_ce_1: 0.002277  loss_mask_1: 0.03918  loss_dice_1: 0.06102  loss_ce_2: 0.002007  loss_mask_2: 0.03885  loss_dice_2: 0.06108  loss_ce_3: 0.001758  loss_mask_3: 0.03927  loss_dice_3: 0.06124  loss_ce_4: 0.001726  loss_mask_4: 0.03928  loss_dice_4: 0.06142  time: 0.4455  data_time: 0.0697  lr: 5.6727e-05  max_mem: 5424M
[01/29 15:08:19] d2.utils.events INFO:  eta: 0:06:04  iter: 779  total_loss: 0.6234  loss_ce: 0.0007512  loss_mask: 0.03532  loss_dice: 0.06432  loss_ce_0: 0.002339  loss_mask_0: 0.03706  loss_dice_0: 0.06491  loss_ce_1: 0.001443  loss_mask_1: 0.03603  loss_dice_1: 0.06565  loss_ce_2: 0.00134  loss_mask_2: 0.03565  loss_dice_2: 0.0651  loss_ce_3: 0.001006  loss_mask_3: 0.03606  loss_dice_3: 0.06372  loss_ce_4: 0.0009099  loss_mask_4: 0.03529  loss_dice_4: 0.06403  time: 0.4453  data_time: 0.0720  lr: 5.6974e-05  max_mem: 5424M
[01/29 15:08:28] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:08:28] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/29 15:08:28] d2.data.common INFO: Serializing 9 elements to byte tensors and concatenating them all ...
[01/29 15:08:28] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 15:08:28] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:08:28] d2.evaluation.evaluator INFO: Start inference on 9 batches
[01/29 15:08:29] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.356728 (0.089182 s / iter per device, on 1 devices)
[01/29 15:08:29] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.048810 s / iter per device, on 1 devices)
[01/29 15:08:29] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 96.23890707914943, 'fwIoU': 97.46731104280704, 'IoU-Grass': nan, 'IoU-CameraEdge': 95.10768801036326, 'IoU-Vehicle': 94.32031676883808, 'IoU-Person': nan, 'IoU-Bush': 95.51527548089477, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 95.53272536464837, 'IoU-Large_stone': 98.77280037702266, 'IoU-Forrest': nan, 'IoU-Gravel': 98.18463647312934, 'mACC': 98.11571634509399, 'pACC': 98.71122170768855, 'ACC-Grass': nan, 'ACC-CameraEdge': 96.31013163272588, 'ACC-Vehicle': 96.20629103679951, 'ACC-Person': nan, 'ACC-Bush': 98.51205170788634, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 99.49003060853926, 'ACC-Large_stone': 99.54261720347701, 'ACC-Forrest': nan, 'ACC-Gravel': 98.63317588113584})])
[01/29 15:08:29] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:08:29] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/29 15:08:29] d2.data.common INFO: Serializing 9 elements to byte tensors and concatenating them all ...
[01/29 15:08:29] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 15:08:29] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:08:29] d2.evaluation.evaluator INFO: Start inference on 9 batches
[01/29 15:08:30] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.333726 (0.083432 s / iter per device, on 1 devices)
[01/29 15:08:30] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.044586 s / iter per device, on 1 devices)
[01/29 15:08:30] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 96.23890707914943, 'fwIoU': 97.46731104280704, 'IoU-Grass': nan, 'IoU-CameraEdge': 95.10768801036326, 'IoU-Vehicle': 94.32031676883808, 'IoU-Person': nan, 'IoU-Bush': 95.51527548089477, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 95.53272536464837, 'IoU-Large_stone': 98.77280037702266, 'IoU-Forrest': nan, 'IoU-Gravel': 98.18463647312934, 'mACC': 98.11571634509399, 'pACC': 98.71122170768855, 'ACC-Grass': nan, 'ACC-CameraEdge': 96.31013163272588, 'ACC-Vehicle': 96.20629103679951, 'ACC-Person': nan, 'ACC-Bush': 98.51205170788634, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 99.49003060853926, 'ACC-Large_stone': 99.54261720347701, 'ACC-Forrest': nan, 'ACC-Gravel': 98.63317588113584})])
[01/29 15:08:30] d2.utils.events INFO:  eta: 0:05:55  iter: 799  total_loss: 0.6235  loss_ce: 0.002012  loss_mask: 0.03683  loss_dice: 0.05863  loss_ce_0: 0.00523  loss_mask_0: 0.03488  loss_dice_0: 0.05966  loss_ce_1: 0.002665  loss_mask_1: 0.03643  loss_dice_1: 0.05927  loss_ce_2: 0.002294  loss_mask_2: 0.03701  loss_dice_2: 0.05951  loss_ce_3: 0.001744  loss_mask_3: 0.03695  loss_dice_3: 0.05828  loss_ce_4: 0.001988  loss_mask_4: 0.03598  loss_dice_4: 0.05849  time: 0.4453  data_time: 0.0699  lr: 5.7154e-05  max_mem: 5424M
[01/29 15:08:39] d2.utils.events INFO:  eta: 0:05:46  iter: 819  total_loss: 0.6043  loss_ce: 0.001041  loss_mask: 0.03859  loss_dice: 0.06107  loss_ce_0: 0.002119  loss_mask_0: 0.03622  loss_dice_0: 0.06087  loss_ce_1: 0.001394  loss_mask_1: 0.03641  loss_dice_1: 0.06074  loss_ce_2: 0.001241  loss_mask_2: 0.03572  loss_dice_2: 0.06124  loss_ce_3: 0.001004  loss_mask_3: 0.0371  loss_dice_3: 0.06103  loss_ce_4: 0.00104  loss_mask_4: 0.03804  loss_dice_4: 0.06048  time: 0.4451  data_time: 0.0709  lr: 5.7267e-05  max_mem: 5424M
[01/29 15:08:48] d2.utils.events INFO:  eta: 0:05:37  iter: 839  total_loss: 0.5578  loss_ce: 0.000698  loss_mask: 0.03553  loss_dice: 0.05802  loss_ce_0: 0.001817  loss_mask_0: 0.03482  loss_dice_0: 0.06014  loss_ce_1: 0.001026  loss_mask_1: 0.03548  loss_dice_1: 0.05756  loss_ce_2: 0.0009446  loss_mask_2: 0.03534  loss_dice_2: 0.05738  loss_ce_3: 0.0007625  loss_mask_3: 0.03543  loss_dice_3: 0.05773  loss_ce_4: 0.0007979  loss_mask_4: 0.03539  loss_dice_4: 0.05834  time: 0.4450  data_time: 0.0705  lr: 5.7311e-05  max_mem: 5424M
[01/29 15:08:56] d2.utils.events INFO:  eta: 0:05:28  iter: 859  total_loss: 0.5749  loss_ce: 0.0004984  loss_mask: 0.0345  loss_dice: 0.05579  loss_ce_0: 0.001651  loss_mask_0: 0.03495  loss_dice_0: 0.05814  loss_ce_1: 0.0009323  loss_mask_1: 0.03658  loss_dice_1: 0.05647  loss_ce_2: 0.0008196  loss_mask_2: 0.0343  loss_dice_2: 0.05565  loss_ce_3: 0.0005959  loss_mask_3: 0.03547  loss_dice_3: 0.05604  loss_ce_4: 0.0005571  loss_mask_4: 0.03434  loss_dice_4: 0.05583  time: 0.4449  data_time: 0.0741  lr: 5.7288e-05  max_mem: 5424M
[01/29 15:09:05] d2.utils.events INFO:  eta: 0:05:19  iter: 879  total_loss: 0.5412  loss_ce: 0.0006655  loss_mask: 0.0333  loss_dice: 0.05236  loss_ce_0: 0.001335  loss_mask_0: 0.03351  loss_dice_0: 0.05204  loss_ce_1: 0.0008903  loss_mask_1: 0.03322  loss_dice_1: 0.05283  loss_ce_2: 0.0008165  loss_mask_2: 0.03352  loss_dice_2: 0.05292  loss_ce_3: 0.000644  loss_mask_3: 0.0328  loss_dice_3: 0.0528  loss_ce_4: 0.0006955  loss_mask_4: 0.03286  loss_dice_4: 0.05259  time: 0.4447  data_time: 0.0702  lr: 5.7195e-05  max_mem: 5424M
[01/29 15:09:14] d2.utils.events INFO:  eta: 0:05:10  iter: 899  total_loss: 0.5981  loss_ce: 0.0004284  loss_mask: 0.03479  loss_dice: 0.06531  loss_ce_0: 0.001842  loss_mask_0: 0.03595  loss_dice_0: 0.06321  loss_ce_1: 0.000891  loss_mask_1: 0.03503  loss_dice_1: 0.0633  loss_ce_2: 0.0007645  loss_mask_2: 0.03548  loss_dice_2: 0.06317  loss_ce_3: 0.0005528  loss_mask_3: 0.03457  loss_dice_3: 0.06393  loss_ce_4: 0.0004935  loss_mask_4: 0.03509  loss_dice_4: 0.06437  time: 0.4445  data_time: 0.0711  lr: 5.7034e-05  max_mem: 5424M
[01/29 15:09:23] d2.utils.events INFO:  eta: 0:05:01  iter: 919  total_loss: 0.5627  loss_ce: 0.0004112  loss_mask: 0.03248  loss_dice: 0.05779  loss_ce_0: 0.001047  loss_mask_0: 0.03282  loss_dice_0: 0.05749  loss_ce_1: 0.0007633  loss_mask_1: 0.03258  loss_dice_1: 0.05733  loss_ce_2: 0.0006816  loss_mask_2: 0.03249  loss_dice_2: 0.05763  loss_ce_3: 0.0004924  loss_mask_3: 0.03251  loss_dice_3: 0.05755  loss_ce_4: 0.0004379  loss_mask_4: 0.03264  loss_dice_4: 0.05738  time: 0.4445  data_time: 0.0746  lr: 5.6804e-05  max_mem: 5424M
[01/29 15:09:32] d2.utils.events INFO:  eta: 0:04:52  iter: 939  total_loss: 0.5434  loss_ce: 0.0004977  loss_mask: 0.03518  loss_dice: 0.0559  loss_ce_0: 0.001464  loss_mask_0: 0.03481  loss_dice_0: 0.05519  loss_ce_1: 0.0008111  loss_mask_1: 0.03466  loss_dice_1: 0.05613  loss_ce_2: 0.0007054  loss_mask_2: 0.03404  loss_dice_2: 0.05688  loss_ce_3: 0.0005533  loss_mask_3: 0.0342  loss_dice_3: 0.05639  loss_ce_4: 0.0005085  loss_mask_4: 0.03443  loss_dice_4: 0.05646  time: 0.4446  data_time: 0.0730  lr: 5.6504e-05  max_mem: 5424M
[01/29 15:09:41] d2.utils.events INFO:  eta: 0:04:43  iter: 959  total_loss: 0.5421  loss_ce: 0.0004968  loss_mask: 0.03308  loss_dice: 0.0564  loss_ce_0: 0.001446  loss_mask_0: 0.03324  loss_dice_0: 0.05559  loss_ce_1: 0.0009315  loss_mask_1: 0.03265  loss_dice_1: 0.05594  loss_ce_2: 0.0008301  loss_mask_2: 0.03285  loss_dice_2: 0.05598  loss_ce_3: 0.0006127  loss_mask_3: 0.03267  loss_dice_3: 0.05623  loss_ce_4: 0.0005883  loss_mask_4: 0.0329  loss_dice_4: 0.05619  time: 0.4445  data_time: 0.0735  lr: 5.6133e-05  max_mem: 5424M
[01/29 15:09:50] d2.utils.events INFO:  eta: 0:04:34  iter: 979  total_loss: 0.5338  loss_ce: 0.0005807  loss_mask: 0.03269  loss_dice: 0.05288  loss_ce_0: 0.001695  loss_mask_0: 0.03343  loss_dice_0: 0.05287  loss_ce_1: 0.0008315  loss_mask_1: 0.03353  loss_dice_1: 0.05295  loss_ce_2: 0.0008637  loss_mask_2: 0.0326  loss_dice_2: 0.05281  loss_ce_3: 0.000683  loss_mask_3: 0.03275  loss_dice_3: 0.05291  loss_ce_4: 0.0006745  loss_mask_4: 0.0328  loss_dice_4: 0.05305  time: 0.4444  data_time: 0.0751  lr: 5.5692e-05  max_mem: 5424M
[01/29 15:09:59] d2.utils.events INFO:  eta: 0:04:26  iter: 999  total_loss: 0.5348  loss_ce: 0.0005  loss_mask: 0.03461  loss_dice: 0.05159  loss_ce_0: 0.00101  loss_mask_0: 0.0345  loss_dice_0: 0.05199  loss_ce_1: 0.000741  loss_mask_1: 0.03474  loss_dice_1: 0.05125  loss_ce_2: 0.0006039  loss_mask_2: 0.03417  loss_dice_2: 0.05156  loss_ce_3: 0.0005157  loss_mask_3: 0.03458  loss_dice_3: 0.05134  loss_ce_4: 0.0005266  loss_mask_4: 0.03412  loss_dice_4: 0.05149  time: 0.4445  data_time: 0.0758  lr: 5.518e-05  max_mem: 5424M
[01/29 15:10:08] d2.utils.events INFO:  eta: 0:04:17  iter: 1019  total_loss: 0.5349  loss_ce: 0.000374  loss_mask: 0.03144  loss_dice: 0.05288  loss_ce_0: 0.001077  loss_mask_0: 0.03237  loss_dice_0: 0.05342  loss_ce_1: 0.0007807  loss_mask_1: 0.03214  loss_dice_1: 0.05269  loss_ce_2: 0.00059  loss_mask_2: 0.03264  loss_dice_2: 0.05262  loss_ce_3: 0.0004742  loss_mask_3: 0.03239  loss_dice_3: 0.05266  loss_ce_4: 0.0004349  loss_mask_4: 0.03178  loss_dice_4: 0.05274  time: 0.4446  data_time: 0.0762  lr: 5.4596e-05  max_mem: 5424M
[01/29 15:10:17] d2.utils.events INFO:  eta: 0:04:08  iter: 1039  total_loss: 0.5491  loss_ce: 0.0004827  loss_mask: 0.03279  loss_dice: 0.05482  loss_ce_0: 0.001143  loss_mask_0: 0.03358  loss_dice_0: 0.05433  loss_ce_1: 0.0007408  loss_mask_1: 0.03273  loss_dice_1: 0.05432  loss_ce_2: 0.0006904  loss_mask_2: 0.03327  loss_dice_2: 0.05462  loss_ce_3: 0.0006127  loss_mask_3: 0.0328  loss_dice_3: 0.0541  loss_ce_4: 0.0005553  loss_mask_4: 0.03289  loss_dice_4: 0.05513  time: 0.4446  data_time: 0.0749  lr: 5.394e-05  max_mem: 5424M
[01/29 15:10:25] d2.utils.events INFO:  eta: 0:03:59  iter: 1059  total_loss: 0.5248  loss_ce: 0.0004019  loss_mask: 0.02934  loss_dice: 0.05015  loss_ce_0: 0.001038  loss_mask_0: 0.02905  loss_dice_0: 0.05129  loss_ce_1: 0.0007042  loss_mask_1: 0.02917  loss_dice_1: 0.04926  loss_ce_2: 0.0006131  loss_mask_2: 0.02951  loss_dice_2: 0.05  loss_ce_3: 0.0005521  loss_mask_3: 0.02942  loss_dice_3: 0.05015  loss_ce_4: 0.0004723  loss_mask_4: 0.02927  loss_dice_4: 0.05069  time: 0.4446  data_time: 0.0729  lr: 5.3211e-05  max_mem: 5424M
[01/29 15:10:34] d2.utils.events INFO:  eta: 0:03:50  iter: 1079  total_loss: 0.4675  loss_ce: 0.0005067  loss_mask: 0.02979  loss_dice: 0.04902  loss_ce_0: 0.001027  loss_mask_0: 0.02864  loss_dice_0: 0.04894  loss_ce_1: 0.0006707  loss_mask_1: 0.02895  loss_dice_1: 0.04851  loss_ce_2: 0.000655  loss_mask_2: 0.02921  loss_dice_2: 0.04885  loss_ce_3: 0.0006126  loss_mask_3: 0.02907  loss_dice_3: 0.04845  loss_ce_4: 0.0005391  loss_mask_4: 0.02928  loss_dice_4: 0.04893  time: 0.4445  data_time: 0.0754  lr: 5.2409e-05  max_mem: 5424M
[01/29 15:10:43] d2.utils.events INFO:  eta: 0:03:41  iter: 1099  total_loss: 0.5325  loss_ce: 0.001159  loss_mask: 0.03143  loss_dice: 0.05192  loss_ce_0: 0.00141  loss_mask_0: 0.03176  loss_dice_0: 0.05463  loss_ce_1: 0.001038  loss_mask_1: 0.03246  loss_dice_1: 0.05456  loss_ce_2: 0.0009754  loss_mask_2: 0.03159  loss_dice_2: 0.05321  loss_ce_3: 0.0008983  loss_mask_3: 0.0312  loss_dice_3: 0.0531  loss_ce_4: 0.00104  loss_mask_4: 0.03156  loss_dice_4: 0.05236  time: 0.4445  data_time: 0.0776  lr: 5.1533e-05  max_mem: 5424M
[01/29 15:10:52] d2.utils.events INFO:  eta: 0:03:32  iter: 1119  total_loss: 0.5225  loss_ce: 0.001107  loss_mask: 0.03105  loss_dice: 0.05209  loss_ce_0: 0.001267  loss_mask_0: 0.02928  loss_dice_0: 0.05321  loss_ce_1: 0.001106  loss_mask_1: 0.03068  loss_dice_1: 0.05286  loss_ce_2: 0.001104  loss_mask_2: 0.02996  loss_dice_2: 0.05286  loss_ce_3: 0.00106  loss_mask_3: 0.03024  loss_dice_3: 0.05262  loss_ce_4: 0.001072  loss_mask_4: 0.03061  loss_dice_4: 0.05212  time: 0.4446  data_time: 0.0751  lr: 5.0581e-05  max_mem: 5424M
[01/29 15:11:01] d2.utils.events INFO:  eta: 0:03:24  iter: 1139  total_loss: 0.4859  loss_ce: 0.0005278  loss_mask: 0.02718  loss_dice: 0.04942  loss_ce_0: 0.001227  loss_mask_0: 0.02839  loss_dice_0: 0.04924  loss_ce_1: 0.0008014  loss_mask_1: 0.02875  loss_dice_1: 0.04881  loss_ce_2: 0.0007818  loss_mask_2: 0.02828  loss_dice_2: 0.04906  loss_ce_3: 0.0006787  loss_mask_3: 0.02818  loss_dice_3: 0.04912  loss_ce_4: 0.0005902  loss_mask_4: 0.02784  loss_dice_4: 0.04924  time: 0.4446  data_time: 0.0753  lr: 4.9555e-05  max_mem: 5424M
[01/29 15:11:10] d2.utils.events INFO:  eta: 0:03:15  iter: 1159  total_loss: 0.5289  loss_ce: 0.0004028  loss_mask: 0.02928  loss_dice: 0.0532  loss_ce_0: 0.001029  loss_mask_0: 0.03002  loss_dice_0: 0.05576  loss_ce_1: 0.0008045  loss_mask_1: 0.02939  loss_dice_1: 0.05506  loss_ce_2: 0.0006903  loss_mask_2: 0.02881  loss_dice_2: 0.05203  loss_ce_3: 0.0005678  loss_mask_3: 0.02937  loss_dice_3: 0.05259  loss_ce_4: 0.0004676  loss_mask_4: 0.02921  loss_dice_4: 0.05259  time: 0.4447  data_time: 0.0775  lr: 4.8452e-05  max_mem: 5424M
[01/29 15:11:19] d2.utils.events INFO:  eta: 0:03:06  iter: 1179  total_loss: 0.476  loss_ce: 0.0004274  loss_mask: 0.02927  loss_dice: 0.04507  loss_ce_0: 0.0008772  loss_mask_0: 0.02966  loss_dice_0: 0.04533  loss_ce_1: 0.0006815  loss_mask_1: 0.02963  loss_dice_1: 0.04465  loss_ce_2: 0.0007004  loss_mask_2: 0.02943  loss_dice_2: 0.04459  loss_ce_3: 0.0005822  loss_mask_3: 0.02919  loss_dice_3: 0.04521  loss_ce_4: 0.0004691  loss_mask_4: 0.02936  loss_dice_4: 0.04492  time: 0.4446  data_time: 0.0739  lr: 4.7271e-05  max_mem: 5424M
[01/29 15:11:28] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:11:28] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/29 15:11:28] d2.data.common INFO: Serializing 9 elements to byte tensors and concatenating them all ...
[01/29 15:11:28] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 15:11:28] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:11:28] d2.evaluation.evaluator INFO: Start inference on 9 batches
[01/29 15:11:29] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.331848 (0.082962 s / iter per device, on 1 devices)
[01/29 15:11:29] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.043996 s / iter per device, on 1 devices)
[01/29 15:11:29] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 96.77036454704228, 'fwIoU': 97.97204403009101, 'IoU-Grass': nan, 'IoU-CameraEdge': 96.23940929581045, 'IoU-Vehicle': 93.82551251810783, 'IoU-Person': nan, 'IoU-Bush': 95.74681337836365, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 97.52188655716982, 'IoU-Large_stone': 98.80491979097734, 'IoU-Forrest': nan, 'IoU-Gravel': 98.48364574182463, 'mACC': 98.02020646429864, 'pACC': 98.97542654743984, 'ACC-Grass': nan, 'ACC-CameraEdge': 97.2586138665248, 'ACC-Vehicle': 94.44800732936326, 'ACC-Person': nan, 'ACC-Bush': 98.6197764711163, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 98.72516298614833, 'ACC-Large_stone': 99.83035474257404, 'ACC-Forrest': nan, 'ACC-Gravel': 99.23932339006511})])
[01/29 15:11:29] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:11:29] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/29 15:11:29] d2.data.common INFO: Serializing 9 elements to byte tensors and concatenating them all ...
[01/29 15:11:29] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 15:11:29] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:11:29] d2.evaluation.evaluator INFO: Start inference on 9 batches
[01/29 15:11:29] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.340454 (0.085113 s / iter per device, on 1 devices)
[01/29 15:11:30] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.044834 s / iter per device, on 1 devices)
[01/29 15:11:30] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 96.77036454704228, 'fwIoU': 97.97204403009101, 'IoU-Grass': nan, 'IoU-CameraEdge': 96.23940929581045, 'IoU-Vehicle': 93.82551251810783, 'IoU-Person': nan, 'IoU-Bush': 95.74681337836365, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 97.52188655716982, 'IoU-Large_stone': 98.80491979097734, 'IoU-Forrest': nan, 'IoU-Gravel': 98.48364574182463, 'mACC': 98.02020646429864, 'pACC': 98.97542654743984, 'ACC-Grass': nan, 'ACC-CameraEdge': 97.2586138665248, 'ACC-Vehicle': 94.44800732936326, 'ACC-Person': nan, 'ACC-Bush': 98.6197764711163, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 98.72516298614833, 'ACC-Large_stone': 99.83035474257404, 'ACC-Forrest': nan, 'ACC-Gravel': 99.23932339006511})])
[01/29 15:11:30] d2.utils.events INFO:  eta: 0:02:57  iter: 1199  total_loss: 0.4765  loss_ce: 0.000322  loss_mask: 0.02871  loss_dice: 0.04595  loss_ce_0: 0.001029  loss_mask_0: 0.02801  loss_dice_0: 0.04609  loss_ce_1: 0.0006313  loss_mask_1: 0.0283  loss_dice_1: 0.04566  loss_ce_2: 0.0005584  loss_mask_2: 0.02837  loss_dice_2: 0.04625  loss_ce_3: 0.000399  loss_mask_3: 0.02838  loss_dice_3: 0.04585  loss_ce_4: 0.0003553  loss_mask_4: 0.0287  loss_dice_4: 0.04586  time: 0.4446  data_time: 0.0727  lr: 4.6013e-05  max_mem: 5424M
[01/29 15:11:38] d2.utils.events INFO:  eta: 0:02:48  iter: 1219  total_loss: 0.4716  loss_ce: 0.0003628  loss_mask: 0.02845  loss_dice: 0.04978  loss_ce_0: 0.0008826  loss_mask_0: 0.02817  loss_dice_0: 0.04987  loss_ce_1: 0.0005695  loss_mask_1: 0.02841  loss_dice_1: 0.04998  loss_ce_2: 0.0004978  loss_mask_2: 0.02823  loss_dice_2: 0.05025  loss_ce_3: 0.0004171  loss_mask_3: 0.02819  loss_dice_3: 0.04975  loss_ce_4: 0.0003937  loss_mask_4: 0.02865  loss_dice_4: 0.04963  time: 0.4445  data_time: 0.0723  lr: 4.4675e-05  max_mem: 5424M
[01/29 15:11:47] d2.utils.events INFO:  eta: 0:02:39  iter: 1239  total_loss: 0.5053  loss_ce: 0.00047  loss_mask: 0.03009  loss_dice: 0.04815  loss_ce_0: 0.0008184  loss_mask_0: 0.02945  loss_dice_0: 0.04851  loss_ce_1: 0.0006348  loss_mask_1: 0.02931  loss_dice_1: 0.04847  loss_ce_2: 0.0005948  loss_mask_2: 0.0296  loss_dice_2: 0.04836  loss_ce_3: 0.0005126  loss_mask_3: 0.03015  loss_dice_3: 0.04788  loss_ce_4: 0.0004648  loss_mask_4: 0.03005  loss_dice_4: 0.04813  time: 0.4445  data_time: 0.0751  lr: 4.3257e-05  max_mem: 5424M
[01/29 15:11:56] d2.utils.events INFO:  eta: 0:02:30  iter: 1259  total_loss: 0.4462  loss_ce: 0.0006921  loss_mask: 0.02732  loss_dice: 0.05123  loss_ce_0: 0.001316  loss_mask_0: 0.02725  loss_dice_0: 0.05067  loss_ce_1: 0.0007037  loss_mask_1: 0.02735  loss_dice_1: 0.05038  loss_ce_2: 0.0007214  loss_mask_2: 0.0272  loss_dice_2: 0.05116  loss_ce_3: 0.0006174  loss_mask_3: 0.02677  loss_dice_3: 0.05096  loss_ce_4: 0.0007275  loss_mask_4: 0.0272  loss_dice_4: 0.05061  time: 0.4445  data_time: 0.0790  lr: 4.1758e-05  max_mem: 5424M
[01/29 15:12:05] d2.utils.events INFO:  eta: 0:02:21  iter: 1279  total_loss: 0.4781  loss_ce: 0.0003709  loss_mask: 0.02768  loss_dice: 0.05098  loss_ce_0: 0.0006563  loss_mask_0: 0.02746  loss_dice_0: 0.05063  loss_ce_1: 0.0004901  loss_mask_1: 0.02764  loss_dice_1: 0.05121  loss_ce_2: 0.0004842  loss_mask_2: 0.02746  loss_dice_2: 0.05099  loss_ce_3: 0.0003978  loss_mask_3: 0.0274  loss_dice_3: 0.05127  loss_ce_4: 0.0003686  loss_mask_4: 0.02721  loss_dice_4: 0.05101  time: 0.4446  data_time: 0.0770  lr: 4.0175e-05  max_mem: 5424M
[01/29 15:12:14] d2.utils.events INFO:  eta: 0:02:12  iter: 1299  total_loss: 0.4455  loss_ce: 0.0003528  loss_mask: 0.02667  loss_dice: 0.04454  loss_ce_0: 0.0005957  loss_mask_0: 0.02665  loss_dice_0: 0.04485  loss_ce_1: 0.0004431  loss_mask_1: 0.0265  loss_dice_1: 0.04496  loss_ce_2: 0.0004246  loss_mask_2: 0.02643  loss_dice_2: 0.04469  loss_ce_3: 0.0003763  loss_mask_3: 0.02648  loss_dice_3: 0.04484  loss_ce_4: 0.0003532  loss_mask_4: 0.02668  loss_dice_4: 0.04468  time: 0.4447  data_time: 0.0778  lr: 3.8508e-05  max_mem: 5424M
[01/29 15:12:23] d2.utils.events INFO:  eta: 0:02:04  iter: 1319  total_loss: 0.4738  loss_ce: 0.000286  loss_mask: 0.02864  loss_dice: 0.04832  loss_ce_0: 0.000549  loss_mask_0: 0.02795  loss_dice_0: 0.047  loss_ce_1: 0.0004433  loss_mask_1: 0.02834  loss_dice_1: 0.04809  loss_ce_2: 0.0004086  loss_mask_2: 0.02873  loss_dice_2: 0.04857  loss_ce_3: 0.0003474  loss_mask_3: 0.02852  loss_dice_3: 0.04834  loss_ce_4: 0.0003104  loss_mask_4: 0.02858  loss_dice_4: 0.04816  time: 0.4447  data_time: 0.0796  lr: 3.6755e-05  max_mem: 5424M
[01/29 15:12:32] d2.utils.events INFO:  eta: 0:01:55  iter: 1339  total_loss: 0.4244  loss_ce: 0.0004986  loss_mask: 0.02234  loss_dice: 0.04352  loss_ce_0: 0.0006692  loss_mask_0: 0.02196  loss_dice_0: 0.04415  loss_ce_1: 0.0005072  loss_mask_1: 0.02233  loss_dice_1: 0.04374  loss_ce_2: 0.000494  loss_mask_2: 0.02227  loss_dice_2: 0.04358  loss_ce_3: 0.0004858  loss_mask_3: 0.02239  loss_dice_3: 0.04367  loss_ce_4: 0.0004424  loss_mask_4: 0.02257  loss_dice_4: 0.04353  time: 0.4447  data_time: 0.0786  lr: 3.4913e-05  max_mem: 5424M
[01/29 15:12:41] d2.utils.events INFO:  eta: 0:01:46  iter: 1359  total_loss: 0.4417  loss_ce: 0.0003443  loss_mask: 0.02393  loss_dice: 0.04539  loss_ce_0: 0.0006035  loss_mask_0: 0.02427  loss_dice_0: 0.04468  loss_ce_1: 0.0004891  loss_mask_1: 0.02465  loss_dice_1: 0.04417  loss_ce_2: 0.0004761  loss_mask_2: 0.02484  loss_dice_2: 0.04506  loss_ce_3: 0.0004202  loss_mask_3: 0.02426  loss_dice_3: 0.04512  loss_ce_4: 0.0003761  loss_mask_4: 0.02412  loss_dice_4: 0.04501  time: 0.4446  data_time: 0.0732  lr: 3.2981e-05  max_mem: 5424M
[01/29 15:12:50] d2.utils.events INFO:  eta: 0:01:37  iter: 1379  total_loss: 0.4393  loss_ce: 0.0003388  loss_mask: 0.02595  loss_dice: 0.04582  loss_ce_0: 0.0006329  loss_mask_0: 0.02591  loss_dice_0: 0.04624  loss_ce_1: 0.0004587  loss_mask_1: 0.02583  loss_dice_1: 0.04668  loss_ce_2: 0.0004676  loss_mask_2: 0.02581  loss_dice_2: 0.0459  loss_ce_3: 0.0004215  loss_mask_3: 0.02555  loss_dice_3: 0.04587  loss_ce_4: 0.0003799  loss_mask_4: 0.02562  loss_dice_4: 0.04597  time: 0.4447  data_time: 0.0717  lr: 3.0956e-05  max_mem: 5424M
[01/29 15:12:59] d2.utils.events INFO:  eta: 0:01:28  iter: 1399  total_loss: 0.4257  loss_ce: 0.0002652  loss_mask: 0.02482  loss_dice: 0.04265  loss_ce_0: 0.0005962  loss_mask_0: 0.02506  loss_dice_0: 0.04283  loss_ce_1: 0.0005028  loss_mask_1: 0.02487  loss_dice_1: 0.04306  loss_ce_2: 0.0004436  loss_mask_2: 0.02465  loss_dice_2: 0.04304  loss_ce_3: 0.0003787  loss_mask_3: 0.02464  loss_dice_3: 0.04247  loss_ce_4: 0.0003123  loss_mask_4: 0.02478  loss_dice_4: 0.04262  time: 0.4446  data_time: 0.0734  lr: 2.8835e-05  max_mem: 5424M
[01/29 15:13:08] d2.utils.events INFO:  eta: 0:01:19  iter: 1419  total_loss: 0.4154  loss_ce: 0.0002601  loss_mask: 0.02467  loss_dice: 0.04165  loss_ce_0: 0.0006435  loss_mask_0: 0.02381  loss_dice_0: 0.04287  loss_ce_1: 0.0004508  loss_mask_1: 0.02372  loss_dice_1: 0.04202  loss_ce_2: 0.0004106  loss_mask_2: 0.02415  loss_dice_2: 0.04185  loss_ce_3: 0.0003315  loss_mask_3: 0.02429  loss_dice_3: 0.04202  loss_ce_4: 0.0003012  loss_mask_4: 0.02485  loss_dice_4: 0.04204  time: 0.4446  data_time: 0.0745  lr: 2.6615e-05  max_mem: 5424M
[01/29 15:13:17] d2.utils.events INFO:  eta: 0:01:10  iter: 1439  total_loss: 0.4357  loss_ce: 0.0002263  loss_mask: 0.02487  loss_dice: 0.04115  loss_ce_0: 0.0006431  loss_mask_0: 0.02437  loss_dice_0: 0.04183  loss_ce_1: 0.0004662  loss_mask_1: 0.02459  loss_dice_1: 0.04131  loss_ce_2: 0.0004111  loss_mask_2: 0.02455  loss_dice_2: 0.04141  loss_ce_3: 0.0003352  loss_mask_3: 0.02461  loss_dice_3: 0.04104  loss_ce_4: 0.0002772  loss_mask_4: 0.02466  loss_dice_4: 0.04131  time: 0.4446  data_time: 0.0729  lr: 2.429e-05  max_mem: 5424M
[01/29 15:13:26] d2.utils.events INFO:  eta: 0:01:02  iter: 1459  total_loss: 0.3945  loss_ce: 0.0002282  loss_mask: 0.02247  loss_dice: 0.04261  loss_ce_0: 0.0006344  loss_mask_0: 0.02214  loss_dice_0: 0.04262  loss_ce_1: 0.0004133  loss_mask_1: 0.02244  loss_dice_1: 0.04298  loss_ce_2: 0.0004095  loss_mask_2: 0.02271  loss_dice_2: 0.04303  loss_ce_3: 0.0003123  loss_mask_3: 0.02252  loss_dice_3: 0.04274  loss_ce_4: 0.0002782  loss_mask_4: 0.02237  loss_dice_4: 0.04278  time: 0.4446  data_time: 0.0766  lr: 2.1857e-05  max_mem: 5424M
[01/29 15:13:35] d2.utils.events INFO:  eta: 0:00:53  iter: 1479  total_loss: 0.3949  loss_ce: 0.0002286  loss_mask: 0.02298  loss_dice: 0.04467  loss_ce_0: 0.0006784  loss_mask_0: 0.02324  loss_dice_0: 0.04445  loss_ce_1: 0.0004745  loss_mask_1: 0.02351  loss_dice_1: 0.04485  loss_ce_2: 0.0003984  loss_mask_2: 0.023  loss_dice_2: 0.04513  loss_ce_3: 0.0003096  loss_mask_3: 0.02285  loss_dice_3: 0.04493  loss_ce_4: 0.0002691  loss_mask_4: 0.02293  loss_dice_4: 0.04479  time: 0.4447  data_time: 0.0766  lr: 1.9307e-05  max_mem: 5424M
[01/29 15:13:43] d2.utils.events INFO:  eta: 0:00:44  iter: 1499  total_loss: 0.387  loss_ce: 0.0001848  loss_mask: 0.02293  loss_dice: 0.04027  loss_ce_0: 0.000517  loss_mask_0: 0.02286  loss_dice_0: 0.04036  loss_ce_1: 0.000394  loss_mask_1: 0.02313  loss_dice_1: 0.04018  loss_ce_2: 0.0003502  loss_mask_2: 0.02258  loss_dice_2: 0.0404  loss_ce_3: 0.0002671  loss_mask_3: 0.02259  loss_dice_3: 0.04038  loss_ce_4: 0.0002277  loss_mask_4: 0.02297  loss_dice_4: 0.04009  time: 0.4447  data_time: 0.0753  lr: 1.6631e-05  max_mem: 5424M
[01/29 15:13:53] d2.utils.events INFO:  eta: 0:00:35  iter: 1519  total_loss: 0.4119  loss_ce: 0.0002166  loss_mask: 0.02283  loss_dice: 0.04311  loss_ce_0: 0.0005218  loss_mask_0: 0.02375  loss_dice_0: 0.0443  loss_ce_1: 0.0003929  loss_mask_1: 0.02333  loss_dice_1: 0.04364  loss_ce_2: 0.0003651  loss_mask_2: 0.02326  loss_dice_2: 0.04337  loss_ce_3: 0.0003064  loss_mask_3: 0.02319  loss_dice_3: 0.0432  loss_ce_4: 0.000261  loss_mask_4: 0.0228  loss_dice_4: 0.04306  time: 0.4447  data_time: 0.0778  lr: 1.3645e-05  max_mem: 5424M
[01/29 15:14:01] d2.utils.events INFO:  eta: 0:00:26  iter: 1539  total_loss: 0.3431  loss_ce: 0.0001953  loss_mask: 0.0205  loss_dice: 0.0367  loss_ce_0: 0.0005216  loss_mask_0: 0.02083  loss_dice_0: 0.03714  loss_ce_1: 0.000349  loss_mask_1: 0.021  loss_dice_1: 0.03685  loss_ce_2: 0.0003367  loss_mask_2: 0.02118  loss_dice_2: 0.03673  loss_ce_3: 0.0002726  loss_mask_3: 0.02079  loss_dice_3: 0.03666  loss_ce_4: 0.0002324  loss_mask_4: 0.02057  loss_dice_4: 0.0368  time: 0.4448  data_time: 0.0753  lr: 1.0571e-05  max_mem: 5424M
[01/29 15:14:10] d2.utils.events INFO:  eta: 0:00:17  iter: 1559  total_loss: 0.3986  loss_ce: 0.0002165  loss_mask: 0.02138  loss_dice: 0.0421  loss_ce_0: 0.0006018  loss_mask_0: 0.02156  loss_dice_0: 0.0417  loss_ce_1: 0.000382  loss_mask_1: 0.02183  loss_dice_1: 0.04162  loss_ce_2: 0.0003537  loss_mask_2: 0.02149  loss_dice_2: 0.04175  loss_ce_3: 0.0002996  loss_mask_3: 0.0217  loss_dice_3: 0.04185  loss_ce_4: 0.0002563  loss_mask_4: 0.02143  loss_dice_4: 0.0421  time: 0.4448  data_time: 0.0767  lr: 7.3931e-06  max_mem: 5424M
[01/29 15:14:19] d2.utils.events INFO:  eta: 0:00:08  iter: 1579  total_loss: 0.3907  loss_ce: 0.000217  loss_mask: 0.02239  loss_dice: 0.04173  loss_ce_0: 0.0005661  loss_mask_0: 0.02248  loss_dice_0: 0.04187  loss_ce_1: 0.000384  loss_mask_1: 0.02218  loss_dice_1: 0.04192  loss_ce_2: 0.000352  loss_mask_2: 0.02203  loss_dice_2: 0.04198  loss_ce_3: 0.0003024  loss_mask_3: 0.02227  loss_dice_3: 0.04183  loss_ce_4: 0.0002538  loss_mask_4: 0.02223  loss_dice_4: 0.04175  time: 0.4447  data_time: 0.0762  lr: 4.0487e-06  max_mem: 5424M
[01/29 15:14:28] fvcore.common.checkpoint INFO: Saving checkpoint to ./ffiModel/model_final.pth
[01/29 15:14:30] d2.utils.events INFO:  eta: 0:00:00  iter: 1599  total_loss: 0.3896  loss_ce: 0.0002065  loss_mask: 0.02273  loss_dice: 0.04004  loss_ce_0: 0.0005403  loss_mask_0: 0.02296  loss_dice_0: 0.0405  loss_ce_1: 0.0003919  loss_mask_1: 0.02263  loss_dice_1: 0.04018  loss_ce_2: 0.0003369  loss_mask_2: 0.02282  loss_dice_2: 0.04019  loss_ce_3: 0.0002763  loss_mask_3: 0.02292  loss_dice_3: 0.04012  loss_ce_4: 0.000236  loss_mask_4: 0.0226  loss_dice_4: 0.04002  time: 0.4447  data_time: 0.0747  lr: 2.6141e-07  max_mem: 5424M
[01/29 15:14:30] d2.engine.hooks INFO: Overall training speed: 1598 iterations in 0:11:50 (0.4447 s / it)
[01/29 15:14:30] d2.engine.hooks INFO: Total training time: 0:11:59 (0:00:09 on hooks)
[01/29 15:14:30] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:14:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/29 15:14:30] d2.data.common INFO: Serializing 9 elements to byte tensors and concatenating them all ...
[01/29 15:14:30] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 15:14:30] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:14:30] d2.evaluation.evaluator INFO: Start inference on 9 batches
[01/29 15:14:31] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.337638 (0.084410 s / iter per device, on 1 devices)
[01/29 15:14:31] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.045343 s / iter per device, on 1 devices)
[01/29 15:14:31] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 97.7725468082559, 'fwIoU': 98.6682978837308, 'IoU-Grass': nan, 'IoU-CameraEdge': 97.5614082899263, 'IoU-Vehicle': 96.03389164942381, 'IoU-Person': nan, 'IoU-Bush': 96.4167803847339, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 98.41080930912133, 'IoU-Large_stone': 99.20296220764429, 'IoU-Forrest': nan, 'IoU-Gravel': 99.00942900868563, 'mACC': 98.72032108026512, 'pACC': 99.3288972252651, 'ACC-Grass': nan, 'ACC-CameraEdge': 98.47321608138003, 'ACC-Vehicle': 97.09115895556573, 'ACC-Person': nan, 'ACC-Bush': 98.31231204273082, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 99.23738046241375, 'ACC-Large_stone': 99.77170055191196, 'ACC-Forrest': nan, 'ACC-Gravel': 99.43615838758836})])
[01/29 15:14:31] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:14:31] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/29 15:14:31] d2.data.common INFO: Serializing 9 elements to byte tensors and concatenating them all ...
[01/29 15:14:31] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/29 15:14:31] d2.data.datasets.coco INFO: Loaded 9 images with semantic segmentation from ../../../data/dataset/train/images
[01/29 15:14:31] d2.evaluation.evaluator INFO: Start inference on 9 batches
[01/29 15:14:31] d2.evaluation.evaluator INFO: Total inference time: 0:00:00.335322 (0.083831 s / iter per device, on 1 devices)
[01/29 15:14:31] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:00 (0.044951 s / iter per device, on 1 devices)
[01/29 15:14:31] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 97.7725468082559, 'fwIoU': 98.6682978837308, 'IoU-Grass': nan, 'IoU-CameraEdge': 97.5614082899263, 'IoU-Vehicle': 96.03389164942381, 'IoU-Person': nan, 'IoU-Bush': 96.4167803847339, 'IoU-Puddle': nan, 'IoU-Building': nan, 'IoU-Dirtroad': nan, 'IoU-Sky': 98.41080930912133, 'IoU-Large_stone': 99.20296220764429, 'IoU-Forrest': nan, 'IoU-Gravel': 99.00942900868563, 'mACC': 98.72032108026512, 'pACC': 99.3288972252651, 'ACC-Grass': nan, 'ACC-CameraEdge': 98.47321608138003, 'ACC-Vehicle': 97.09115895556573, 'ACC-Person': nan, 'ACC-Bush': 98.31231204273082, 'ACC-Puddle': nan, 'ACC-Building': nan, 'ACC-Dirtroad': nan, 'ACC-Sky': 99.23738046241375, 'ACC-Large_stone': 99.77170055191196, 'ACC-Forrest': nan, 'ACC-Gravel': 99.43615838758836})])
[01/29 15:26:02] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 21:55:27] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 21:55:28] detectron2 INFO: Environment info:
----------------------  ------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]
numpy                   1.20.3
detectron2              0.6 @/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 9.3
CUDA compiler           CUDA 11.4
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.1+cu102 @/usr/local/lib/python3.8/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   GRID RTX8000-8Q (arch=7.5)
Driver version          470.63.01
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.1+cu102 @/usr/local/lib/python3.8/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.4
----------------------  ------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 21:55:28] detectron2 INFO: Command line arguments: Namespace(config_file='', dist_url='tcp://127.0.0.1:54076', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/31 21:55:28] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m  [39m-[38;5;15m [39mffi_train_stuffonly
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mabsolute
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39mmask_former_semantic
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mbitmask
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m256
[38;5;15m  [39m-[38;5;15m [39m307
[38;5;15m  [39m-[38;5;15m [39m358
[38;5;15m  [39m-[38;5;15m [39m409
[38;5;15m  [39m-[38;5;15m [39m460
[38;5;15m  [39m-[38;5;15m [39m512
[38;5;15m  [39m-[38;5;15m [39m563
[38;5;15m  [39m-[38;5;15m [39m614
[38;5;15m  [39m-[38;5;15m [39m665
[38;5;15m  [39m-[38;5;15m [39m716
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m819
[38;5;15m  [39m-[38;5;15m [39m870
[38;5;15m  [39m-[38;5;15m [39m921
[38;5;15m  [39m-[38;5;15m [39m972
[38;5;15m  [39m-[38;5;15m [39m1024
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m      [39m-[38;5;15m [39m64
[38;5;15m      [39m-[38;5;15m [39m128
[38;5;15m      [39m-[38;5;15m [39m256
[38;5;15m      [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mD2SwinTransformer
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m6
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m20.0
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m32
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39mres5
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mMaskFormer
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m123.675
[38;5;15m  [39m-[38;5;15m [39m116.28
[38;5;15m  [39m-[38;5;15m [39m103.53
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m58.395
[38;5;15m  [39m-[38;5;15m [39m57.12
[38;5;15m  [39m-[38;5;15m [39m57.375
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39mbasic
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id003[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRes5ROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id003[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m6000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m12000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m18
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39mhard_pixel_mining
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskFormerHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m12
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39mBasePixelDecoder
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m48
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.3
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m96
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m4.0
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m3
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m24
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m224
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m7
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39mmodels/model_final_8657a5.pkl
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m./ffiModel
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.0002
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mfull_model
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupPolyLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m1450
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39mADAMW
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0e-06
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m1500
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m3584
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m384
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m640
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m896
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m145
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[01/31 21:55:28] detectron2 INFO: Full config saved to ./ffiModel/config.yaml
[01/31 21:55:28] d2.utils.env INFO: Using a generated random seed 28804103
[01/31 21:55:32] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): BasePixelDecoder(
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_2): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_3): Conv2d(
        384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_4): Conv2d(
        768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (predictor): TransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList()
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (3): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (4): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (5): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (query_embed): Embedding(100, 256)
      (input_proj): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (class_embed): Linear(in_features=256, out_features=13, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 1.0
  )
)
[01/31 21:55:32] mask_former.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerSemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2048, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[512, 512], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f8e123a90d0>, RandomFlip()]
[01/31 21:55:32] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 21:55:32] d2.data.build INFO: Using training sampler TrainingSampler
[01/31 21:55:32] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 21:55:32] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 21:55:32] fvcore.common.checkpoint INFO: [Checkpointer] Loading from models/model_final_8657a5.pkl ...
[01/31 21:55:32] fvcore.common.checkpoint INFO: Reading a file from 'MaskFormer Model Zoo'
[01/31 21:55:32] mask_former.modeling.heads.mask_former_head WARNING: Weight format of MaskFormerHead have changed! Please upgrade your models. Applying automatic conversion now ...
[01/31 21:55:32] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (151, 256) in the checkpoint but (13, 256) in the model! You might want to double check if this is expected.
[01/31 21:55:32] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/31 21:55:32] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/31 21:55:32] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[01/31 21:55:32] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 21:55:42] d2.utils.events INFO:  eta: 0:10:52  iter: 19  total_loss: 16.38  loss_ce: 2.179  loss_mask: 0.1949  loss_dice: 0.3648  loss_ce_0: 2.047  loss_mask_0: 0.2152  loss_dice_0: 0.3568  loss_ce_1: 2.124  loss_mask_1: 0.2077  loss_dice_1: 0.3601  loss_ce_2: 2.26  loss_mask_2: 0.2065  loss_dice_2: 0.3718  loss_ce_3: 2.203  loss_mask_3: 0.1878  loss_dice_3: 0.3728  loss_ce_4: 2.193  loss_mask_4: 0.1932  loss_dice_4: 0.362  time: 0.4560  data_time: 0.0864  lr: 2.5036e-06  max_mem: 5278M
[01/31 21:55:51] d2.utils.events INFO:  eta: 0:10:43  iter: 39  total_loss: 12.7  loss_ce: 1.57  loss_mask: 0.1688  loss_dice: 0.3274  loss_ce_0: 1.736  loss_mask_0: 0.1753  loss_dice_0: 0.3254  loss_ce_1: 1.731  loss_mask_1: 0.1705  loss_dice_1: 0.324  loss_ce_2: 1.685  loss_mask_2: 0.1746  loss_dice_2: 0.3183  loss_ce_3: 1.633  loss_mask_3: 0.1651  loss_dice_3: 0.3242  loss_ce_4: 1.581  loss_mask_4: 0.1649  loss_dice_4: 0.3292  time: 0.4564  data_time: 0.0792  lr: 5.0741e-06  max_mem: 5278M
[01/31 21:56:00] d2.utils.events INFO:  eta: 0:10:34  iter: 59  total_loss: 10.05  loss_ce: 1.204  loss_mask: 0.1243  loss_dice: 0.2687  loss_ce_0: 1.398  loss_mask_0: 0.1206  loss_dice_0: 0.2801  loss_ce_1: 1.337  loss_mask_1: 0.1237  loss_dice_1: 0.2686  loss_ce_2: 1.265  loss_mask_2: 0.1247  loss_dice_2: 0.2659  loss_ce_3: 1.219  loss_mask_3: 0.1201  loss_dice_3: 0.269  loss_ce_4: 1.209  loss_mask_4: 0.1307  loss_dice_4: 0.262  time: 0.4562  data_time: 0.0775  lr: 7.5782e-06  max_mem: 5316M
[01/31 21:56:09] d2.utils.events INFO:  eta: 0:10:24  iter: 79  total_loss: 7.984  loss_ce: 0.9697  loss_mask: 0.1121  loss_dice: 0.2028  loss_ce_0: 1.174  loss_mask_0: 0.1122  loss_dice_0: 0.2234  loss_ce_1: 1.071  loss_mask_1: 0.1058  loss_dice_1: 0.2098  loss_ce_2: 1.006  loss_mask_2: 0.1149  loss_dice_2: 0.201  loss_ce_3: 0.9741  loss_mask_3: 0.1104  loss_dice_3: 0.2093  loss_ce_4: 0.971  loss_mask_4: 0.1161  loss_dice_4: 0.2017  time: 0.4559  data_time: 0.0787  lr: 1.0016e-05  max_mem: 5316M
[01/31 21:56:18] d2.utils.events INFO:  eta: 0:10:14  iter: 99  total_loss: 6.928  loss_ce: 0.791  loss_mask: 0.1079  loss_dice: 0.174  loss_ce_0: 0.9963  loss_mask_0: 0.1073  loss_dice_0: 0.1907  loss_ce_1: 0.8991  loss_mask_1: 0.1095  loss_dice_1: 0.183  loss_ce_2: 0.8675  loss_mask_2: 0.1099  loss_dice_2: 0.1784  loss_ce_3: 0.841  loss_mask_3: 0.1108  loss_dice_3: 0.1743  loss_ce_4: 0.8117  loss_mask_4: 0.1109  loss_dice_4: 0.1728  time: 0.4555  data_time: 0.0813  lr: 1.2386e-05  max_mem: 5316M
[01/31 21:56:27] d2.utils.events INFO:  eta: 0:10:05  iter: 119  total_loss: 5.95  loss_ce: 0.6633  loss_mask: 0.09127  loss_dice: 0.1556  loss_ce_0: 0.9215  loss_mask_0: 0.08356  loss_dice_0: 0.1689  loss_ce_1: 0.7936  loss_mask_1: 0.09638  loss_dice_1: 0.1668  loss_ce_2: 0.7451  loss_mask_2: 0.08994  loss_dice_2: 0.1646  loss_ce_3: 0.7026  loss_mask_3: 0.08976  loss_dice_3: 0.1683  loss_ce_4: 0.6698  loss_mask_4: 0.09002  loss_dice_4: 0.1593  time: 0.4550  data_time: 0.0798  lr: 1.469e-05  max_mem: 5316M
[01/31 21:56:37] d2.utils.events INFO:  eta: 0:09:56  iter: 139  total_loss: 4.926  loss_ce: 0.4489  loss_mask: 0.1037  loss_dice: 0.1736  loss_ce_0: 0.6709  loss_mask_0: 0.1097  loss_dice_0: 0.176  loss_ce_1: 0.5917  loss_mask_1: 0.113  loss_dice_1: 0.1647  loss_ce_2: 0.5549  loss_mask_2: 0.1028  loss_dice_2: 0.1691  loss_ce_3: 0.4695  loss_mask_3: 0.1032  loss_dice_3: 0.1735  loss_ce_4: 0.4523  loss_mask_4: 0.09947  loss_dice_4: 0.1768  time: 0.4563  data_time: 0.0813  lr: 1.6927e-05  max_mem: 5316M
[01/31 21:56:39] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 21:56:39] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 21:56:39] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 21:56:39] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 21:56:39] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 21:56:39] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 21:56:40] d2.evaluation.evaluator INFO: Inference done 11/29. Dataloading: 0.0013 s/iter. Inference: 0.0470 s/iter. Eval: 0.0240 s/iter. Total: 0.0724 s/iter. ETA=0:00:01
[01/31 21:56:41] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.759882 (0.073328 s / iter per device, on 1 devices)
[01/31 21:56:41] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.046849 s / iter per device, on 1 devices)
[01/31 21:56:41] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 41.995868182407555, 'fwIoU': 70.19574908260408, 'IoU-Grass': nan, 'IoU-CameraEdge': 52.545353248135285, 'IoU-Vehicle': 88.43984551147264, 'IoU-Person': nan, 'IoU-Bush': 0.0, 'IoU-Puddle': 0.0, 'IoU-Building': 0.0, 'IoU-Dirtroad': nan, 'IoU-Sky': 83.65320586585241, 'IoU-Large_stone': 96.33825293994546, 'IoU-Forrest': nan, 'IoU-Gravel': 14.990287893854648, 'mACC': 48.38489187716689, 'pACC': 80.46619705012421, 'ACC-Grass': nan, 'ACC-CameraEdge': 98.995569847273, 'ACC-Vehicle': 91.8157430387192, 'ACC-Person': nan, 'ACC-Bush': 0.0, 'ACC-Puddle': 0.0, 'ACC-Building': 0.0, 'ACC-Dirtroad': nan, 'ACC-Sky': 84.35119225780704, 'ACC-Large_stone': 96.62193065623939, 'ACC-Forrest': nan, 'ACC-Gravel': 15.294699217296529})])
[01/31 21:56:41] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 21:56:41] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 21:56:41] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 21:56:41] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 21:56:41] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 21:56:41] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 21:56:43] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.727713 (0.071988 s / iter per device, on 1 devices)
[01/31 21:56:43] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.045468 s / iter per device, on 1 devices)
[01/31 21:56:43] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 41.995868182407555, 'fwIoU': 70.19574908260408, 'IoU-Grass': nan, 'IoU-CameraEdge': 52.545353248135285, 'IoU-Vehicle': 88.43984551147264, 'IoU-Person': nan, 'IoU-Bush': 0.0, 'IoU-Puddle': 0.0, 'IoU-Building': 0.0, 'IoU-Dirtroad': nan, 'IoU-Sky': 83.65320586585241, 'IoU-Large_stone': 96.33825293994546, 'IoU-Forrest': nan, 'IoU-Gravel': 14.990287893854648, 'mACC': 48.38489187716689, 'pACC': 80.46619705012421, 'ACC-Grass': nan, 'ACC-CameraEdge': 98.995569847273, 'ACC-Vehicle': 91.8157430387192, 'ACC-Person': nan, 'ACC-Bush': 0.0, 'ACC-Puddle': 0.0, 'ACC-Building': 0.0, 'ACC-Dirtroad': nan, 'ACC-Sky': 84.35119225780704, 'ACC-Large_stone': 96.62193065623939, 'ACC-Forrest': nan, 'ACC-Gravel': 15.294699217296529})])
[01/31 21:56:50] d2.utils.events INFO:  eta: 0:09:47  iter: 159  total_loss: 3.932  loss_ce: 0.3204  loss_mask: 0.08871  loss_dice: 0.1649  loss_ce_0: 0.522  loss_mask_0: 0.1042  loss_dice_0: 0.1447  loss_ce_1: 0.4387  loss_mask_1: 0.101  loss_dice_1: 0.1564  loss_ce_2: 0.3875  loss_mask_2: 0.09669  loss_dice_2: 0.1544  loss_ce_3: 0.3582  loss_mask_3: 0.09209  loss_dice_3: 0.1636  loss_ce_4: 0.347  loss_mask_4: 0.08594  loss_dice_4: 0.1569  time: 0.4567  data_time: 0.0770  lr: 1.9096e-05  max_mem: 5316M
[01/31 21:56:59] d2.utils.events INFO:  eta: 0:09:38  iter: 179  total_loss: 3.039  loss_ce: 0.2182  loss_mask: 0.08533  loss_dice: 0.1577  loss_ce_0: 0.4017  loss_mask_0: 0.09657  loss_dice_0: 0.1632  loss_ce_1: 0.3108  loss_mask_1: 0.09978  loss_dice_1: 0.1603  loss_ce_2: 0.2778  loss_mask_2: 0.09463  loss_dice_2: 0.1539  loss_ce_3: 0.2463  loss_mask_3: 0.0899  loss_dice_3: 0.1562  loss_ce_4: 0.233  loss_mask_4: 0.09201  loss_dice_4: 0.1529  time: 0.4567  data_time: 0.0759  lr: 2.1198e-05  max_mem: 5316M
[01/31 21:57:09] d2.utils.events INFO:  eta: 0:09:29  iter: 199  total_loss: 2.772  loss_ce: 0.1942  loss_mask: 0.08746  loss_dice: 0.1595  loss_ce_0: 0.3305  loss_mask_0: 0.09676  loss_dice_0: 0.1532  loss_ce_1: 0.2212  loss_mask_1: 0.105  loss_dice_1: 0.1491  loss_ce_2: 0.222  loss_mask_2: 0.0866  loss_dice_2: 0.156  loss_ce_3: 0.1791  loss_mask_3: 0.08887  loss_dice_3: 0.1584  loss_ce_4: 0.1983  loss_mask_4: 0.09231  loss_dice_4: 0.1594  time: 0.4575  data_time: 0.0806  lr: 2.3232e-05  max_mem: 5316M
[01/31 21:57:10] d2.engine.hooks INFO: Overall training speed: 201 iterations in 0:01:32 (0.4593 s / it)
[01/31 21:57:10] d2.engine.hooks INFO: Total training time: 0:01:37 (0:00:04 on hooks)
[01/31 21:57:10] d2.utils.events INFO:  eta: 0:09:27  iter: 203  total_loss: 2.76  loss_ce: 0.2081  loss_mask: 0.08452  loss_dice: 0.1515  loss_ce_0: 0.3091  loss_mask_0: 0.09676  loss_dice_0: 0.1515  loss_ce_1: 0.2122  loss_mask_1: 0.09663  loss_dice_1: 0.146  loss_ce_2: 0.2067  loss_mask_2: 0.08651  loss_dice_2: 0.1498  loss_ce_3: 0.1867  loss_mask_3: 0.08439  loss_dice_3: 0.1508  loss_ce_4: 0.1904  loss_mask_4: 0.08729  loss_dice_4: 0.1529  time: 0.4575  data_time: 0.0808  lr: 2.3532e-05  max_mem: 5316M
[01/31 22:00:21] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 22:00:22] detectron2 INFO: Environment info:
----------------------  ------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]
numpy                   1.20.3
detectron2              0.6 @/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 9.3
CUDA compiler           CUDA 11.4
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.1+cu102 @/usr/local/lib/python3.8/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   GRID RTX8000-8Q (arch=7.5)
Driver version          470.63.01
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.1+cu102 @/usr/local/lib/python3.8/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.4
----------------------  ------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 22:00:22] detectron2 INFO: Command line arguments: Namespace(config_file='', dist_url='tcp://127.0.0.1:54076', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/31 22:00:22] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m  [39m-[38;5;15m [39mffi_train_stuffonly
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mabsolute
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39mmask_former_semantic
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mbitmask
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m256
[38;5;15m  [39m-[38;5;15m [39m307
[38;5;15m  [39m-[38;5;15m [39m358
[38;5;15m  [39m-[38;5;15m [39m409
[38;5;15m  [39m-[38;5;15m [39m460
[38;5;15m  [39m-[38;5;15m [39m512
[38;5;15m  [39m-[38;5;15m [39m563
[38;5;15m  [39m-[38;5;15m [39m614
[38;5;15m  [39m-[38;5;15m [39m665
[38;5;15m  [39m-[38;5;15m [39m716
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m819
[38;5;15m  [39m-[38;5;15m [39m870
[38;5;15m  [39m-[38;5;15m [39m921
[38;5;15m  [39m-[38;5;15m [39m972
[38;5;15m  [39m-[38;5;15m [39m1024
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m      [39m-[38;5;15m [39m64
[38;5;15m      [39m-[38;5;15m [39m128
[38;5;15m      [39m-[38;5;15m [39m256
[38;5;15m      [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mD2SwinTransformer
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m6
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m20.0
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m32
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39mres5
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mMaskFormer
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m123.675
[38;5;15m  [39m-[38;5;15m [39m116.28
[38;5;15m  [39m-[38;5;15m [39m103.53
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m58.395
[38;5;15m  [39m-[38;5;15m [39m57.12
[38;5;15m  [39m-[38;5;15m [39m57.375
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39mbasic
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id003[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRes5ROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id003[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m6000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m12000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m18
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39mhard_pixel_mining
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskFormerHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m12
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39mBasePixelDecoder
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m48
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.3
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m96
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m4.0
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m3
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m24
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m224
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m7
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39mmodels/model_final_8657a5.pkl
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m./ffiModel
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.0002
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mfull_model
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupPolyLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m1450
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39mADAMW
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0e-06
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m1500
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m3584
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m384
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m640
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m896
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m145
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[01/31 22:00:22] detectron2 INFO: Full config saved to ./ffiModel/config.yaml
[01/31 22:00:22] d2.utils.env INFO: Using a generated random seed 22741892
[01/31 22:00:26] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): BasePixelDecoder(
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_2): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_3): Conv2d(
        384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_4): Conv2d(
        768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (predictor): TransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList()
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (3): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (4): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (5): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (query_embed): Embedding(100, 256)
      (input_proj): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (class_embed): Linear(in_features=256, out_features=13, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 1.0
  )
)
[01/31 22:00:26] mask_former.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerSemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2048, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[512, 512], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f3e5b2990d0>, RandomFlip()]
[01/31 22:00:26] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:00:26] d2.data.build INFO: Using training sampler TrainingSampler
[01/31 22:00:26] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:00:26] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:00:26] fvcore.common.checkpoint INFO: [Checkpointer] Loading from models/model_final_8657a5.pkl ...
[01/31 22:00:26] fvcore.common.checkpoint INFO: Reading a file from 'MaskFormer Model Zoo'
[01/31 22:00:26] mask_former.modeling.heads.mask_former_head WARNING: Weight format of MaskFormerHead have changed! Please upgrade your models. Applying automatic conversion now ...
[01/31 22:00:26] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (151, 256) in the checkpoint but (13, 256) in the model! You might want to double check if this is expected.
[01/31 22:00:26] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/31 22:00:26] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/31 22:00:26] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[01/31 22:00:26] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 22:00:35] d2.utils.events INFO:  eta: 0:10:45  iter: 19  total_loss: 20.52  loss_ce: 2.667  loss_mask: 0.1952  loss_dice: 0.3686  loss_ce_0: 3.047  loss_mask_0: 0.2442  loss_dice_0: 0.3506  loss_ce_1: 2.883  loss_mask_1: 0.2138  loss_dice_1: 0.3518  loss_ce_2: 2.878  loss_mask_2: 0.2508  loss_dice_2: 0.3661  loss_ce_3: 2.9  loss_mask_3: 0.1986  loss_dice_3: 0.366  loss_ce_4: 2.736  loss_mask_4: 0.1973  loss_dice_4: 0.3654  time: 0.4527  data_time: 0.0859  lr: 2.5036e-06  max_mem: 5398M
[01/31 22:00:44] d2.utils.events INFO:  eta: 0:10:37  iter: 39  total_loss: 16.18  loss_ce: 1.913  loss_mask: 0.1603  loss_dice: 0.3601  loss_ce_0: 2.47  loss_mask_0: 0.2009  loss_dice_0: 0.3446  loss_ce_1: 2.253  loss_mask_1: 0.1815  loss_dice_1: 0.3417  loss_ce_2: 2.176  loss_mask_2: 0.1826  loss_dice_2: 0.3543  loss_ce_3: 2.178  loss_mask_3: 0.1598  loss_dice_3: 0.347  loss_ce_4: 1.966  loss_mask_4: 0.1663  loss_dice_4: 0.3543  time: 0.4521  data_time: 0.0812  lr: 5.0741e-06  max_mem: 5398M
[01/31 22:00:54] d2.utils.events INFO:  eta: 0:10:27  iter: 59  total_loss: 11.48  loss_ce: 1.364  loss_mask: 0.1465  loss_dice: 0.3286  loss_ce_0: 1.727  loss_mask_0: 0.1597  loss_dice_0: 0.3199  loss_ce_1: 1.558  loss_mask_1: 0.1397  loss_dice_1: 0.3209  loss_ce_2: 1.432  loss_mask_2: 0.1525  loss_dice_2: 0.3049  loss_ce_3: 1.4  loss_mask_3: 0.147  loss_dice_3: 0.3098  loss_ce_4: 1.387  loss_mask_4: 0.144  loss_dice_4: 0.3123  time: 0.4519  data_time: 0.0788  lr: 7.5782e-06  max_mem: 5398M
[01/31 22:01:03] d2.utils.events INFO:  eta: 0:10:18  iter: 79  total_loss: 9.516  loss_ce: 1.176  loss_mask: 0.1129  loss_dice: 0.2209  loss_ce_0: 1.318  loss_mask_0: 0.1313  loss_dice_0: 0.2503  loss_ce_1: 1.292  loss_mask_1: 0.1181  loss_dice_1: 0.2259  loss_ce_2: 1.252  loss_mask_2: 0.1202  loss_dice_2: 0.2275  loss_ce_3: 1.208  loss_mask_3: 0.1162  loss_dice_3: 0.2219  loss_ce_4: 1.175  loss_mask_4: 0.1156  loss_dice_4: 0.2246  time: 0.4520  data_time: 0.0771  lr: 1.0016e-05  max_mem: 5398M
[01/31 22:01:12] d2.utils.events INFO:  eta: 0:10:09  iter: 99  total_loss: 8.712  loss_ce: 1.04  loss_mask: 0.1141  loss_dice: 0.2263  loss_ce_0: 1.217  loss_mask_0: 0.1151  loss_dice_0: 0.2329  loss_ce_1: 1.168  loss_mask_1: 0.1112  loss_dice_1: 0.2148  loss_ce_2: 1.1  loss_mask_2: 0.1195  loss_dice_2: 0.2109  loss_ce_3: 1.076  loss_mask_3: 0.1141  loss_dice_3: 0.2176  loss_ce_4: 1.046  loss_mask_4: 0.1153  loss_dice_4: 0.2095  time: 0.4519  data_time: 0.0796  lr: 1.2386e-05  max_mem: 5398M
[01/31 22:01:21] d2.utils.events INFO:  eta: 0:10:00  iter: 119  total_loss: 7.711  loss_ce: 0.8591  loss_mask: 0.08842  loss_dice: 0.1951  loss_ce_0: 1.149  loss_mask_0: 0.09726  loss_dice_0: 0.2121  loss_ce_1: 1.078  loss_mask_1: 0.09324  loss_dice_1: 0.1971  loss_ce_2: 0.9812  loss_mask_2: 0.09213  loss_dice_2: 0.1942  loss_ce_3: 0.9325  loss_mask_3: 0.09123  loss_dice_3: 0.2005  loss_ce_4: 0.891  loss_mask_4: 0.099  loss_dice_4: 0.1964  time: 0.4524  data_time: 0.0803  lr: 1.469e-05  max_mem: 5398M
[01/31 22:01:30] d2.utils.events INFO:  eta: 0:09:50  iter: 139  total_loss: 6.606  loss_ce: 0.6825  loss_mask: 0.108  loss_dice: 0.1837  loss_ce_0: 0.9711  loss_mask_0: 0.107  loss_dice_0: 0.194  loss_ce_1: 0.9342  loss_mask_1: 0.1177  loss_dice_1: 0.1719  loss_ce_2: 0.8017  loss_mask_2: 0.1167  loss_dice_2: 0.1801  loss_ce_3: 0.776  loss_mask_3: 0.1142  loss_dice_3: 0.1761  loss_ce_4: 0.704  loss_mask_4: 0.116  loss_dice_4: 0.1831  time: 0.4516  data_time: 0.0742  lr: 1.6927e-05  max_mem: 5398M
[01/31 22:01:32] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:01:32] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:01:32] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:01:32] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:01:32] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:01:32] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:01:33] d2.evaluation.evaluator INFO: Inference done 11/29. Dataloading: 0.0010 s/iter. Inference: 0.0466 s/iter. Eval: 0.0232 s/iter. Total: 0.0707 s/iter. ETA=0:00:01
[01/31 22:01:34] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.745073 (0.072711 s / iter per device, on 1 devices)
[01/31 22:01:34] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.046686 s / iter per device, on 1 devices)
[01/31 22:01:34] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 41.99812802527034, 'fwIoU': 70.22795760985333, 'IoU-other': nan, 'IoU-Grass': 53.20931476754345, 'IoU-CameraEdge': 88.24839587982757, 'IoU-Vehicle': nan, 'IoU-Person': 0.0, 'IoU-Bush': 0.0, 'IoU-Puddle': 0.0, 'IoU-Building': nan, 'IoU-Dirtroad': 86.85957909157474, 'IoU-Sky': 96.55679989398186, 'IoU-Large_stone': nan, 'IoU-Forrest': 11.110934569235106, 'IoU-Gravel': nan, 'mACC': 48.991234657507064, 'pACC': 81.11649779568225, 'ACC-other': nan, 'ACC-Grass': 94.12916664044654, 'ACC-CameraEdge': 95.39596692823771, 'ACC-Vehicle': nan, 'ACC-Person': 0.0, 'ACC-Bush': 0.0, 'ACC-Puddle': 0.0, 'ACC-Building': nan, 'ACC-Dirtroad': 91.72338621171306, 'ACC-Sky': 99.4559260378318, 'ACC-Large_stone': nan, 'ACC-Forrest': 11.225431441827384, 'ACC-Gravel': nan})])
[01/31 22:01:34] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 150, in train
    self.after_step()
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/train_loop.py", line 180, in after_step
    h.after_step()
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/hooks.py", line 552, in after_step
    self._do_eval()
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/hooks.py", line 525, in _do_eval
    results = self._func()
  File "/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2/engine/defaults.py", line 453, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "trainMaskSemantic.py", line 380, in test
    write_to_csv(results_train, trainName)
  File "trainMaskSemantic.py", line 77, in write_to_csv
    writer_object.writerow(new_data)
  File "/usr/lib/python3.8/csv.py", line 154, in writerow
    return self.writer.writerow(self._dict_to_list(rowdict))
  File "/usr/lib/python3.8/csv.py", line 149, in _dict_to_list
    raise ValueError("dict contains fields not in fieldnames: "
ValueError: dict contains fields not in fieldnames: 'IoU-other', 'ACC-other'
[01/31 22:01:34] d2.engine.hooks INFO: Overall training speed: 142 iterations in 0:01:04 (0.4547 s / it)
[01/31 22:01:34] d2.engine.hooks INFO: Total training time: 0:01:06 (0:00:02 on hooks)
[01/31 22:01:34] d2.utils.events INFO:  eta: 0:09:48  iter: 144  total_loss: 6.18  loss_ce: 0.6031  loss_mask: 0.1071  loss_dice: 0.1845  loss_ce_0: 0.9253  loss_mask_0: 0.1037  loss_dice_0: 0.1899  loss_ce_1: 0.8626  loss_mask_1: 0.1155  loss_dice_1: 0.1761  loss_ce_2: 0.7607  loss_mask_2: 0.113  loss_dice_2: 0.19  loss_ce_3: 0.6836  loss_mask_3: 0.1104  loss_dice_3: 0.1921  loss_ce_4: 0.6276  loss_mask_4: 0.1071  loss_dice_4: 0.1868  time: 0.4515  data_time: 0.0757  lr: 1.7475e-05  max_mem: 5398M
[01/31 22:05:49] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 22:05:49] detectron2 INFO: Environment info:
----------------------  ------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]
numpy                   1.20.3
detectron2              0.6 @/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 9.3
CUDA compiler           CUDA 11.4
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.1+cu102 @/usr/local/lib/python3.8/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   GRID RTX8000-8Q (arch=7.5)
Driver version          470.63.01
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.1+cu102 @/usr/local/lib/python3.8/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.4
----------------------  ------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 22:05:49] detectron2 INFO: Command line arguments: Namespace(config_file='', dist_url='tcp://127.0.0.1:54076', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/31 22:05:49] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m  [39m-[38;5;15m [39mffi_train_stuffonly
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mabsolute
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39mmask_former_semantic
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mbitmask
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m256
[38;5;15m  [39m-[38;5;15m [39m307
[38;5;15m  [39m-[38;5;15m [39m358
[38;5;15m  [39m-[38;5;15m [39m409
[38;5;15m  [39m-[38;5;15m [39m460
[38;5;15m  [39m-[38;5;15m [39m512
[38;5;15m  [39m-[38;5;15m [39m563
[38;5;15m  [39m-[38;5;15m [39m614
[38;5;15m  [39m-[38;5;15m [39m665
[38;5;15m  [39m-[38;5;15m [39m716
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m819
[38;5;15m  [39m-[38;5;15m [39m870
[38;5;15m  [39m-[38;5;15m [39m921
[38;5;15m  [39m-[38;5;15m [39m972
[38;5;15m  [39m-[38;5;15m [39m1024
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m      [39m-[38;5;15m [39m64
[38;5;15m      [39m-[38;5;15m [39m128
[38;5;15m      [39m-[38;5;15m [39m256
[38;5;15m      [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mD2SwinTransformer
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m6
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m20.0
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m32
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39mres5
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mMaskFormer
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m123.675
[38;5;15m  [39m-[38;5;15m [39m116.28
[38;5;15m  [39m-[38;5;15m [39m103.53
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m58.395
[38;5;15m  [39m-[38;5;15m [39m57.12
[38;5;15m  [39m-[38;5;15m [39m57.375
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39mbasic
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id003[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRes5ROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id003[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m6000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m12000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m18
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39mhard_pixel_mining
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskFormerHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m12
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39mBasePixelDecoder
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m48
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.3
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m96
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m4.0
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m3
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m24
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m224
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m7
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39mmodels/model_final_8657a5.pkl
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m./ffiModel
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.0002
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mfull_model
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupPolyLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m1450
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39mADAMW
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0e-06
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m1500
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m3584
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m384
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m640
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m896
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m145
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[01/31 22:05:49] detectron2 INFO: Full config saved to ./ffiModel/config.yaml
[01/31 22:05:49] d2.utils.env INFO: Using a generated random seed 50259375
[01/31 22:05:53] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): BasePixelDecoder(
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_2): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_3): Conv2d(
        384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_4): Conv2d(
        768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (predictor): TransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList()
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (3): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (4): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (5): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (query_embed): Embedding(100, 256)
      (input_proj): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (class_embed): Linear(in_features=256, out_features=13, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 1.0
  )
)
[01/31 22:05:53] mask_former.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerSemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2048, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[512, 512], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f37560ae0a0>, RandomFlip()]
[01/31 22:05:53] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:05:53] d2.data.build INFO: Using training sampler TrainingSampler
[01/31 22:05:53] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:05:53] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:05:53] fvcore.common.checkpoint INFO: [Checkpointer] Loading from models/model_final_8657a5.pkl ...
[01/31 22:05:54] fvcore.common.checkpoint INFO: Reading a file from 'MaskFormer Model Zoo'
[01/31 22:05:54] mask_former.modeling.heads.mask_former_head WARNING: Weight format of MaskFormerHead have changed! Please upgrade your models. Applying automatic conversion now ...
[01/31 22:05:54] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (151, 256) in the checkpoint but (13, 256) in the model! You might want to double check if this is expected.
[01/31 22:05:54] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/31 22:05:54] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/31 22:05:54] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[01/31 22:05:54] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 22:06:03] d2.utils.events INFO:  eta: 0:10:43  iter: 19  total_loss: 16.2  loss_ce: 2.175  loss_mask: 0.1897  loss_dice: 0.3539  loss_ce_0: 2.214  loss_mask_0: 0.2124  loss_dice_0: 0.3534  loss_ce_1: 2.051  loss_mask_1: 0.2065  loss_dice_1: 0.3549  loss_ce_2: 2.123  loss_mask_2: 0.2013  loss_dice_2: 0.3569  loss_ce_3: 2.159  loss_mask_3: 0.1808  loss_dice_3: 0.353  loss_ce_4: 2.249  loss_mask_4: 0.184  loss_dice_4: 0.3555  time: 0.4500  data_time: 0.0863  lr: 2.5036e-06  max_mem: 5316M
[01/31 22:06:12] d2.utils.events INFO:  eta: 0:10:34  iter: 39  total_loss: 13.07  loss_ce: 1.646  loss_mask: 0.178  loss_dice: 0.3365  loss_ce_0: 1.877  loss_mask_0: 0.1961  loss_dice_0: 0.3229  loss_ce_1: 1.686  loss_mask_1: 0.1792  loss_dice_1: 0.3327  loss_ce_2: 1.695  loss_mask_2: 0.1797  loss_dice_2: 0.3433  loss_ce_3: 1.684  loss_mask_3: 0.1801  loss_dice_3: 0.3419  loss_ce_4: 1.702  loss_mask_4: 0.1788  loss_dice_4: 0.3356  time: 0.4500  data_time: 0.0747  lr: 5.0741e-06  max_mem: 5316M
[01/31 22:06:20] d2.engine.hooks INFO: Overall training speed: 55 iterations in 0:00:25 (0.4567 s / it)
[01/31 22:06:20] d2.engine.hooks INFO: Total training time: 0:00:25 (0:00:00 on hooks)
[01/31 22:06:20] d2.utils.events INFO:  eta: 0:10:25  iter: 57  total_loss: 11.65  loss_ce: 1.436  loss_mask: 0.1537  loss_dice: 0.3116  loss_ce_0: 1.614  loss_mask_0: 0.1557  loss_dice_0: 0.303  loss_ce_1: 1.502  loss_mask_1: 0.1525  loss_dice_1: 0.3051  loss_ce_2: 1.49  loss_mask_2: 0.1637  loss_dice_2: 0.3144  loss_ce_3: 1.462  loss_mask_3: 0.1501  loss_dice_3: 0.3107  loss_ce_4: 1.451  loss_mask_4: 0.1473  loss_dice_4: 0.3042  time: 0.4496  data_time: 0.0742  lr: 7.2068e-06  max_mem: 5316M
[01/31 22:06:35] detectron2 INFO: Rank of current process: 0. World size: 1
[01/31 22:06:35] detectron2 INFO: Environment info:
----------------------  ------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]
numpy                   1.20.3
detectron2              0.6 @/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 9.3
CUDA compiler           CUDA 11.4
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.1+cu102 @/usr/local/lib/python3.8/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   GRID RTX8000-8Q (arch=7.5)
Driver version          470.63.01
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.1+cu102 @/usr/local/lib/python3.8/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.4
----------------------  ------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[01/31 22:06:35] detectron2 INFO: Command line arguments: Namespace(config_file='', dist_url='tcp://127.0.0.1:54076', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/31 22:06:35] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m  [39m-[38;5;15m [39mffi_train_stuffonly
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mabsolute
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39mmask_former_semantic
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mbitmask
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m256
[38;5;15m  [39m-[38;5;15m [39m307
[38;5;15m  [39m-[38;5;15m [39m358
[38;5;15m  [39m-[38;5;15m [39m409
[38;5;15m  [39m-[38;5;15m [39m460
[38;5;15m  [39m-[38;5;15m [39m512
[38;5;15m  [39m-[38;5;15m [39m563
[38;5;15m  [39m-[38;5;15m [39m614
[38;5;15m  [39m-[38;5;15m [39m665
[38;5;15m  [39m-[38;5;15m [39m716
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m819
[38;5;15m  [39m-[38;5;15m [39m870
[38;5;15m  [39m-[38;5;15m [39m921
[38;5;15m  [39m-[38;5;15m [39m972
[38;5;15m  [39m-[38;5;15m [39m1024
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m      [39m-[38;5;15m [39m64
[38;5;15m      [39m-[38;5;15m [39m128
[38;5;15m      [39m-[38;5;15m [39m256
[38;5;15m      [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mD2SwinTransformer
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m6
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m20.0
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m32
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39mres5
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mMaskFormer
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m123.675
[38;5;15m  [39m-[38;5;15m [39m116.28
[38;5;15m  [39m-[38;5;15m [39m103.53
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m58.395
[38;5;15m  [39m-[38;5;15m [39m57.12
[38;5;15m  [39m-[38;5;15m [39m57.375
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39mbasic
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id003[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRes5ROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id003[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m6000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m12000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m18
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39mhard_pixel_mining
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskFormerHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m12
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39mBasePixelDecoder
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m48
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.3
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m96
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m4.0
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m3
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m24
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m224
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m7
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39mmodels/model_final_8657a5.pkl
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m./ffiModel
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.0002
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mfull_model
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupPolyLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m1450
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39mADAMW
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0e-06
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m1500
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m3584
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m384
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m640
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m896
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m145
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[01/31 22:06:35] detectron2 INFO: Full config saved to ./ffiModel/config.yaml
[01/31 22:06:35] d2.utils.env INFO: Using a generated random seed 36539472
[01/31 22:06:40] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): BasePixelDecoder(
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_2): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_3): Conv2d(
        384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_4): Conv2d(
        768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (predictor): TransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList()
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (3): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (4): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (5): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (query_embed): Embedding(100, 256)
      (input_proj): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (class_embed): Linear(in_features=256, out_features=13, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 1.0
  )
)
[01/31 22:06:40] mask_former.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerSemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2048, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[512, 512], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f5d97702040>, RandomFlip()]
[01/31 22:06:40] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:06:40] d2.data.build INFO: Using training sampler TrainingSampler
[01/31 22:06:40] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:06:40] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:06:40] fvcore.common.checkpoint INFO: [Checkpointer] Loading from models/model_final_8657a5.pkl ...
[01/31 22:06:40] fvcore.common.checkpoint INFO: Reading a file from 'MaskFormer Model Zoo'
[01/31 22:06:40] mask_former.modeling.heads.mask_former_head WARNING: Weight format of MaskFormerHead have changed! Please upgrade your models. Applying automatic conversion now ...
[01/31 22:06:40] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (151, 256) in the checkpoint but (13, 256) in the model! You might want to double check if this is expected.
[01/31 22:06:40] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/31 22:06:40] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[01/31 22:06:40] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[01/31 22:06:40] d2.engine.train_loop INFO: Starting training from iteration 0
[01/31 22:06:49] d2.utils.events INFO:  eta: 0:10:48  iter: 19  total_loss: 22.56  loss_ce: 3.324  loss_mask: 0.2032  loss_dice: 0.3483  loss_ce_0: 2.953  loss_mask_0: 0.1988  loss_dice_0: 0.3375  loss_ce_1: 3.101  loss_mask_1: 0.2104  loss_dice_1: 0.3557  loss_ce_2: 3.189  loss_mask_2: 0.2144  loss_dice_2: 0.3691  loss_ce_3: 3.304  loss_mask_3: 0.1932  loss_dice_3: 0.3486  loss_ce_4: 3.371  loss_mask_4: 0.188  loss_dice_4: 0.3454  time: 0.4541  data_time: 0.0907  lr: 2.5036e-06  max_mem: 5401M
[01/31 22:06:58] d2.utils.events INFO:  eta: 0:10:36  iter: 39  total_loss: 17.59  loss_ce: 2.314  loss_mask: 0.1755  loss_dice: 0.3236  loss_ce_0: 2.57  loss_mask_0: 0.2084  loss_dice_0: 0.3193  loss_ce_1: 2.529  loss_mask_1: 0.1732  loss_dice_1: 0.2998  loss_ce_2: 2.491  loss_mask_2: 0.1787  loss_dice_2: 0.3005  loss_ce_3: 2.464  loss_mask_3: 0.1716  loss_dice_3: 0.3129  loss_ce_4: 2.476  loss_mask_4: 0.1656  loss_dice_4: 0.3176  time: 0.4521  data_time: 0.0814  lr: 5.0741e-06  max_mem: 5401M
[01/31 22:07:07] d2.utils.events INFO:  eta: 0:10:27  iter: 59  total_loss: 12.53  loss_ce: 1.401  loss_mask: 0.1418  loss_dice: 0.2869  loss_ce_0: 1.97  loss_mask_0: 0.1667  loss_dice_0: 0.3145  loss_ce_1: 1.786  loss_mask_1: 0.1636  loss_dice_1: 0.2889  loss_ce_2: 1.647  loss_mask_2: 0.1469  loss_dice_2: 0.3023  loss_ce_3: 1.516  loss_mask_3: 0.1415  loss_dice_3: 0.2908  loss_ce_4: 1.504  loss_mask_4: 0.1449  loss_dice_4: 0.2896  time: 0.4518  data_time: 0.0819  lr: 7.5782e-06  max_mem: 5401M
[01/31 22:07:17] d2.utils.events INFO:  eta: 0:10:19  iter: 79  total_loss: 10.12  loss_ce: 1.244  loss_mask: 0.1125  loss_dice: 0.2401  loss_ce_0: 1.423  loss_mask_0: 0.1268  loss_dice_0: 0.2651  loss_ce_1: 1.372  loss_mask_1: 0.1188  loss_dice_1: 0.243  loss_ce_2: 1.285  loss_mask_2: 0.1206  loss_dice_2: 0.2528  loss_ce_3: 1.276  loss_mask_3: 0.1151  loss_dice_3: 0.2342  loss_ce_4: 1.272  loss_mask_4: 0.1193  loss_dice_4: 0.2376  time: 0.4537  data_time: 0.0746  lr: 1.0016e-05  max_mem: 5401M
[01/31 22:07:26] d2.utils.events INFO:  eta: 0:10:10  iter: 99  total_loss: 8.461  loss_ce: 1.058  loss_mask: 0.09779  loss_dice: 0.2016  loss_ce_0: 1.237  loss_mask_0: 0.109  loss_dice_0: 0.2024  loss_ce_1: 1.2  loss_mask_1: 0.09432  loss_dice_1: 0.1896  loss_ce_2: 1.114  loss_mask_2: 0.1062  loss_dice_2: 0.2003  loss_ce_3: 1.087  loss_mask_3: 0.1091  loss_dice_3: 0.207  loss_ce_4: 1.071  loss_mask_4: 0.107  loss_dice_4: 0.1926  time: 0.4545  data_time: 0.0769  lr: 1.2386e-05  max_mem: 5401M
[01/31 22:07:35] d2.utils.events INFO:  eta: 0:10:00  iter: 119  total_loss: 7.496  loss_ce: 0.8494  loss_mask: 0.103  loss_dice: 0.1841  loss_ce_0: 1.083  loss_mask_0: 0.1037  loss_dice_0: 0.1986  loss_ce_1: 1.022  loss_mask_1: 0.1017  loss_dice_1: 0.1847  loss_ce_2: 0.9109  loss_mask_2: 0.1053  loss_dice_2: 0.1827  loss_ce_3: 0.9023  loss_mask_3: 0.1072  loss_dice_3: 0.1808  loss_ce_4: 0.8576  loss_mask_4: 0.1145  loss_dice_4: 0.1782  time: 0.4536  data_time: 0.0727  lr: 1.469e-05  max_mem: 5401M
[01/31 22:07:44] d2.utils.events INFO:  eta: 0:09:52  iter: 139  total_loss: 6.411  loss_ce: 0.6516  loss_mask: 0.1166  loss_dice: 0.1742  loss_ce_0: 0.957  loss_mask_0: 0.1057  loss_dice_0: 0.1792  loss_ce_1: 0.8903  loss_mask_1: 0.114  loss_dice_1: 0.1722  loss_ce_2: 0.7577  loss_mask_2: 0.1135  loss_dice_2: 0.1664  loss_ce_3: 0.7142  loss_mask_3: 0.1182  loss_dice_3: 0.1729  loss_ce_4: 0.6753  loss_mask_4: 0.1186  loss_dice_4: 0.1696  time: 0.4541  data_time: 0.0798  lr: 1.6927e-05  max_mem: 5401M
[01/31 22:07:46] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:07:46] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:07:46] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:07:46] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:07:46] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:07:46] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:07:47] d2.evaluation.evaluator INFO: Inference done 11/29. Dataloading: 0.0010 s/iter. Inference: 0.0480 s/iter. Eval: 0.0228 s/iter. Total: 0.0717 s/iter. ETA=0:00:01
[01/31 22:07:48] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.753793 (0.073075 s / iter per device, on 1 devices)
[01/31 22:07:48] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.047128 s / iter per device, on 1 devices)
[01/31 22:07:48] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 42.32912799305839, 'fwIoU': 70.65993075558595, 'IoU-other': nan, 'IoU-Grass': 53.09852850580251, 'IoU-CameraEdge': 89.16178857238793, 'IoU-Vehicle': nan, 'IoU-Person': 0.0, 'IoU-Bush': 0.0, 'IoU-Puddle': 0.0, 'IoU-Building': nan, 'IoU-Dirtroad': 90.64577024144798, 'IoU-Sky': 97.39940204886462, 'IoU-Large_stone': nan, 'IoU-Forrest': 8.32753457596412, 'IoU-Gravel': nan, 'mACC': 49.19014734552428, 'pACC': 81.07749169501537, 'ACC-other': nan, 'ACC-Grass': 95.21609580205272, 'ACC-CameraEdge': 95.23385982278202, 'ACC-Vehicle': nan, 'ACC-Person': 0.0, 'ACC-Bush': 0.0, 'ACC-Puddle': 0.0, 'ACC-Building': nan, 'ACC-Dirtroad': 95.93524892746682, 'ACC-Sky': 98.5502736149043, 'ACC-Large_stone': nan, 'ACC-Forrest': 8.585700596988387, 'ACC-Gravel': nan})])
[01/31 22:07:49] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:07:49] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:07:49] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:07:49] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:07:49] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:07:49] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:07:51] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.659981 (0.069166 s / iter per device, on 1 devices)
[01/31 22:07:51] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.043533 s / iter per device, on 1 devices)
[01/31 22:07:51] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 42.32912799305839, 'fwIoU': 70.65993075558595, 'IoU-other': nan, 'IoU-Grass': 53.09852850580251, 'IoU-CameraEdge': 89.16178857238793, 'IoU-Vehicle': nan, 'IoU-Person': 0.0, 'IoU-Bush': 0.0, 'IoU-Puddle': 0.0, 'IoU-Building': nan, 'IoU-Dirtroad': 90.64577024144798, 'IoU-Sky': 97.39940204886462, 'IoU-Large_stone': nan, 'IoU-Forrest': 8.32753457596412, 'IoU-Gravel': nan, 'mACC': 49.19014734552428, 'pACC': 81.07749169501537, 'ACC-other': nan, 'ACC-Grass': 95.21609580205272, 'ACC-CameraEdge': 95.23385982278202, 'ACC-Vehicle': nan, 'ACC-Person': 0.0, 'ACC-Bush': 0.0, 'ACC-Puddle': 0.0, 'ACC-Building': nan, 'ACC-Dirtroad': 95.93524892746682, 'ACC-Sky': 98.5502736149043, 'ACC-Large_stone': nan, 'ACC-Forrest': 8.585700596988387, 'ACC-Gravel': nan})])
[01/31 22:07:57] d2.utils.events INFO:  eta: 0:09:42  iter: 159  total_loss: 5.302  loss_ce: 0.4466  loss_mask: 0.1002  loss_dice: 0.185  loss_ce_0: 0.8299  loss_mask_0: 0.09149  loss_dice_0: 0.1795  loss_ce_1: 0.7197  loss_mask_1: 0.09546  loss_dice_1: 0.1736  loss_ce_2: 0.5826  loss_mask_2: 0.09936  loss_dice_2: 0.1755  loss_ce_3: 0.5281  loss_mask_3: 0.09891  loss_dice_3: 0.1814  loss_ce_4: 0.4685  loss_mask_4: 0.1073  loss_dice_4: 0.1804  time: 0.4535  data_time: 0.0804  lr: 1.9096e-05  max_mem: 5401M
[01/31 22:08:06] d2.utils.events INFO:  eta: 0:09:33  iter: 179  total_loss: 4.159  loss_ce: 0.306  loss_mask: 0.1035  loss_dice: 0.1914  loss_ce_0: 0.6441  loss_mask_0: 0.09818  loss_dice_0: 0.1739  loss_ce_1: 0.5188  loss_mask_1: 0.1091  loss_dice_1: 0.1637  loss_ce_2: 0.3924  loss_mask_2: 0.1077  loss_dice_2: 0.1692  loss_ce_3: 0.3377  loss_mask_3: 0.1171  loss_dice_3: 0.1829  loss_ce_4: 0.3055  loss_mask_4: 0.1052  loss_dice_4: 0.1824  time: 0.4532  data_time: 0.0832  lr: 2.1198e-05  max_mem: 5401M
[01/31 22:08:15] d2.utils.events INFO:  eta: 0:09:23  iter: 199  total_loss: 3.585  loss_ce: 0.2232  loss_mask: 0.1045  loss_dice: 0.1753  loss_ce_0: 0.5128  loss_mask_0: 0.0912  loss_dice_0: 0.1654  loss_ce_1: 0.4164  loss_mask_1: 0.09748  loss_dice_1: 0.1633  loss_ce_2: 0.3162  loss_mask_2: 0.1058  loss_dice_2: 0.167  loss_ce_3: 0.284  loss_mask_3: 0.1072  loss_dice_3: 0.1696  loss_ce_4: 0.2215  loss_mask_4: 0.1056  loss_dice_4: 0.1688  time: 0.4525  data_time: 0.0772  lr: 2.3232e-05  max_mem: 5401M
[01/31 22:08:24] d2.utils.events INFO:  eta: 0:09:14  iter: 219  total_loss: 2.939  loss_ce: 0.1752  loss_mask: 0.0942  loss_dice: 0.1566  loss_ce_0: 0.3578  loss_mask_0: 0.08428  loss_dice_0: 0.153  loss_ce_1: 0.2688  loss_mask_1: 0.09466  loss_dice_1: 0.1493  loss_ce_2: 0.2015  loss_mask_2: 0.09713  loss_dice_2: 0.1498  loss_ce_3: 0.1814  loss_mask_3: 0.1022  loss_dice_3: 0.1529  loss_ce_4: 0.1843  loss_mask_4: 0.1028  loss_dice_4: 0.1567  time: 0.4520  data_time: 0.0763  lr: 2.5199e-05  max_mem: 5401M
[01/31 22:08:33] d2.utils.events INFO:  eta: 0:09:05  iter: 239  total_loss: 2.707  loss_ce: 0.1584  loss_mask: 0.08897  loss_dice: 0.1649  loss_ce_0: 0.2777  loss_mask_0: 0.09377  loss_dice_0: 0.1564  loss_ce_1: 0.2062  loss_mask_1: 0.1102  loss_dice_1: 0.1521  loss_ce_2: 0.1913  loss_mask_2: 0.09351  loss_dice_2: 0.151  loss_ce_3: 0.1836  loss_mask_3: 0.08765  loss_dice_3: 0.15  loss_ce_4: 0.1672  loss_mask_4: 0.08867  loss_dice_4: 0.1655  time: 0.4519  data_time: 0.0758  lr: 2.7098e-05  max_mem: 5401M
[01/31 22:08:43] d2.utils.events INFO:  eta: 0:08:56  iter: 259  total_loss: 2.469  loss_ce: 0.1703  loss_mask: 0.09386  loss_dice: 0.1553  loss_ce_0: 0.2545  loss_mask_0: 0.08716  loss_dice_0: 0.1533  loss_ce_1: 0.2157  loss_mask_1: 0.08381  loss_dice_1: 0.1472  loss_ce_2: 0.2016  loss_mask_2: 0.09339  loss_dice_2: 0.1474  loss_ce_3: 0.1808  loss_mask_3: 0.09456  loss_dice_3: 0.1488  loss_ce_4: 0.174  loss_mask_4: 0.09373  loss_dice_4: 0.1461  time: 0.4524  data_time: 0.0726  lr: 2.8929e-05  max_mem: 5401M
[01/31 22:08:52] d2.utils.events INFO:  eta: 0:08:47  iter: 279  total_loss: 2.228  loss_ce: 0.09629  loss_mask: 0.08582  loss_dice: 0.1533  loss_ce_0: 0.2249  loss_mask_0: 0.1017  loss_dice_0: 0.1421  loss_ce_1: 0.1431  loss_mask_1: 0.1093  loss_dice_1: 0.1481  loss_ce_2: 0.1262  loss_mask_2: 0.09422  loss_dice_2: 0.1489  loss_ce_3: 0.1082  loss_mask_3: 0.09866  loss_dice_3: 0.1467  loss_ce_4: 0.1105  loss_mask_4: 0.09009  loss_dice_4: 0.1478  time: 0.4524  data_time: 0.0726  lr: 3.0691e-05  max_mem: 5401M
[01/31 22:08:56] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:08:56] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:08:56] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:08:56] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:08:56] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:08:56] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:08:57] d2.evaluation.evaluator INFO: Inference done 11/29. Dataloading: 0.0011 s/iter. Inference: 0.0465 s/iter. Eval: 0.0241 s/iter. Total: 0.0717 s/iter. ETA=0:00:01
[01/31 22:08:58] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.738280 (0.072428 s / iter per device, on 1 devices)
[01/31 22:08:58] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.045384 s / iter per device, on 1 devices)
[01/31 22:08:58] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 66.13800302072032, 'fwIoU': 85.5136860220932, 'IoU-other': nan, 'IoU-Grass': 70.48290745677122, 'IoU-CameraEdge': 90.85695207343343, 'IoU-Vehicle': nan, 'IoU-Person': 77.46178457163171, 'IoU-Bush': 30.34272477082385, 'IoU-Puddle': 0.0, 'IoU-Building': nan, 'IoU-Dirtroad': 93.11070462094413, 'IoU-Sky': 97.70649377098951, 'IoU-Large_stone': nan, 'IoU-Forrest': 69.14245690116864, 'IoU-Gravel': nan, 'mACC': 72.66128723704706, 'pACC': 91.45995882517892, 'ACC-other': nan, 'ACC-Grass': 76.90550056320834, 'ACC-CameraEdge': 94.99572018113915, 'ACC-Vehicle': nan, 'ACC-Person': 81.51645293070166, 'ACC-Bush': 42.280612695329744, 'ACC-Puddle': 0.0, 'ACC-Building': nan, 'ACC-Dirtroad': 95.55282849446274, 'ACC-Sky': 98.37458809786868, 'ACC-Large_stone': nan, 'ACC-Forrest': 91.66459493366614, 'ACC-Gravel': nan})])
[01/31 22:08:58] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:08:58] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:08:58] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:08:58] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:08:58] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:08:58] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:09:01] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.790843 (0.074618 s / iter per device, on 1 devices)
[01/31 22:09:01] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.047244 s / iter per device, on 1 devices)
[01/31 22:09:01] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 66.13800302072032, 'fwIoU': 85.5136860220932, 'IoU-other': nan, 'IoU-Grass': 70.48290745677122, 'IoU-CameraEdge': 90.85695207343343, 'IoU-Vehicle': nan, 'IoU-Person': 77.46178457163171, 'IoU-Bush': 30.34272477082385, 'IoU-Puddle': 0.0, 'IoU-Building': nan, 'IoU-Dirtroad': 93.11070462094413, 'IoU-Sky': 97.70649377098951, 'IoU-Large_stone': nan, 'IoU-Forrest': 69.14245690116864, 'IoU-Gravel': nan, 'mACC': 72.66128723704706, 'pACC': 91.45995882517892, 'ACC-other': nan, 'ACC-Grass': 76.90550056320834, 'ACC-CameraEdge': 94.99572018113915, 'ACC-Vehicle': nan, 'ACC-Person': 81.51645293070166, 'ACC-Bush': 42.280612695329744, 'ACC-Puddle': 0.0, 'ACC-Building': nan, 'ACC-Dirtroad': 95.55282849446274, 'ACC-Sky': 98.37458809786868, 'ACC-Large_stone': nan, 'ACC-Forrest': 91.66459493366614, 'ACC-Gravel': nan})])
[01/31 22:09:05] d2.utils.events INFO:  eta: 0:08:38  iter: 299  total_loss: 2.3  loss_ce: 0.1125  loss_mask: 0.08385  loss_dice: 0.1531  loss_ce_0: 0.1503  loss_mask_0: 0.08774  loss_dice_0: 0.1713  loss_ce_1: 0.1035  loss_mask_1: 0.08759  loss_dice_1: 0.1564  loss_ce_2: 0.1522  loss_mask_2: 0.08176  loss_dice_2: 0.1546  loss_ce_3: 0.1432  loss_mask_3: 0.08157  loss_dice_3: 0.1534  loss_ce_4: 0.1041  loss_mask_4: 0.0799  loss_dice_4: 0.155  time: 0.4523  data_time: 0.0757  lr: 3.2385e-05  max_mem: 5401M
[01/31 22:09:14] d2.utils.events INFO:  eta: 0:08:28  iter: 319  total_loss: 2.39  loss_ce: 0.1524  loss_mask: 0.1016  loss_dice: 0.1455  loss_ce_0: 0.1661  loss_mask_0: 0.1049  loss_dice_0: 0.1483  loss_ce_1: 0.138  loss_mask_1: 0.09154  loss_dice_1: 0.1374  loss_ce_2: 0.1655  loss_mask_2: 0.08405  loss_dice_2: 0.1362  loss_ce_3: 0.1498  loss_mask_3: 0.0927  loss_dice_3: 0.1434  loss_ce_4: 0.1433  loss_mask_4: 0.08501  loss_dice_4: 0.1483  time: 0.4519  data_time: 0.0776  lr: 3.4011e-05  max_mem: 5401M
[01/31 22:09:23] d2.utils.events INFO:  eta: 0:08:19  iter: 339  total_loss: 1.955  loss_ce: 0.07098  loss_mask: 0.08072  loss_dice: 0.1491  loss_ce_0: 0.1433  loss_mask_0: 0.07993  loss_dice_0: 0.1558  loss_ce_1: 0.09691  loss_mask_1: 0.07676  loss_dice_1: 0.151  loss_ce_2: 0.1121  loss_mask_2: 0.07496  loss_dice_2: 0.1463  loss_ce_3: 0.08117  loss_mask_3: 0.0789  loss_dice_3: 0.1453  loss_ce_4: 0.07553  loss_mask_4: 0.07628  loss_dice_4: 0.149  time: 0.4517  data_time: 0.0762  lr: 3.5567e-05  max_mem: 5401M
[01/31 22:09:32] d2.utils.events INFO:  eta: 0:08:10  iter: 359  total_loss: 2.015  loss_ce: 0.1047  loss_mask: 0.08306  loss_dice: 0.1386  loss_ce_0: 0.1224  loss_mask_0: 0.07318  loss_dice_0: 0.1458  loss_ce_1: 0.1167  loss_mask_1: 0.08666  loss_dice_1: 0.1351  loss_ce_2: 0.1236  loss_mask_2: 0.08324  loss_dice_2: 0.1438  loss_ce_3: 0.08775  loss_mask_3: 0.0848  loss_dice_3: 0.1454  loss_ce_4: 0.1033  loss_mask_4: 0.08254  loss_dice_4: 0.1372  time: 0.4516  data_time: 0.0780  lr: 3.7055e-05  max_mem: 5401M
[01/31 22:09:41] d2.utils.events INFO:  eta: 0:08:01  iter: 379  total_loss: 1.847  loss_ce: 0.04855  loss_mask: 0.08049  loss_dice: 0.1581  loss_ce_0: 0.1215  loss_mask_0: 0.08702  loss_dice_0: 0.1462  loss_ce_1: 0.0704  loss_mask_1: 0.08122  loss_dice_1: 0.1521  loss_ce_2: 0.07099  loss_mask_2: 0.07977  loss_dice_2: 0.1552  loss_ce_3: 0.0535  loss_mask_3: 0.08342  loss_dice_3: 0.1535  loss_ce_4: 0.05046  loss_mask_4: 0.08624  loss_dice_4: 0.1545  time: 0.4512  data_time: 0.0756  lr: 3.8473e-05  max_mem: 5401M
[01/31 22:09:50] d2.utils.events INFO:  eta: 0:07:52  iter: 399  total_loss: 1.826  loss_ce: 0.05263  loss_mask: 0.09358  loss_dice: 0.13  loss_ce_0: 0.08985  loss_mask_0: 0.09396  loss_dice_0: 0.1363  loss_ce_1: 0.0617  loss_mask_1: 0.0984  loss_dice_1: 0.1317  loss_ce_2: 0.06865  loss_mask_2: 0.0958  loss_dice_2: 0.1275  loss_ce_3: 0.07022  loss_mask_3: 0.09147  loss_dice_3: 0.1241  loss_ce_4: 0.05323  loss_mask_4: 0.09674  loss_dice_4: 0.1301  time: 0.4513  data_time: 0.0786  lr: 3.9822e-05  max_mem: 5401M
[01/31 22:09:59] d2.utils.events INFO:  eta: 0:07:43  iter: 419  total_loss: 1.672  loss_ce: 0.04112  loss_mask: 0.07421  loss_dice: 0.1196  loss_ce_0: 0.07596  loss_mask_0: 0.08384  loss_dice_0: 0.1389  loss_ce_1: 0.055  loss_mask_1: 0.07853  loss_dice_1: 0.1288  loss_ce_2: 0.04752  loss_mask_2: 0.07557  loss_dice_2: 0.1264  loss_ce_3: 0.04369  loss_mask_3: 0.07782  loss_dice_3: 0.1221  loss_ce_4: 0.04237  loss_mask_4: 0.07488  loss_dice_4: 0.1196  time: 0.4510  data_time: 0.0778  lr: 4.1101e-05  max_mem: 5401M
[01/31 22:10:06] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:10:06] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:10:06] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:10:06] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:10:06] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:10:06] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:10:07] d2.evaluation.evaluator INFO: Inference done 11/29. Dataloading: 0.0014 s/iter. Inference: 0.0461 s/iter. Eval: 0.0241 s/iter. Total: 0.0715 s/iter. ETA=0:00:01
[01/31 22:10:08] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.770476 (0.073770 s / iter per device, on 1 devices)
[01/31 22:10:08] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.046133 s / iter per device, on 1 devices)
[01/31 22:10:08] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 70.25382180323895, 'fwIoU': 88.00459328399624, 'IoU-other': nan, 'IoU-Grass': 77.8334622055519, 'IoU-CameraEdge': 91.00821494905449, 'IoU-Vehicle': nan, 'IoU-Person': 84.8660880603811, 'IoU-Bush': 30.801720644618307, 'IoU-Puddle': 12.705727452271232, 'IoU-Building': nan, 'IoU-Dirtroad': 93.22371287067898, 'IoU-Sky': 98.0284978574771, 'IoU-Large_stone': nan, 'IoU-Forrest': 73.56315038587846, 'IoU-Gravel': nan, 'mACC': 75.26693075365907, 'pACC': 93.30398850631865, 'ACC-other': nan, 'ACC-Grass': 91.72134087633958, 'ACC-CameraEdge': 95.01221780691561, 'ACC-Vehicle': nan, 'ACC-Person': 92.03615305191015, 'ACC-Bush': 32.71442129425267, 'ACC-Puddle': 12.705727452271232, 'ACC-Building': nan, 'ACC-Dirtroad': 98.42547141574379, 'ACC-Sky': 98.65971655667258, 'ACC-Large_stone': nan, 'ACC-Forrest': 80.86039757516687, 'ACC-Gravel': nan})])
[01/31 22:10:08] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:10:08] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:10:08] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:10:08] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:10:08] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:10:08] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:10:10] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.738349 (0.072431 s / iter per device, on 1 devices)
[01/31 22:10:10] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.045741 s / iter per device, on 1 devices)
[01/31 22:10:10] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 70.25382180323895, 'fwIoU': 88.00459328399624, 'IoU-other': nan, 'IoU-Grass': 77.8334622055519, 'IoU-CameraEdge': 91.00821494905449, 'IoU-Vehicle': nan, 'IoU-Person': 84.8660880603811, 'IoU-Bush': 30.801720644618307, 'IoU-Puddle': 12.705727452271232, 'IoU-Building': nan, 'IoU-Dirtroad': 93.22371287067898, 'IoU-Sky': 98.0284978574771, 'IoU-Large_stone': nan, 'IoU-Forrest': 73.56315038587846, 'IoU-Gravel': nan, 'mACC': 75.26693075365907, 'pACC': 93.30398850631865, 'ACC-other': nan, 'ACC-Grass': 91.72134087633958, 'ACC-CameraEdge': 95.01221780691561, 'ACC-Vehicle': nan, 'ACC-Person': 92.03615305191015, 'ACC-Bush': 32.71442129425267, 'ACC-Puddle': 12.705727452271232, 'ACC-Building': nan, 'ACC-Dirtroad': 98.42547141574379, 'ACC-Sky': 98.65971655667258, 'ACC-Large_stone': nan, 'ACC-Forrest': 80.86039757516687, 'ACC-Gravel': nan})])
[01/31 22:10:12] d2.utils.events INFO:  eta: 0:07:34  iter: 439  total_loss: 1.59  loss_ce: 0.04758  loss_mask: 0.07273  loss_dice: 0.1364  loss_ce_0: 0.08075  loss_mask_0: 0.07135  loss_dice_0: 0.1377  loss_ce_1: 0.05141  loss_mask_1: 0.07334  loss_dice_1: 0.1325  loss_ce_2: 0.08114  loss_mask_2: 0.07374  loss_dice_2: 0.1264  loss_ce_3: 0.05581  loss_mask_3: 0.07383  loss_dice_3: 0.1341  loss_ce_4: 0.04752  loss_mask_4: 0.07323  loss_dice_4: 0.1353  time: 0.4511  data_time: 0.0765  lr: 4.2311e-05  max_mem: 5401M
[01/31 22:10:22] d2.utils.events INFO:  eta: 0:07:25  iter: 459  total_loss: 1.582  loss_ce: 0.03705  loss_mask: 0.07726  loss_dice: 0.1173  loss_ce_0: 0.0641  loss_mask_0: 0.0773  loss_dice_0: 0.1134  loss_ce_1: 0.04445  loss_mask_1: 0.07517  loss_dice_1: 0.1119  loss_ce_2: 0.04437  loss_mask_2: 0.07217  loss_dice_2: 0.1136  loss_ce_3: 0.03163  loss_mask_3: 0.07629  loss_dice_3: 0.111  loss_ce_4: 0.02944  loss_mask_4: 0.07532  loss_dice_4: 0.1166  time: 0.4512  data_time: 0.0769  lr: 4.345e-05  max_mem: 5401M
[01/31 22:10:31] d2.utils.events INFO:  eta: 0:07:16  iter: 479  total_loss: 1.75  loss_ce: 0.04037  loss_mask: 0.08264  loss_dice: 0.1358  loss_ce_0: 0.06826  loss_mask_0: 0.08429  loss_dice_0: 0.1413  loss_ce_1: 0.05293  loss_mask_1: 0.08101  loss_dice_1: 0.1334  loss_ce_2: 0.05631  loss_mask_2: 0.08176  loss_dice_2: 0.135  loss_ce_3: 0.03593  loss_mask_3: 0.08548  loss_dice_3: 0.1416  loss_ce_4: 0.03504  loss_mask_4: 0.08478  loss_dice_4: 0.1435  time: 0.4512  data_time: 0.0804  lr: 4.4519e-05  max_mem: 5401M
[01/31 22:10:40] d2.utils.events INFO:  eta: 0:07:07  iter: 499  total_loss: 1.407  loss_ce: 0.02352  loss_mask: 0.09595  loss_dice: 0.1363  loss_ce_0: 0.04026  loss_mask_0: 0.08194  loss_dice_0: 0.1353  loss_ce_1: 0.02913  loss_mask_1: 0.08304  loss_dice_1: 0.1363  loss_ce_2: 0.03111  loss_mask_2: 0.08278  loss_dice_2: 0.1372  loss_ce_3: 0.02774  loss_mask_3: 0.08344  loss_dice_3: 0.1353  loss_ce_4: 0.0254  loss_mask_4: 0.08966  loss_dice_4: 0.1378  time: 0.4512  data_time: 0.0763  lr: 4.5517e-05  max_mem: 5401M
[01/31 22:10:49] d2.utils.events INFO:  eta: 0:06:58  iter: 519  total_loss: 1.356  loss_ce: 0.02896  loss_mask: 0.0699  loss_dice: 0.1121  loss_ce_0: 0.05337  loss_mask_0: 0.07988  loss_dice_0: 0.1074  loss_ce_1: 0.0356  loss_mask_1: 0.06837  loss_dice_1: 0.1122  loss_ce_2: 0.03461  loss_mask_2: 0.06988  loss_dice_2: 0.1139  loss_ce_3: 0.03085  loss_mask_3: 0.06881  loss_dice_3: 0.1144  loss_ce_4: 0.03055  loss_mask_4: 0.06895  loss_dice_4: 0.1135  time: 0.4514  data_time: 0.0789  lr: 4.6444e-05  max_mem: 5401M
[01/31 22:10:58] d2.utils.events INFO:  eta: 0:06:49  iter: 539  total_loss: 1.37  loss_ce: 0.02857  loss_mask: 0.06502  loss_dice: 0.1061  loss_ce_0: 0.06038  loss_mask_0: 0.07266  loss_dice_0: 0.11  loss_ce_1: 0.06731  loss_mask_1: 0.07372  loss_dice_1: 0.1094  loss_ce_2: 0.05638  loss_mask_2: 0.06968  loss_dice_2: 0.1037  loss_ce_3: 0.03116  loss_mask_3: 0.06397  loss_dice_3: 0.1076  loss_ce_4: 0.0296  loss_mask_4: 0.06469  loss_dice_4: 0.1063  time: 0.4515  data_time: 0.0818  lr: 4.73e-05  max_mem: 5401M
[01/31 22:11:07] d2.utils.events INFO:  eta: 0:06:41  iter: 559  total_loss: 1.33  loss_ce: 0.02375  loss_mask: 0.06511  loss_dice: 0.1161  loss_ce_0: 0.04153  loss_mask_0: 0.07391  loss_dice_0: 0.1112  loss_ce_1: 0.03157  loss_mask_1: 0.07019  loss_dice_1: 0.1141  loss_ce_2: 0.02968  loss_mask_2: 0.06667  loss_dice_2: 0.1119  loss_ce_3: 0.02527  loss_mask_3: 0.06655  loss_dice_3: 0.1169  loss_ce_4: 0.0228  loss_mask_4: 0.06473  loss_dice_4: 0.1147  time: 0.4518  data_time: 0.0811  lr: 4.8085e-05  max_mem: 5401M
[01/31 22:11:16] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:11:16] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:11:16] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:11:16] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:11:16] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:11:16] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:11:17] d2.evaluation.evaluator INFO: Inference done 11/29. Dataloading: 0.0013 s/iter. Inference: 0.0436 s/iter. Eval: 0.0239 s/iter. Total: 0.0688 s/iter. ETA=0:00:01
[01/31 22:11:19] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.754280 (0.073095 s / iter per device, on 1 devices)
[01/31 22:11:19] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.045965 s / iter per device, on 1 devices)
[01/31 22:11:19] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 71.52398714775015, 'fwIoU': 88.84199875674011, 'IoU-other': nan, 'IoU-Grass': 78.72082852244499, 'IoU-CameraEdge': 92.85066540230255, 'IoU-Vehicle': nan, 'IoU-Person': 82.57261410788381, 'IoU-Bush': 51.302207799830626, 'IoU-Puddle': 0.0, 'IoU-Building': nan, 'IoU-Dirtroad': 94.0133462404946, 'IoU-Sky': 98.26509677193242, 'IoU-Large_stone': nan, 'IoU-Forrest': 74.46713833711217, 'IoU-Gravel': nan, 'mACC': 77.28882673626593, 'pACC': 93.72683530480889, 'ACC-other': nan, 'ACC-Grass': 92.02937493313867, 'ACC-CameraEdge': 96.45420593818889, 'ACC-Vehicle': nan, 'ACC-Person': 86.05952683795472, 'ACC-Bush': 67.5184294164386, 'ACC-Puddle': 0.0, 'ACC-Building': nan, 'ACC-Dirtroad': 95.48967375037414, 'ACC-Sky': 99.06629225342382, 'ACC-Large_stone': nan, 'ACC-Forrest': 81.69311076060865, 'ACC-Gravel': nan})])
[01/31 22:11:19] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:11:19] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:11:19] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:11:19] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:11:19] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:11:19] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:11:21] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.733448 (0.072227 s / iter per device, on 1 devices)
[01/31 22:11:21] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.044546 s / iter per device, on 1 devices)
[01/31 22:11:21] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 71.52398714775015, 'fwIoU': 88.84199875674011, 'IoU-other': nan, 'IoU-Grass': 78.72082852244499, 'IoU-CameraEdge': 92.85066540230255, 'IoU-Vehicle': nan, 'IoU-Person': 82.57261410788381, 'IoU-Bush': 51.302207799830626, 'IoU-Puddle': 0.0, 'IoU-Building': nan, 'IoU-Dirtroad': 94.0133462404946, 'IoU-Sky': 98.26509677193242, 'IoU-Large_stone': nan, 'IoU-Forrest': 74.46713833711217, 'IoU-Gravel': nan, 'mACC': 77.28882673626593, 'pACC': 93.72683530480889, 'ACC-other': nan, 'ACC-Grass': 92.02937493313867, 'ACC-CameraEdge': 96.45420593818889, 'ACC-Vehicle': nan, 'ACC-Person': 86.05952683795472, 'ACC-Bush': 67.5184294164386, 'ACC-Puddle': 0.0, 'ACC-Building': nan, 'ACC-Dirtroad': 95.48967375037414, 'ACC-Sky': 99.06629225342382, 'ACC-Large_stone': nan, 'ACC-Forrest': 81.69311076060865, 'ACC-Gravel': nan})])
[01/31 22:11:21] d2.utils.events INFO:  eta: 0:06:32  iter: 579  total_loss: 1.474  loss_ce: 0.03458  loss_mask: 0.07108  loss_dice: 0.1116  loss_ce_0: 0.0435  loss_mask_0: 0.07285  loss_dice_0: 0.1197  loss_ce_1: 0.03497  loss_mask_1: 0.06784  loss_dice_1: 0.1139  loss_ce_2: 0.0344  loss_mask_2: 0.06799  loss_dice_2: 0.1125  loss_ce_3: 0.03242  loss_mask_3: 0.06695  loss_dice_3: 0.111  loss_ce_4: 0.0311  loss_mask_4: 0.06853  loss_dice_4: 0.111  time: 0.4520  data_time: 0.0809  lr: 4.8798e-05  max_mem: 5401M
[01/31 22:11:30] d2.utils.events INFO:  eta: 0:06:23  iter: 599  total_loss: 1.573  loss_ce: 0.04214  loss_mask: 0.07466  loss_dice: 0.1219  loss_ce_0: 0.05847  loss_mask_0: 0.0683  loss_dice_0: 0.1233  loss_ce_1: 0.05591  loss_mask_1: 0.06999  loss_dice_1: 0.1185  loss_ce_2: 0.04879  loss_mask_2: 0.07379  loss_dice_2: 0.1203  loss_ce_3: 0.04561  loss_mask_3: 0.07434  loss_dice_3: 0.1204  loss_ce_4: 0.04622  loss_mask_4: 0.07486  loss_dice_4: 0.1227  time: 0.4520  data_time: 0.0830  lr: 4.9439e-05  max_mem: 5401M
[01/31 22:11:39] d2.utils.events INFO:  eta: 0:06:14  iter: 619  total_loss: 1.476  loss_ce: 0.02526  loss_mask: 0.06688  loss_dice: 0.1152  loss_ce_0: 0.04012  loss_mask_0: 0.06719  loss_dice_0: 0.1162  loss_ce_1: 0.03082  loss_mask_1: 0.0669  loss_dice_1: 0.1122  loss_ce_2: 0.02763  loss_mask_2: 0.07021  loss_dice_2: 0.1096  loss_ce_3: 0.02618  loss_mask_3: 0.07005  loss_dice_3: 0.114  loss_ce_4: 0.02516  loss_mask_4: 0.06871  loss_dice_4: 0.1141  time: 0.4521  data_time: 0.0820  lr: 5.0008e-05  max_mem: 5401M
[01/31 22:11:48] d2.utils.events INFO:  eta: 0:06:05  iter: 639  total_loss: 1.136  loss_ce: 0.02538  loss_mask: 0.05387  loss_dice: 0.0993  loss_ce_0: 0.02706  loss_mask_0: 0.05682  loss_dice_0: 0.09526  loss_ce_1: 0.02429  loss_mask_1: 0.05407  loss_dice_1: 0.09531  loss_ce_2: 0.02585  loss_mask_2: 0.05249  loss_dice_2: 0.09151  loss_ce_3: 0.02518  loss_mask_3: 0.05363  loss_dice_3: 0.09561  loss_ce_4: 0.02576  loss_mask_4: 0.05318  loss_dice_4: 0.09861  time: 0.4519  data_time: 0.0782  lr: 5.0504e-05  max_mem: 5401M
[01/31 22:11:57] d2.utils.events INFO:  eta: 0:05:56  iter: 659  total_loss: 1.398  loss_ce: 0.02336  loss_mask: 0.06295  loss_dice: 0.1148  loss_ce_0: 0.03147  loss_mask_0: 0.06604  loss_dice_0: 0.1143  loss_ce_1: 0.02328  loss_mask_1: 0.06795  loss_dice_1: 0.1104  loss_ce_2: 0.02576  loss_mask_2: 0.0701  loss_dice_2: 0.1114  loss_ce_3: 0.02389  loss_mask_3: 0.06217  loss_dice_3: 0.1163  loss_ce_4: 0.0232  loss_mask_4: 0.06333  loss_dice_4: 0.1133  time: 0.4521  data_time: 0.0797  lr: 5.0927e-05  max_mem: 5401M
[01/31 22:12:06] d2.utils.events INFO:  eta: 0:05:47  iter: 679  total_loss: 1.283  loss_ce: 0.02167  loss_mask: 0.06813  loss_dice: 0.1125  loss_ce_0: 0.03807  loss_mask_0: 0.07081  loss_dice_0: 0.1066  loss_ce_1: 0.02643  loss_mask_1: 0.07358  loss_dice_1: 0.1097  loss_ce_2: 0.02487  loss_mask_2: 0.07169  loss_dice_2: 0.1106  loss_ce_3: 0.02416  loss_mask_3: 0.06857  loss_dice_3: 0.1125  loss_ce_4: 0.02112  loss_mask_4: 0.06823  loss_dice_4: 0.1122  time: 0.4520  data_time: 0.0793  lr: 5.1277e-05  max_mem: 5401M
[01/31 22:12:15] d2.utils.events INFO:  eta: 0:05:38  iter: 699  total_loss: 1.035  loss_ce: 0.01713  loss_mask: 0.05654  loss_dice: 0.08801  loss_ce_0: 0.02385  loss_mask_0: 0.05807  loss_dice_0: 0.09008  loss_ce_1: 0.02164  loss_mask_1: 0.05667  loss_dice_1: 0.08993  loss_ce_2: 0.0194  loss_mask_2: 0.05648  loss_dice_2: 0.08899  loss_ce_3: 0.01961  loss_mask_3: 0.05439  loss_dice_3: 0.08728  loss_ce_4: 0.01781  loss_mask_4: 0.05632  loss_dice_4: 0.08645  time: 0.4521  data_time: 0.0806  lr: 5.1554e-05  max_mem: 5401M
[01/31 22:12:24] d2.utils.events INFO:  eta: 0:05:29  iter: 719  total_loss: 1.232  loss_ce: 0.02286  loss_mask: 0.06115  loss_dice: 0.1048  loss_ce_0: 0.02542  loss_mask_0: 0.05876  loss_dice_0: 0.1178  loss_ce_1: 0.02162  loss_mask_1: 0.06211  loss_dice_1: 0.1108  loss_ce_2: 0.02218  loss_mask_2: 0.06018  loss_dice_2: 0.1028  loss_ce_3: 0.02322  loss_mask_3: 0.06132  loss_dice_3: 0.1026  loss_ce_4: 0.02277  loss_mask_4: 0.06022  loss_dice_4: 0.1037  time: 0.4522  data_time: 0.0796  lr: 5.1756e-05  max_mem: 5401M
[01/31 22:12:27] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:12:27] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:12:27] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:12:27] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:12:27] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:12:27] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:12:27] d2.evaluation.evaluator INFO: Inference done 11/29. Dataloading: 0.0011 s/iter. Inference: 0.0436 s/iter. Eval: 0.0240 s/iter. Total: 0.0687 s/iter. ETA=0:00:01
[01/31 22:12:29] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.686836 (0.070285 s / iter per device, on 1 devices)
[01/31 22:12:29] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.043772 s / iter per device, on 1 devices)
[01/31 22:12:29] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 75.0763550688649, 'fwIoU': 92.3522480207931, 'IoU-other': nan, 'IoU-Grass': 85.29152584066016, 'IoU-CameraEdge': 94.078942760078, 'IoU-Vehicle': nan, 'IoU-Person': 85.37944202217092, 'IoU-Bush': 56.609546813077515, 'IoU-Puddle': 0.0, 'IoU-Building': nan, 'IoU-Dirtroad': 95.07560087930077, 'IoU-Sky': 98.22561478159201, 'IoU-Large_stone': nan, 'IoU-Forrest': 85.95016745403977, 'IoU-Gravel': nan, 'mACC': 78.7921075083664, 'pACC': 95.9029771391236, 'ACC-other': nan, 'ACC-Grass': 90.1125787390426, 'ACC-CameraEdge': 96.3380052696764, 'ACC-Vehicle': nan, 'ACC-Person': 89.665853622039, 'ACC-Bush': 61.557009799593885, 'ACC-Puddle': 0.0, 'ACC-Building': nan, 'ACC-Dirtroad': 96.42158036516012, 'ACC-Sky': 99.04900304697726, 'ACC-Large_stone': nan, 'ACC-Forrest': 97.19282922444195, 'ACC-Gravel': nan})])
[01/31 22:12:29] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:12:29] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:12:29] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:12:29] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:12:29] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:12:29] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:12:31] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.693622 (0.070568 s / iter per device, on 1 devices)
[01/31 22:12:31] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.043783 s / iter per device, on 1 devices)
[01/31 22:12:31] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 75.0763550688649, 'fwIoU': 92.3522480207931, 'IoU-other': nan, 'IoU-Grass': 85.29152584066016, 'IoU-CameraEdge': 94.078942760078, 'IoU-Vehicle': nan, 'IoU-Person': 85.37944202217092, 'IoU-Bush': 56.609546813077515, 'IoU-Puddle': 0.0, 'IoU-Building': nan, 'IoU-Dirtroad': 95.07560087930077, 'IoU-Sky': 98.22561478159201, 'IoU-Large_stone': nan, 'IoU-Forrest': 85.95016745403977, 'IoU-Gravel': nan, 'mACC': 78.7921075083664, 'pACC': 95.9029771391236, 'ACC-other': nan, 'ACC-Grass': 90.1125787390426, 'ACC-CameraEdge': 96.3380052696764, 'ACC-Vehicle': nan, 'ACC-Person': 89.665853622039, 'ACC-Bush': 61.557009799593885, 'ACC-Puddle': 0.0, 'ACC-Building': nan, 'ACC-Dirtroad': 96.42158036516012, 'ACC-Sky': 99.04900304697726, 'ACC-Large_stone': nan, 'ACC-Forrest': 97.19282922444195, 'ACC-Gravel': nan})])
[01/31 22:12:38] d2.utils.events INFO:  eta: 0:05:20  iter: 739  total_loss: 1.499  loss_ce: 0.02603  loss_mask: 0.0723  loss_dice: 0.1245  loss_ce_0: 0.03719  loss_mask_0: 0.07051  loss_dice_0: 0.1211  loss_ce_1: 0.037  loss_mask_1: 0.07025  loss_dice_1: 0.1208  loss_ce_2: 0.03525  loss_mask_2: 0.07191  loss_dice_2: 0.12  loss_ce_3: 0.03348  loss_mask_3: 0.07018  loss_dice_3: 0.1209  loss_ce_4: 0.02649  loss_mask_4: 0.07121  loss_dice_4: 0.1232  time: 0.4521  data_time: 0.0793  lr: 5.1884e-05  max_mem: 5401M
[01/31 22:12:47] d2.utils.events INFO:  eta: 0:05:11  iter: 759  total_loss: 1.011  loss_ce: 0.01274  loss_mask: 0.05803  loss_dice: 0.09699  loss_ce_0: 0.01991  loss_mask_0: 0.05824  loss_dice_0: 0.09663  loss_ce_1: 0.01465  loss_mask_1: 0.06046  loss_dice_1: 0.09459  loss_ce_2: 0.01719  loss_mask_2: 0.05903  loss_dice_2: 0.09425  loss_ce_3: 0.01465  loss_mask_3: 0.05697  loss_dice_3: 0.09384  loss_ce_4: 0.01366  loss_mask_4: 0.05785  loss_dice_4: 0.09461  time: 0.4522  data_time: 0.0783  lr: 5.1937e-05  max_mem: 5401M
[01/31 22:12:56] d2.utils.events INFO:  eta: 0:05:02  iter: 779  total_loss: 1.358  loss_ce: 0.02114  loss_mask: 0.07893  loss_dice: 0.1108  loss_ce_0: 0.02613  loss_mask_0: 0.0786  loss_dice_0: 0.111  loss_ce_1: 0.02446  loss_mask_1: 0.07999  loss_dice_1: 0.1047  loss_ce_2: 0.02436  loss_mask_2: 0.08012  loss_dice_2: 0.1052  loss_ce_3: 0.02529  loss_mask_3: 0.07961  loss_dice_3: 0.1086  loss_ce_4: 0.02133  loss_mask_4: 0.08221  loss_dice_4: 0.1096  time: 0.4522  data_time: 0.0762  lr: 5.1915e-05  max_mem: 5401M
[01/31 22:13:05] d2.utils.events INFO:  eta: 0:04:53  iter: 799  total_loss: 1.066  loss_ce: 0.0115  loss_mask: 0.06336  loss_dice: 0.09756  loss_ce_0: 0.02062  loss_mask_0: 0.06719  loss_dice_0: 0.09838  loss_ce_1: 0.01689  loss_mask_1: 0.06184  loss_dice_1: 0.09655  loss_ce_2: 0.01626  loss_mask_2: 0.06352  loss_dice_2: 0.0984  loss_ce_3: 0.01483  loss_mask_3: 0.06385  loss_dice_3: 0.0975  loss_ce_4: 0.01296  loss_mask_4: 0.06259  loss_dice_4: 0.09725  time: 0.4522  data_time: 0.0759  lr: 5.1818e-05  max_mem: 5401M
[01/31 22:13:14] d2.utils.events INFO:  eta: 0:04:44  iter: 819  total_loss: 1.406  loss_ce: 0.03188  loss_mask: 0.05692  loss_dice: 0.1106  loss_ce_0: 0.0561  loss_mask_0: 0.04937  loss_dice_0: 0.1083  loss_ce_1: 0.03598  loss_mask_1: 0.05353  loss_dice_1: 0.1139  loss_ce_2: 0.05263  loss_mask_2: 0.05549  loss_dice_2: 0.1065  loss_ce_3: 0.03055  loss_mask_3: 0.05477  loss_dice_3: 0.1055  loss_ce_4: 0.03291  loss_mask_4: 0.05611  loss_dice_4: 0.1043  time: 0.4522  data_time: 0.0817  lr: 5.1644e-05  max_mem: 5401M
[01/31 22:13:23] d2.utils.events INFO:  eta: 0:04:35  iter: 839  total_loss: 1.217  loss_ce: 0.01116  loss_mask: 0.068  loss_dice: 0.09254  loss_ce_0: 0.01585  loss_mask_0: 0.06295  loss_dice_0: 0.09129  loss_ce_1: 0.01273  loss_mask_1: 0.06178  loss_dice_1: 0.08918  loss_ce_2: 0.0123  loss_mask_2: 0.06379  loss_dice_2: 0.09079  loss_ce_3: 0.01073  loss_mask_3: 0.06425  loss_dice_3: 0.08967  loss_ce_4: 0.01051  loss_mask_4: 0.06541  loss_dice_4: 0.09065  time: 0.4523  data_time: 0.0791  lr: 5.1393e-05  max_mem: 5401M
[01/31 22:13:32] d2.utils.events INFO:  eta: 0:04:26  iter: 859  total_loss: 1.138  loss_ce: 0.01593  loss_mask: 0.06282  loss_dice: 0.1129  loss_ce_0: 0.02129  loss_mask_0: 0.06274  loss_dice_0: 0.1131  loss_ce_1: 0.01971  loss_mask_1: 0.06097  loss_dice_1: 0.1102  loss_ce_2: 0.01982  loss_mask_2: 0.05616  loss_dice_2: 0.1119  loss_ce_3: 0.01719  loss_mask_3: 0.06138  loss_dice_3: 0.1112  loss_ce_4: 0.01628  loss_mask_4: 0.06179  loss_dice_4: 0.1104  time: 0.4524  data_time: 0.0835  lr: 5.1066e-05  max_mem: 5401M
[01/31 22:13:37] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:13:37] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:13:37] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:13:37] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:13:37] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:13:37] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:13:38] d2.evaluation.evaluator INFO: Inference done 11/29. Dataloading: 0.0010 s/iter. Inference: 0.0452 s/iter. Eval: 0.0239 s/iter. Total: 0.0701 s/iter. ETA=0:00:01
[01/31 22:13:39] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.708361 (0.071182 s / iter per device, on 1 devices)
[01/31 22:13:39] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.044847 s / iter per device, on 1 devices)
[01/31 22:13:39] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 81.63187378271547, 'fwIoU': 91.22068185743535, 'IoU-other': nan, 'IoU-Grass': 83.84017636792994, 'IoU-CameraEdge': 94.11619845487765, 'IoU-Vehicle': nan, 'IoU-Person': 80.79290750289381, 'IoU-Bush': 40.90787394547717, 'IoU-Puddle': 78.0138077535847, 'IoU-Building': nan, 'IoU-Dirtroad': 96.092371300358, 'IoU-Sky': 98.3675570310906, 'IoU-Large_stone': nan, 'IoU-Forrest': 80.92409790551191, 'IoU-Gravel': nan, 'mACC': 88.30147592116367, 'pACC': 95.23564603342581, 'ACC-other': nan, 'ACC-Grass': 94.17016443166301, 'ACC-CameraEdge': 95.94612688347894, 'ACC-Vehicle': nan, 'ACC-Person': 91.91195175602675, 'ACC-Bush': 42.99737353226803, 'ACC-Puddle': 96.70836076366031, 'ACC-Building': nan, 'ACC-Dirtroad': 97.92347600518806, 'ACC-Sky': 99.15128871026899, 'ACC-Large_stone': nan, 'ACC-Forrest': 87.60306528675528, 'ACC-Gravel': nan})])
[01/31 22:13:39] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:13:39] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:13:39] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:13:39] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:13:39] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:13:39] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:13:41] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.761985 (0.073416 s / iter per device, on 1 devices)
[01/31 22:13:41] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.046294 s / iter per device, on 1 devices)
[01/31 22:13:41] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 81.63187378271547, 'fwIoU': 91.22068185743535, 'IoU-other': nan, 'IoU-Grass': 83.84017636792994, 'IoU-CameraEdge': 94.11619845487765, 'IoU-Vehicle': nan, 'IoU-Person': 80.79290750289381, 'IoU-Bush': 40.90787394547717, 'IoU-Puddle': 78.0138077535847, 'IoU-Building': nan, 'IoU-Dirtroad': 96.092371300358, 'IoU-Sky': 98.3675570310906, 'IoU-Large_stone': nan, 'IoU-Forrest': 80.92409790551191, 'IoU-Gravel': nan, 'mACC': 88.30147592116367, 'pACC': 95.23564603342581, 'ACC-other': nan, 'ACC-Grass': 94.17016443166301, 'ACC-CameraEdge': 95.94612688347894, 'ACC-Vehicle': nan, 'ACC-Person': 91.91195175602675, 'ACC-Bush': 42.99737353226803, 'ACC-Puddle': 96.70836076366031, 'ACC-Building': nan, 'ACC-Dirtroad': 97.92347600518806, 'ACC-Sky': 99.15128871026899, 'ACC-Large_stone': nan, 'ACC-Forrest': 87.60306528675528, 'ACC-Gravel': nan})])
[01/31 22:13:46] d2.utils.events INFO:  eta: 0:04:17  iter: 879  total_loss: 1.135  loss_ce: 0.01172  loss_mask: 0.05135  loss_dice: 0.09219  loss_ce_0: 0.0181  loss_mask_0: 0.05348  loss_dice_0: 0.09255  loss_ce_1: 0.01463  loss_mask_1: 0.05577  loss_dice_1: 0.09139  loss_ce_2: 0.01358  loss_mask_2: 0.05363  loss_dice_2: 0.09282  loss_ce_3: 0.01102  loss_mask_3: 0.05465  loss_dice_3: 0.09198  loss_ce_4: 0.01142  loss_mask_4: 0.05189  loss_dice_4: 0.09138  time: 0.4525  data_time: 0.0808  lr: 5.066e-05  max_mem: 5401M
[01/31 22:13:55] d2.utils.events INFO:  eta: 0:04:08  iter: 899  total_loss: 1.034  loss_ce: 0.01606  loss_mask: 0.0586  loss_dice: 0.08883  loss_ce_0: 0.01809  loss_mask_0: 0.05826  loss_dice_0: 0.08942  loss_ce_1: 0.01686  loss_mask_1: 0.05584  loss_dice_1: 0.08926  loss_ce_2: 0.01837  loss_mask_2: 0.05533  loss_dice_2: 0.08837  loss_ce_3: 0.01696  loss_mask_3: 0.05793  loss_dice_3: 0.08976  loss_ce_4: 0.01664  loss_mask_4: 0.05843  loss_dice_4: 0.09073  time: 0.4525  data_time: 0.0789  lr: 5.0177e-05  max_mem: 5401M
[01/31 22:14:04] d2.utils.events INFO:  eta: 0:03:59  iter: 919  total_loss: 1.012  loss_ce: 0.006715  loss_mask: 0.06535  loss_dice: 0.0947  loss_ce_0: 0.01133  loss_mask_0: 0.06548  loss_dice_0: 0.09863  loss_ce_1: 0.006835  loss_mask_1: 0.064  loss_dice_1: 0.09755  loss_ce_2: 0.006316  loss_mask_2: 0.06369  loss_dice_2: 0.09521  loss_ce_3: 0.005934  loss_mask_3: 0.06244  loss_dice_3: 0.09599  loss_ce_4: 0.00618  loss_mask_4: 0.06535  loss_dice_4: 0.09481  time: 0.4525  data_time: 0.0810  lr: 4.9614e-05  max_mem: 5401M
[01/31 22:14:13] d2.utils.events INFO:  eta: 0:03:50  iter: 939  total_loss: 0.9854  loss_ce: 0.01472  loss_mask: 0.0556  loss_dice: 0.08767  loss_ce_0: 0.01858  loss_mask_0: 0.05973  loss_dice_0: 0.08754  loss_ce_1: 0.01431  loss_mask_1: 0.05708  loss_dice_1: 0.0885  loss_ce_2: 0.01522  loss_mask_2: 0.05622  loss_dice_2: 0.08935  loss_ce_3: 0.01523  loss_mask_3: 0.05435  loss_dice_3: 0.08769  loss_ce_4: 0.01574  loss_mask_4: 0.05641  loss_dice_4: 0.08676  time: 0.4525  data_time: 0.0793  lr: 4.8972e-05  max_mem: 5401M
[01/31 22:14:22] d2.utils.events INFO:  eta: 0:03:41  iter: 959  total_loss: 1.176  loss_ce: 0.0177  loss_mask: 0.05842  loss_dice: 0.1064  loss_ce_0: 0.01971  loss_mask_0: 0.06184  loss_dice_0: 0.1109  loss_ce_1: 0.01751  loss_mask_1: 0.05858  loss_dice_1: 0.1052  loss_ce_2: 0.01818  loss_mask_2: 0.0578  loss_dice_2: 0.1062  loss_ce_3: 0.0172  loss_mask_3: 0.05726  loss_dice_3: 0.1059  loss_ce_4: 0.01732  loss_mask_4: 0.05686  loss_dice_4: 0.1063  time: 0.4527  data_time: 0.0831  lr: 4.825e-05  max_mem: 5401M
[01/31 22:14:31] d2.utils.events INFO:  eta: 0:03:32  iter: 979  total_loss: 0.9956  loss_ce: 0.01354  loss_mask: 0.05742  loss_dice: 0.07537  loss_ce_0: 0.01593  loss_mask_0: 0.05635  loss_dice_0: 0.08753  loss_ce_1: 0.01074  loss_mask_1: 0.05342  loss_dice_1: 0.0785  loss_ce_2: 0.01285  loss_mask_2: 0.05655  loss_dice_2: 0.08  loss_ce_3: 0.01174  loss_mask_3: 0.05812  loss_dice_3: 0.08057  loss_ce_4: 0.01233  loss_mask_4: 0.05903  loss_dice_4: 0.08081  time: 0.4528  data_time: 0.0789  lr: 4.7447e-05  max_mem: 5401M
[01/31 22:14:41] d2.utils.events INFO:  eta: 0:03:23  iter: 999  total_loss: 0.8975  loss_ce: 0.01242  loss_mask: 0.0474  loss_dice: 0.08442  loss_ce_0: 0.01247  loss_mask_0: 0.04806  loss_dice_0: 0.09122  loss_ce_1: 0.009181  loss_mask_1: 0.04813  loss_dice_1: 0.08858  loss_ce_2: 0.01068  loss_mask_2: 0.04789  loss_dice_2: 0.08745  loss_ce_3: 0.01235  loss_mask_3: 0.04678  loss_dice_3: 0.08593  loss_ce_4: 0.0127  loss_mask_4: 0.04726  loss_dice_4: 0.08394  time: 0.4528  data_time: 0.0791  lr: 4.6562e-05  max_mem: 5401M
[01/31 22:14:47] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:14:47] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:14:47] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:14:47] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:14:47] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:14:47] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:14:48] d2.evaluation.evaluator INFO: Inference done 11/29. Dataloading: 0.0013 s/iter. Inference: 0.0467 s/iter. Eval: 0.0241 s/iter. Total: 0.0720 s/iter. ETA=0:00:01
[01/31 22:14:50] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.775829 (0.073993 s / iter per device, on 1 devices)
[01/31 22:14:50] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.046750 s / iter per device, on 1 devices)
[01/31 22:14:50] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 73.56307056534597, 'fwIoU': 91.84636216946687, 'IoU-other': nan, 'IoU-Grass': 86.37675759141169, 'IoU-CameraEdge': 94.75356286839481, 'IoU-Vehicle': nan, 'IoU-Person': 38.847463703172615, 'IoU-Bush': 0.0, 'IoU-Puddle': 88.63920099875156, 'IoU-Building': nan, 'IoU-Dirtroad': 95.9295390820899, 'IoU-Sky': 98.41193100682965, 'IoU-Large_stone': nan, 'IoU-Forrest': 85.54610927211759, 'IoU-Gravel': nan, 'mACC': 83.67199982881364, 'pACC': 95.50084457300197, 'ACC-other': nan, 'ACC-Grass': 96.27678386014813, 'ACC-CameraEdge': 96.12760076702006, 'ACC-Vehicle': nan, 'ACC-Person': 97.29450671135919, 'ACC-Bush': 0.0, 'ACC-Puddle': 93.4825543120474, 'ACC-Building': nan, 'ACC-Dirtroad': 98.49546044098574, 'ACC-Sky': 99.43194764496094, 'ACC-Large_stone': nan, 'ACC-Forrest': 88.26714489398763, 'ACC-Gravel': nan})])
[01/31 22:14:50] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:14:50] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:14:50] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:14:50] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:14:50] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:14:50] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:14:52] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.769786 (0.073741 s / iter per device, on 1 devices)
[01/31 22:14:52] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.046787 s / iter per device, on 1 devices)
[01/31 22:14:52] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 73.56307056534597, 'fwIoU': 91.84636216946687, 'IoU-other': nan, 'IoU-Grass': 86.37675759141169, 'IoU-CameraEdge': 94.75356286839481, 'IoU-Vehicle': nan, 'IoU-Person': 38.847463703172615, 'IoU-Bush': 0.0, 'IoU-Puddle': 88.63920099875156, 'IoU-Building': nan, 'IoU-Dirtroad': 95.9295390820899, 'IoU-Sky': 98.41193100682965, 'IoU-Large_stone': nan, 'IoU-Forrest': 85.54610927211759, 'IoU-Gravel': nan, 'mACC': 83.67199982881364, 'pACC': 95.50084457300197, 'ACC-other': nan, 'ACC-Grass': 96.27678386014813, 'ACC-CameraEdge': 96.12760076702006, 'ACC-Vehicle': nan, 'ACC-Person': 97.29450671135919, 'ACC-Bush': 0.0, 'ACC-Puddle': 93.4825543120474, 'ACC-Building': nan, 'ACC-Dirtroad': 98.49546044098574, 'ACC-Sky': 99.43194764496094, 'ACC-Large_stone': nan, 'ACC-Forrest': 88.26714489398763, 'ACC-Gravel': nan})])
[01/31 22:14:54] d2.utils.events INFO:  eta: 0:03:14  iter: 1019  total_loss: 0.8925  loss_ce: 0.01106  loss_mask: 0.05398  loss_dice: 0.08651  loss_ce_0: 0.01368  loss_mask_0: 0.05385  loss_dice_0: 0.08021  loss_ce_1: 0.01205  loss_mask_1: 0.05377  loss_dice_1: 0.08057  loss_ce_2: 0.01206  loss_mask_2: 0.05535  loss_dice_2: 0.0848  loss_ce_3: 0.01146  loss_mask_3: 0.05295  loss_dice_3: 0.08582  loss_ce_4: 0.01139  loss_mask_4: 0.05466  loss_dice_4: 0.08532  time: 0.4528  data_time: 0.0822  lr: 4.5594e-05  max_mem: 5401M
[01/31 22:15:03] d2.utils.events INFO:  eta: 0:03:05  iter: 1039  total_loss: 0.8254  loss_ce: 0.004841  loss_mask: 0.04416  loss_dice: 0.08472  loss_ce_0: 0.009194  loss_mask_0: 0.04691  loss_dice_0: 0.08212  loss_ce_1: 0.007327  loss_mask_1: 0.04376  loss_dice_1: 0.08456  loss_ce_2: 0.005964  loss_mask_2: 0.04301  loss_dice_2: 0.0845  loss_ce_3: 0.00602  loss_mask_3: 0.04319  loss_dice_3: 0.08362  loss_ce_4: 0.005357  loss_mask_4: 0.04399  loss_dice_4: 0.08368  time: 0.4528  data_time: 0.0751  lr: 4.4543e-05  max_mem: 5401M
[01/31 22:15:12] d2.utils.events INFO:  eta: 0:02:56  iter: 1059  total_loss: 0.9362  loss_ce: 0.0103  loss_mask: 0.05499  loss_dice: 0.07986  loss_ce_0: 0.02  loss_mask_0: 0.05582  loss_dice_0: 0.08006  loss_ce_1: 0.01485  loss_mask_1: 0.05603  loss_dice_1: 0.08213  loss_ce_2: 0.01496  loss_mask_2: 0.05767  loss_dice_2: 0.08175  loss_ce_3: 0.0143  loss_mask_3: 0.05488  loss_dice_3: 0.08224  loss_ce_4: 0.01179  loss_mask_4: 0.05799  loss_dice_4: 0.07992  time: 0.4529  data_time: 0.0801  lr: 4.3407e-05  max_mem: 5401M
[01/31 22:15:21] d2.utils.events INFO:  eta: 0:02:47  iter: 1079  total_loss: 0.8558  loss_ce: 0.00601  loss_mask: 0.04601  loss_dice: 0.08402  loss_ce_0: 0.01108  loss_mask_0: 0.04862  loss_dice_0: 0.08465  loss_ce_1: 0.008989  loss_mask_1: 0.04713  loss_dice_1: 0.08339  loss_ce_2: 0.007771  loss_mask_2: 0.04775  loss_dice_2: 0.08434  loss_ce_3: 0.007323  loss_mask_3: 0.04682  loss_dice_3: 0.08363  loss_ce_4: 0.005996  loss_mask_4: 0.04728  loss_dice_4: 0.08324  time: 0.4528  data_time: 0.0781  lr: 4.2186e-05  max_mem: 5401M
[01/31 22:15:30] d2.utils.events INFO:  eta: 0:02:38  iter: 1099  total_loss: 0.9111  loss_ce: 0.01037  loss_mask: 0.04997  loss_dice: 0.08674  loss_ce_0: 0.01314  loss_mask_0: 0.05158  loss_dice_0: 0.08814  loss_ce_1: 0.01142  loss_mask_1: 0.05078  loss_dice_1: 0.08611  loss_ce_2: 0.01111  loss_mask_2: 0.04878  loss_dice_2: 0.08553  loss_ce_3: 0.01028  loss_mask_3: 0.04827  loss_dice_3: 0.08737  loss_ce_4: 0.01054  loss_mask_4: 0.04888  loss_dice_4: 0.08578  time: 0.4527  data_time: 0.0786  lr: 4.0877e-05  max_mem: 5401M
[01/31 22:15:39] d2.utils.events INFO:  eta: 0:02:29  iter: 1119  total_loss: 0.8461  loss_ce: 0.008073  loss_mask: 0.05208  loss_dice: 0.0808  loss_ce_0: 0.009125  loss_mask_0: 0.05866  loss_dice_0: 0.08078  loss_ce_1: 0.008026  loss_mask_1: 0.05919  loss_dice_1: 0.07984  loss_ce_2: 0.008535  loss_mask_2: 0.05523  loss_dice_2: 0.07904  loss_ce_3: 0.008361  loss_mask_3: 0.05443  loss_dice_3: 0.08071  loss_ce_4: 0.009039  loss_mask_4: 0.05337  loss_dice_4: 0.07956  time: 0.4526  data_time: 0.0771  lr: 3.9481e-05  max_mem: 5401M
[01/31 22:15:48] d2.utils.events INFO:  eta: 0:02:19  iter: 1139  total_loss: 0.9178  loss_ce: 0.008993  loss_mask: 0.0452  loss_dice: 0.08195  loss_ce_0: 0.012  loss_mask_0: 0.0463  loss_dice_0: 0.08773  loss_ce_1: 0.01219  loss_mask_1: 0.04593  loss_dice_1: 0.08633  loss_ce_2: 0.01145  loss_mask_2: 0.04516  loss_dice_2: 0.08386  loss_ce_3: 0.01027  loss_mask_3: 0.0442  loss_dice_3: 0.08271  loss_ce_4: 0.009746  loss_mask_4: 0.04613  loss_dice_4: 0.08288  time: 0.4525  data_time: 0.0762  lr: 3.7994e-05  max_mem: 5401M
[01/31 22:15:57] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:15:57] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:15:57] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:15:57] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:15:57] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:15:57] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:15:58] d2.evaluation.evaluator INFO: Inference done 11/29. Dataloading: 0.0011 s/iter. Inference: 0.0446 s/iter. Eval: 0.0238 s/iter. Total: 0.0696 s/iter. ETA=0:00:01
[01/31 22:15:59] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.728110 (0.072005 s / iter per device, on 1 devices)
[01/31 22:15:59] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.045354 s / iter per device, on 1 devices)
[01/31 22:15:59] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 87.37316451597657, 'fwIoU': 95.02843592154665, 'IoU-other': nan, 'IoU-Grass': 91.56035976118335, 'IoU-CameraEdge': 94.6599883332201, 'IoU-Vehicle': nan, 'IoU-Person': 83.87394683375247, 'IoU-Bush': 72.50131628253352, 'IoU-Puddle': 70.5421293272371, 'IoU-Building': nan, 'IoU-Dirtroad': 95.61521119391215, 'IoU-Sky': 98.47196045792964, 'IoU-Large_stone': nan, 'IoU-Forrest': 91.76040393804429, 'IoU-Gravel': nan, 'mACC': 91.12679453578103, 'pACC': 97.40932524277154, 'ACC-other': nan, 'ACC-Grass': 95.64108211514622, 'ACC-CameraEdge': 96.60890106684647, 'ACC-Vehicle': nan, 'ACC-Person': 88.33704939620213, 'ACC-Bush': 84.33830670080339, 'ACC-Puddle': 71.09940750493746, 'ACC-Building': nan, 'ACC-Dirtroad': 99.18377731218199, 'ACC-Sky': 99.28702030568223, 'ACC-Large_stone': nan, 'ACC-Forrest': 94.51881188444834, 'ACC-Gravel': nan})])
[01/31 22:15:59] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:15:59] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:15:59] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:15:59] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:15:59] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:15:59] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:16:02] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.726727 (0.071947 s / iter per device, on 1 devices)
[01/31 22:16:02] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.045082 s / iter per device, on 1 devices)
[01/31 22:16:02] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 87.37316451597657, 'fwIoU': 95.02843592154665, 'IoU-other': nan, 'IoU-Grass': 91.56035976118335, 'IoU-CameraEdge': 94.6599883332201, 'IoU-Vehicle': nan, 'IoU-Person': 83.87394683375247, 'IoU-Bush': 72.50131628253352, 'IoU-Puddle': 70.5421293272371, 'IoU-Building': nan, 'IoU-Dirtroad': 95.61521119391215, 'IoU-Sky': 98.47196045792964, 'IoU-Large_stone': nan, 'IoU-Forrest': 91.76040393804429, 'IoU-Gravel': nan, 'mACC': 91.12679453578103, 'pACC': 97.40932524277154, 'ACC-other': nan, 'ACC-Grass': 95.64108211514622, 'ACC-CameraEdge': 96.60890106684647, 'ACC-Vehicle': nan, 'ACC-Person': 88.33704939620213, 'ACC-Bush': 84.33830670080339, 'ACC-Puddle': 71.09940750493746, 'ACC-Building': nan, 'ACC-Dirtroad': 99.18377731218199, 'ACC-Sky': 99.28702030568223, 'ACC-Large_stone': nan, 'ACC-Forrest': 94.51881188444834, 'ACC-Gravel': nan})])
[01/31 22:16:02] d2.utils.events INFO:  eta: 0:02:10  iter: 1159  total_loss: 0.8454  loss_ce: 0.008195  loss_mask: 0.04949  loss_dice: 0.07422  loss_ce_0: 0.01165  loss_mask_0: 0.05466  loss_dice_0: 0.07483  loss_ce_1: 0.009624  loss_mask_1: 0.04919  loss_dice_1: 0.07688  loss_ce_2: 0.00929  loss_mask_2: 0.04935  loss_dice_2: 0.0755  loss_ce_3: 0.008455  loss_mask_3: 0.0496  loss_dice_3: 0.07441  loss_ce_4: 0.00791  loss_mask_4: 0.0492  loss_dice_4: 0.07415  time: 0.4524  data_time: 0.0741  lr: 3.6416e-05  max_mem: 5401M
[01/31 22:16:11] d2.utils.events INFO:  eta: 0:02:01  iter: 1179  total_loss: 0.7926  loss_ce: 0.008866  loss_mask: 0.04123  loss_dice: 0.06724  loss_ce_0: 0.01556  loss_mask_0: 0.04254  loss_dice_0: 0.06592  loss_ce_1: 0.01201  loss_mask_1: 0.04248  loss_dice_1: 0.06597  loss_ce_2: 0.01004  loss_mask_2: 0.04188  loss_dice_2: 0.06648  loss_ce_3: 0.009107  loss_mask_3: 0.04139  loss_dice_3: 0.06722  loss_ce_4: 0.008172  loss_mask_4: 0.04152  loss_dice_4: 0.06708  time: 0.4523  data_time: 0.0753  lr: 3.4745e-05  max_mem: 5401M
[01/31 22:16:20] d2.utils.events INFO:  eta: 0:01:52  iter: 1199  total_loss: 0.8329  loss_ce: 0.009229  loss_mask: 0.05066  loss_dice: 0.07836  loss_ce_0: 0.01179  loss_mask_0: 0.04779  loss_dice_0: 0.08114  loss_ce_1: 0.009151  loss_mask_1: 0.05143  loss_dice_1: 0.07941  loss_ce_2: 0.01019  loss_mask_2: 0.05125  loss_dice_2: 0.07742  loss_ce_3: 0.007799  loss_mask_3: 0.05051  loss_dice_3: 0.07729  loss_ce_4: 0.009056  loss_mask_4: 0.05055  loss_dice_4: 0.07862  time: 0.4522  data_time: 0.0756  lr: 3.2979e-05  max_mem: 5401M
[01/31 22:16:29] d2.utils.events INFO:  eta: 0:01:43  iter: 1219  total_loss: 0.8822  loss_ce: 0.004713  loss_mask: 0.04609  loss_dice: 0.07087  loss_ce_0: 0.01087  loss_mask_0: 0.04772  loss_dice_0: 0.07314  loss_ce_1: 0.01123  loss_mask_1: 0.04599  loss_dice_1: 0.06927  loss_ce_2: 0.006576  loss_mask_2: 0.04701  loss_dice_2: 0.06979  loss_ce_3: 0.004713  loss_mask_3: 0.04616  loss_dice_3: 0.0704  loss_ce_4: 0.00451  loss_mask_4: 0.04704  loss_dice_4: 0.07023  time: 0.4522  data_time: 0.0784  lr: 3.1114e-05  max_mem: 5401M
[01/31 22:16:38] d2.utils.events INFO:  eta: 0:01:34  iter: 1239  total_loss: 0.8512  loss_ce: 0.01034  loss_mask: 0.047  loss_dice: 0.08479  loss_ce_0: 0.01291  loss_mask_0: 0.04789  loss_dice_0: 0.08097  loss_ce_1: 0.01047  loss_mask_1: 0.0493  loss_dice_1: 0.08003  loss_ce_2: 0.0118  loss_mask_2: 0.04877  loss_dice_2: 0.0828  loss_ce_3: 0.01172  loss_mask_3: 0.04832  loss_dice_3: 0.08217  loss_ce_4: 0.01181  loss_mask_4: 0.04726  loss_dice_4: 0.0825  time: 0.4521  data_time: 0.0785  lr: 2.915e-05  max_mem: 5401M
[01/31 22:16:47] d2.utils.events INFO:  eta: 0:01:25  iter: 1259  total_loss: 0.8318  loss_ce: 0.01027  loss_mask: 0.04568  loss_dice: 0.08574  loss_ce_0: 0.01306  loss_mask_0: 0.04596  loss_dice_0: 0.08901  loss_ce_1: 0.01128  loss_mask_1: 0.04523  loss_dice_1: 0.08828  loss_ce_2: 0.01128  loss_mask_2: 0.04635  loss_dice_2: 0.08718  loss_ce_3: 0.009521  loss_mask_3: 0.04536  loss_dice_3: 0.08604  loss_ce_4: 0.01  loss_mask_4: 0.04559  loss_dice_4: 0.08508  time: 0.4520  data_time: 0.0739  lr: 2.7081e-05  max_mem: 5401M
[01/31 22:16:56] d2.utils.events INFO:  eta: 0:01:16  iter: 1279  total_loss: 0.9515  loss_ce: 0.009148  loss_mask: 0.04438  loss_dice: 0.08557  loss_ce_0: 0.01202  loss_mask_0: 0.04753  loss_dice_0: 0.08552  loss_ce_1: 0.01126  loss_mask_1: 0.04829  loss_dice_1: 0.08439  loss_ce_2: 0.01029  loss_mask_2: 0.04487  loss_dice_2: 0.08439  loss_ce_3: 0.008825  loss_mask_3: 0.0439  loss_dice_3: 0.08576  loss_ce_4: 0.008785  loss_mask_4: 0.04466  loss_dice_4: 0.08444  time: 0.4520  data_time: 0.0787  lr: 2.4904e-05  max_mem: 5401M
[01/31 22:17:04] d2.utils.events INFO:  eta: 0:01:07  iter: 1299  total_loss: 0.8686  loss_ce: 0.008166  loss_mask: 0.04605  loss_dice: 0.07973  loss_ce_0: 0.01377  loss_mask_0: 0.04664  loss_dice_0: 0.08301  loss_ce_1: 0.01307  loss_mask_1: 0.04722  loss_dice_1: 0.0804  loss_ce_2: 0.01017  loss_mask_2: 0.04614  loss_dice_2: 0.07947  loss_ce_3: 0.007827  loss_mask_3: 0.04587  loss_dice_3: 0.08075  loss_ce_4: 0.008168  loss_mask_4: 0.04569  loss_dice_4: 0.07943  time: 0.4519  data_time: 0.0760  lr: 2.2615e-05  max_mem: 5401M
[01/31 22:17:07] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:17:07] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:17:07] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:17:07] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:17:07] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:17:07] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:17:08] d2.evaluation.evaluator INFO: Inference done 11/29. Dataloading: 0.0012 s/iter. Inference: 0.0445 s/iter. Eval: 0.0241 s/iter. Total: 0.0698 s/iter. ETA=0:00:01
[01/31 22:17:09] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.719992 (0.071666 s / iter per device, on 1 devices)
[01/31 22:17:09] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.044737 s / iter per device, on 1 devices)
[01/31 22:17:09] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 89.77534686493263, 'fwIoU': 96.38294889690522, 'IoU-other': nan, 'IoU-Grass': 94.45348647458164, 'IoU-CameraEdge': 94.68241932141444, 'IoU-Vehicle': nan, 'IoU-Person': 84.20985448046974, 'IoU-Bush': 77.94603922300212, 'IoU-Puddle': 76.85039370078741, 'IoU-Building': nan, 'IoU-Dirtroad': 96.67700295173887, 'IoU-Sky': 98.51451556263436, 'IoU-Large_stone': nan, 'IoU-Forrest': 94.8690632048324, 'IoU-Gravel': nan, 'mACC': 95.66378269211, 'pACC': 98.13299476601607, 'ACC-other': nan, 'ACC-Grass': 96.88640182240374, 'ACC-CameraEdge': 96.13262178356071, 'ACC-Vehicle': nan, 'ACC-Person': 88.8458257889775, 'ACC-Bush': 92.21770989670698, 'ACC-Puddle': 96.37919684002634, 'ACC-Building': nan, 'ACC-Dirtroad': 98.94717150553727, 'ACC-Sky': 99.50376202562457, 'ACC-Large_stone': nan, 'ACC-Forrest': 96.39757187404302, 'ACC-Gravel': nan})])
[01/31 22:17:09] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:17:09] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:17:09] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:17:09] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:17:09] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:17:09] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:17:11] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.766135 (0.073589 s / iter per device, on 1 devices)
[01/31 22:17:11] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.046653 s / iter per device, on 1 devices)
[01/31 22:17:11] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 89.77534686493263, 'fwIoU': 96.38294889690522, 'IoU-other': nan, 'IoU-Grass': 94.45348647458164, 'IoU-CameraEdge': 94.68241932141444, 'IoU-Vehicle': nan, 'IoU-Person': 84.20985448046974, 'IoU-Bush': 77.94603922300212, 'IoU-Puddle': 76.85039370078741, 'IoU-Building': nan, 'IoU-Dirtroad': 96.67700295173887, 'IoU-Sky': 98.51451556263436, 'IoU-Large_stone': nan, 'IoU-Forrest': 94.8690632048324, 'IoU-Gravel': nan, 'mACC': 95.66378269211, 'pACC': 98.13299476601607, 'ACC-other': nan, 'ACC-Grass': 96.88640182240374, 'ACC-CameraEdge': 96.13262178356071, 'ACC-Vehicle': nan, 'ACC-Person': 88.8458257889775, 'ACC-Bush': 92.21770989670698, 'ACC-Puddle': 96.37919684002634, 'ACC-Building': nan, 'ACC-Dirtroad': 98.94717150553727, 'ACC-Sky': 99.50376202562457, 'ACC-Large_stone': nan, 'ACC-Forrest': 96.39757187404302, 'ACC-Gravel': nan})])
[01/31 22:17:18] d2.utils.events INFO:  eta: 0:00:58  iter: 1319  total_loss: 0.8072  loss_ce: 0.00815  loss_mask: 0.03702  loss_dice: 0.06977  loss_ce_0: 0.01016  loss_mask_0: 0.0386  loss_dice_0: 0.0723  loss_ce_1: 0.01006  loss_mask_1: 0.0413  loss_dice_1: 0.07098  loss_ce_2: 0.01017  loss_mask_2: 0.04147  loss_dice_2: 0.07037  loss_ce_3: 0.008929  loss_mask_3: 0.03909  loss_dice_3: 0.0698  loss_ce_4: 0.008197  loss_mask_4: 0.03835  loss_dice_4: 0.06954  time: 0.4519  data_time: 0.0771  lr: 2.0207e-05  max_mem: 5401M
[01/31 22:17:27] d2.utils.events INFO:  eta: 0:00:49  iter: 1339  total_loss: 0.8255  loss_ce: 0.008475  loss_mask: 0.04684  loss_dice: 0.08058  loss_ce_0: 0.01313  loss_mask_0: 0.0463  loss_dice_0: 0.08193  loss_ce_1: 0.01042  loss_mask_1: 0.04708  loss_dice_1: 0.08174  loss_ce_2: 0.01003  loss_mask_2: 0.04604  loss_dice_2: 0.08  loss_ce_3: 0.008895  loss_mask_3: 0.04655  loss_dice_3: 0.08078  loss_ce_4: 0.008645  loss_mask_4: 0.04574  loss_dice_4: 0.07995  time: 0.4518  data_time: 0.0750  lr: 1.7672e-05  max_mem: 5401M
[01/31 22:17:36] d2.utils.events INFO:  eta: 0:00:40  iter: 1359  total_loss: 0.7924  loss_ce: 0.006581  loss_mask: 0.04683  loss_dice: 0.06783  loss_ce_0: 0.007812  loss_mask_0: 0.046  loss_dice_0: 0.06928  loss_ce_1: 0.007112  loss_mask_1: 0.04533  loss_dice_1: 0.06991  loss_ce_2: 0.007379  loss_mask_2: 0.04796  loss_dice_2: 0.06878  loss_ce_3: 0.006786  loss_mask_3: 0.0467  loss_dice_3: 0.06933  loss_ce_4: 0.006921  loss_mask_4: 0.04696  loss_dice_4: 0.06823  time: 0.4517  data_time: 0.0759  lr: 1.4999e-05  max_mem: 5401M
[01/31 22:17:45] d2.utils.events INFO:  eta: 0:00:31  iter: 1379  total_loss: 0.6905  loss_ce: 0.004752  loss_mask: 0.03654  loss_dice: 0.06621  loss_ce_0: 0.006767  loss_mask_0: 0.03895  loss_dice_0: 0.06742  loss_ce_1: 0.004986  loss_mask_1: 0.0379  loss_dice_1: 0.06724  loss_ce_2: 0.005171  loss_mask_2: 0.03844  loss_dice_2: 0.06569  loss_ce_3: 0.004661  loss_mask_3: 0.03736  loss_dice_3: 0.06665  loss_ce_4: 0.004615  loss_mask_4: 0.03666  loss_dice_4: 0.06662  time: 0.4515  data_time: 0.0751  lr: 1.2173e-05  max_mem: 5401M
[01/31 22:17:54] d2.utils.events INFO:  eta: 0:00:22  iter: 1399  total_loss: 0.7792  loss_ce: 0.006748  loss_mask: 0.04322  loss_dice: 0.07823  loss_ce_0: 0.008416  loss_mask_0: 0.04478  loss_dice_0: 0.07952  loss_ce_1: 0.005884  loss_mask_1: 0.04473  loss_dice_1: 0.07982  loss_ce_2: 0.005647  loss_mask_2: 0.04417  loss_dice_2: 0.08028  loss_ce_3: 0.006212  loss_mask_3: 0.04391  loss_dice_3: 0.0784  loss_ce_4: 0.00664  loss_mask_4: 0.04322  loss_dice_4: 0.07788  time: 0.4515  data_time: 0.0760  lr: 9.1693e-06  max_mem: 5401M
[01/31 22:18:03] d2.utils.events INFO:  eta: 0:00:13  iter: 1419  total_loss: 0.6754  loss_ce: 0.004943  loss_mask: 0.04027  loss_dice: 0.06176  loss_ce_0: 0.008449  loss_mask_0: 0.04068  loss_dice_0: 0.06598  loss_ce_1: 0.005835  loss_mask_1: 0.03967  loss_dice_1: 0.06293  loss_ce_2: 0.006059  loss_mask_2: 0.03957  loss_dice_2: 0.0623  loss_ce_3: 0.004852  loss_mask_3: 0.03927  loss_dice_3: 0.06254  loss_ce_4: 0.004569  loss_mask_4: 0.03997  loss_dice_4: 0.06261  time: 0.4515  data_time: 0.0791  lr: 5.9418e-06  max_mem: 5401M
[01/31 22:18:12] d2.utils.events INFO:  eta: 0:00:04  iter: 1439  total_loss: 0.7377  loss_ce: 0.005367  loss_mask: 0.03941  loss_dice: 0.0664  loss_ce_0: 0.008005  loss_mask_0: 0.04045  loss_dice_0: 0.06621  loss_ce_1: 0.006486  loss_mask_1: 0.04065  loss_dice_1: 0.06602  loss_ce_2: 0.005788  loss_mask_2: 0.04088  loss_dice_2: 0.06538  loss_ce_3: 0.005988  loss_mask_3: 0.03927  loss_dice_3: 0.06611  loss_ce_4: 0.005609  loss_mask_4: 0.03843  loss_dice_4: 0.06662  time: 0.4514  data_time: 0.0784  lr: 2.3715e-06  max_mem: 5401M
[01/31 22:18:16] fvcore.common.checkpoint INFO: Saving checkpoint to ./ffiModel/model_final.pth
[01/31 22:18:18] d2.utils.events INFO:  eta: 0:00:00  iter: 1449  total_loss: 0.6884  loss_ce: 0.005715  loss_mask: 0.03712  loss_dice: 0.06552  loss_ce_0: 0.007537  loss_mask_0: 0.03884  loss_dice_0: 0.06541  loss_ce_1: 0.006486  loss_mask_1: 0.03888  loss_dice_1: 0.06602  loss_ce_2: 0.006487  loss_mask_2: 0.03922  loss_dice_2: 0.06469  loss_ce_3: 0.006743  loss_mask_3: 0.0382  loss_dice_3: 0.06497  loss_ce_4: 0.005835  loss_mask_4: 0.03721  loss_dice_4: 0.06482  time: 0.4514  data_time: 0.0777  lr: 2.7592e-07  max_mem: 5401M
[01/31 22:18:18] d2.engine.hooks INFO: Overall training speed: 1448 iterations in 0:10:53 (0.4514 s / it)
[01/31 22:18:18] d2.engine.hooks INFO: Total training time: 0:11:36 (0:00:42 on hooks)
[01/31 22:18:18] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:18:18] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:18:18] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:18:18] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:18:18] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:18:18] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:18:19] d2.evaluation.evaluator INFO: Inference done 11/29. Dataloading: 0.0010 s/iter. Inference: 0.0446 s/iter. Eval: 0.0238 s/iter. Total: 0.0694 s/iter. ETA=0:00:01
[01/31 22:18:20] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.717191 (0.071550 s / iter per device, on 1 devices)
[01/31 22:18:20] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.045190 s / iter per device, on 1 devices)
[01/31 22:18:20] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 90.18049678347548, 'fwIoU': 96.49133232879078, 'IoU-other': nan, 'IoU-Grass': 94.39938853764697, 'IoU-CameraEdge': 95.10591243569225, 'IoU-Vehicle': nan, 'IoU-Person': 86.14139890963925, 'IoU-Bush': 77.54942528735633, 'IoU-Puddle': 77.78361344537815, 'IoU-Building': nan, 'IoU-Dirtroad': 96.7565328420909, 'IoU-Sky': 98.65868500262502, 'IoU-Large_stone': nan, 'IoU-Forrest': 95.0490178073749, 'IoU-Gravel': nan, 'mACC': 94.9462618207017, 'pACC': 98.19882133535067, 'ACC-other': nan, 'ACC-Grass': 97.22832277186602, 'ACC-CameraEdge': 96.75474964255145, 'ACC-Vehicle': nan, 'ACC-Person': 88.90119263172072, 'ACC-Bush': 83.76169771342809, 'ACC-Puddle': 97.49835418038182, 'ACC-Building': nan, 'ACC-Dirtroad': 99.04150453955901, 'ACC-Sky': 99.4557750403956, 'ACC-Large_stone': nan, 'ACC-Forrest': 96.92849804571094, 'ACC-Gravel': nan})])
[01/31 22:18:20] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:18:20] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=2048, sample_style='choice')]
[01/31 22:18:20] d2.data.common INFO: Serializing 29 elements to byte tensors and concatenating them all ...
[01/31 22:18:20] d2.data.common INFO: Serialized dataset takes 0.00 MiB
[01/31 22:18:20] d2.data.datasets.coco INFO: Loaded 29 images with semantic segmentation from ../../../data/dataset/train/images
[01/31 22:18:20] d2.evaluation.evaluator INFO: Start inference on 29 batches
[01/31 22:18:22] d2.evaluation.evaluator INFO: Total inference time: 0:00:01.731024 (0.072126 s / iter per device, on 1 devices)
[01/31 22:18:22] d2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:01 (0.045948 s / iter per device, on 1 devices)
[01/31 22:18:22] d2.evaluation.sem_seg_evaluation INFO: OrderedDict([('sem_seg', {'mIoU': 90.18049678347548, 'fwIoU': 96.49133232879078, 'IoU-other': nan, 'IoU-Grass': 94.39938853764697, 'IoU-CameraEdge': 95.10591243569225, 'IoU-Vehicle': nan, 'IoU-Person': 86.14139890963925, 'IoU-Bush': 77.54942528735633, 'IoU-Puddle': 77.78361344537815, 'IoU-Building': nan, 'IoU-Dirtroad': 96.7565328420909, 'IoU-Sky': 98.65868500262502, 'IoU-Large_stone': nan, 'IoU-Forrest': 95.0490178073749, 'IoU-Gravel': nan, 'mACC': 94.9462618207017, 'pACC': 98.19882133535067, 'ACC-other': nan, 'ACC-Grass': 97.22832277186602, 'ACC-CameraEdge': 96.75474964255145, 'ACC-Vehicle': nan, 'ACC-Person': 88.90119263172072, 'ACC-Bush': 83.76169771342809, 'ACC-Puddle': 97.49835418038182, 'ACC-Building': nan, 'ACC-Dirtroad': 99.04150453955901, 'ACC-Sky': 99.4557750403956, 'ACC-Large_stone': nan, 'ACC-Forrest': 96.92849804571094, 'ACC-Gravel': nan})])
[02/04 18:35:17] detectron2 INFO: Rank of current process: 0. World size: 1
[02/04 18:35:18] detectron2 INFO: Environment info:
----------------------  ------------------------------------------------------------------
sys.platform            linux
Python                  3.8.10 (default, Nov 26 2021, 20:14:08) [GCC 9.3.0]
numpy                   1.20.3
detectron2              0.6 @/lhome/asbjotof/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 9.3
CUDA compiler           CUDA 11.4
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.1+cu102 @/usr/local/lib/python3.8/dist-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   GRID RTX8000-8Q (arch=7.5)
Driver version          470.63.01
CUDA_HOME               /usr/local/cuda
Pillow                  8.3.2
torchvision             0.10.1+cu102 @/usr/local/lib/python3.8/dist-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5
fvcore                  0.1.5.post20210924
iopath                  0.1.8
cv2                     4.5.4
----------------------  ------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[02/04 18:35:18] detectron2 INFO: Command line arguments: Namespace(config_file='', dist_url='tcp://127.0.0.1:54076', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[02/04 18:35:18] detectron2 INFO: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m  [39m-[38;5;15m [39mffi_train_stuffonly
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mabsolute
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39mmask_former_semantic
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mbitmask
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m256
[38;5;15m  [39m-[38;5;15m [39m307
[38;5;15m  [39m-[38;5;15m [39m358
[38;5;15m  [39m-[38;5;15m [39m409
[38;5;15m  [39m-[38;5;15m [39m460
[38;5;15m  [39m-[38;5;15m [39m512
[38;5;15m  [39m-[38;5;15m [39m563
[38;5;15m  [39m-[38;5;15m [39m614
[38;5;15m  [39m-[38;5;15m [39m665
[38;5;15m  [39m-[38;5;15m [39m716
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m819
[38;5;15m  [39m-[38;5;15m [39m870
[38;5;15m  [39m-[38;5;15m [39m921
[38;5;15m  [39m-[38;5;15m [39m972
[38;5;15m  [39m-[38;5;15m [39m1024
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m      [39m-[38;5;15m [39m64
[38;5;15m      [39m-[38;5;15m [39m128
[38;5;15m      [39m-[38;5;15m [39m256
[38;5;15m      [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mD2SwinTransformer
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_FORMER[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m6
[38;5;15m    [39m[38;5;197mDEEP_SUPERVISION[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mDICE_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mDIM_FEEDFORWARD[39m[38;5;15m:[39m[38;5;15m [39m2048
[38;5;15m    [39m[38;5;197mDROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mENFORCE_INPUT_PROJ[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mHIDDEN_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mMASK_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m20.0
[38;5;15m    [39m[38;5;197mNHEADS[39m[38;5;15m:[39m[38;5;15m [39m8
[38;5;15m    [39m[38;5;197mNO_OBJECT_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mNUM_OBJECT_QUERIES[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m    [39m[38;5;197mPRE_NORM[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m32
[38;5;15m    [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mOBJECT_MASK_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mOVERLAP_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m      [39m[38;5;197mPANOPTIC_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m      [39m[38;5;197mSEM_SEG_POSTPROCESSING_BEFORE_INFERENCE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mTRANSFORMER_IN_FEATURE[39m[38;5;15m:[39m[38;5;15m [39mres5
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mMaskFormer
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m123.675
[38;5;15m  [39m-[38;5;15m [39m116.28
[38;5;15m  [39m-[38;5;15m [39m103.53
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m58.395
[38;5;15m  [39m-[38;5;15m [39m57.12
[38;5;15m  [39m-[38;5;15m [39m57.375
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39mbasic
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id003[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRes5ROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id003[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m6000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m12000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m18
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39mhard_pixel_mining
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMASK_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskFormerHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m12
[38;5;15m    [39m[38;5;197mPIXEL_DECODER_NAME[39m[38;5;15m:[39m[38;5;15m [39mBasePixelDecoder
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m48
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m[38;5;197mTRANSFORMER_ENC_LAYERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSWIN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mAPE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.3
[38;5;15m    [39m[38;5;197mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mEMBED_DIM[39m[38;5;15m:[39m[38;5;15m [39m96
[38;5;15m    [39m[38;5;197mMLP_RATIO[39m[38;5;15m:[39m[38;5;15m [39m4.0
[38;5;15m    [39m[38;5;197mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m3
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m24
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mPATCH_NORM[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mPATCH_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRETRAIN_IMG_SIZE[39m[38;5;15m:[39m[38;5;15m [39m224
[38;5;15m    [39m[38;5;197mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mQK_SCALE[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m    [39m[38;5;197mWINDOW_SIZE[39m[38;5;15m:[39m[38;5;15m [39m7
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39mmodels/model_final_8657a5.pkl
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m./ffiModel
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.0002
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mfull_model
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupPolyLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m1450
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39mADAMW
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0e-06
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m1500
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m3584
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m384
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m640
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m896
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m145
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[02/04 18:35:18] detectron2 INFO: Full config saved to ./ffiModel/config.yaml
[02/04 18:35:18] d2.utils.env INFO: Using a generated random seed 19353588
[02/04 18:35:22] d2.engine.defaults INFO: Model:
MaskFormer(
  (backbone): D2SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          (reduction): Linear(in_features=1536, out_features=768, bias=False)
          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): BasicLayer(
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=768, out_features=2304, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=768, out_features=768, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (sem_seg_head): MaskFormerHead(
    (pixel_decoder): BasePixelDecoder(
      (adapter_1): Conv2d(
        96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_2): Conv2d(
        192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (adapter_3): Conv2d(
        384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (layer_4): Conv2d(
        768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (mask_features): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (predictor): TransformerPredictor(
      (pe_layer): PositionEmbeddingSine()
      (transformer): Transformer(
        (encoder): TransformerEncoder(
          (layers): ModuleList()
        )
        (decoder): TransformerDecoder(
          (layers): ModuleList(
            (0): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (1): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (2): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (3): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (4): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
            (5): TransformerDecoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (multihead_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (linear1): Linear(in_features=256, out_features=2048, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=2048, out_features=256, bias=True)
              (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
              (dropout3): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (query_embed): Embedding(100, 256)
      (input_proj): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (class_embed): Linear(in_features=256, out_features=13, bias=True)
      (mask_embed): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
  (criterion): SetCriterion(
    (matcher): Matcher HungarianMatcher
        cost_class: 1
        cost_mask: 20.0
        cost_dice: 1.0
  )
)
[02/04 18:35:22] mask_former.data.dataset_mappers.mask_former_semantic_dataset_mapper INFO: [MaskFormerSemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=2048, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[512, 512], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7fe84de7cf10>, RandomFlip()]
[02/04 18:35:22] d2.data.datasets.coco WARNING: Directory ../../../data/dataset/train/images and ../../../data/dataset/train/panoptic_stuff_train has 145 and 174 files, respectively.
[02/04 18:35:22] d2.data.datasets.coco WARNING: Will use their intersection of 145 files.
[02/04 18:35:22] d2.data.datasets.coco INFO: Loaded 145 images with semantic segmentation from ../../../data/dataset/train/images
[02/04 18:35:22] d2.data.build INFO: Using training sampler TrainingSampler
[02/04 18:35:22] d2.data.common INFO: Serializing 145 elements to byte tensors and concatenating them all ...
[02/04 18:35:22] d2.data.common INFO: Serialized dataset takes 0.03 MiB
[02/04 18:35:22] fvcore.common.checkpoint INFO: [Checkpointer] Loading from models/model_final_8657a5.pkl ...
[02/04 18:35:23] fvcore.common.checkpoint INFO: Reading a file from 'MaskFormer Model Zoo'
[02/04 18:35:23] mask_former.modeling.heads.mask_former_head WARNING: Weight format of MaskFormerHead have changed! Please upgrade your models. Applying automatic conversion now ...
[02/04 18:35:23] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.weight' to the model due to incompatible shapes: (151, 256) in the checkpoint but (13, 256) in the model! You might want to double check if this is expected.
[02/04 18:35:23] fvcore.common.checkpoint WARNING: Skip loading parameter 'sem_seg_head.predictor.class_embed.bias' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[02/04 18:35:23] fvcore.common.checkpoint WARNING: Skip loading parameter 'criterion.empty_weight' to the model due to incompatible shapes: (151,) in the checkpoint but (13,) in the model! You might want to double check if this is expected.
[02/04 18:35:23] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mcriterion.empty_weight[0m
[34msem_seg_head.predictor.class_embed.{bias, weight}[0m
[02/04 18:35:23] d2.engine.train_loop INFO: Starting training from iteration 0
[02/04 18:35:36] d2.utils.events INFO:  eta: 0:14:43  iter: 19  total_loss: 23.49  loss_ce: 3.487  loss_mask: 0.1731  loss_dice: 0.2881  loss_ce_0: 3.302  loss_mask_0: 0.1641  loss_dice_0: 0.2925  loss_ce_1: 3.418  loss_mask_1: 0.1605  loss_dice_1: 0.2986  loss_ce_2: 3.504  loss_mask_2: 0.1756  loss_dice_2: 0.2935  loss_ce_3: 3.447  loss_mask_3: 0.181  loss_dice_3: 0.292  loss_ce_4: 3.51  loss_mask_4: 0.1709  loss_dice_4: 0.2905  time: 0.6233  data_time: 0.2591  lr: 2.5036e-06  max_mem: 5320M
[02/04 18:35:48] d2.utils.events INFO:  eta: 0:14:29  iter: 39  total_loss: 20.78  loss_ce: 2.918  loss_mask: 0.1603  loss_dice: 0.2651  loss_ce_0: 3.061  loss_mask_0: 0.1566  loss_dice_0: 0.2728  loss_ce_1: 3.146  loss_mask_1: 0.1494  loss_dice_1: 0.2649  loss_ce_2: 3.044  loss_mask_2: 0.1499  loss_dice_2: 0.2611  loss_ce_3: 2.914  loss_mask_3: 0.1639  loss_dice_3: 0.2653  loss_ce_4: 2.954  loss_mask_4: 0.1607  loss_dice_4: 0.2725  time: 0.6172  data_time: 0.2392  lr: 5.0741e-06  max_mem: 5320M
[02/04 18:35:54] d2.engine.hooks INFO: Overall training speed: 47 iterations in 0:00:29 (0.6276 s / it)
[02/04 18:35:54] d2.engine.hooks INFO: Total training time: 0:00:29 (0:00:00 on hooks)
[02/04 18:35:54] d2.utils.events INFO:  eta: 0:14:23  iter: 49  total_loss: 18.99  loss_ce: 2.543  loss_mask: 0.1678  loss_dice: 0.2641  loss_ce_0: 2.745  loss_mask_0: 0.153  loss_dice_0: 0.2645  loss_ce_1: 2.876  loss_mask_1: 0.1526  loss_dice_1: 0.2582  loss_ce_2: 2.755  loss_mask_2: 0.1598  loss_dice_2: 0.2573  loss_ce_3: 2.637  loss_mask_3: 0.1639  loss_dice_3: 0.258  loss_ce_4: 2.622  loss_mask_4: 0.1737  loss_dice_4: 0.2646  time: 0.6168  data_time: 0.2435  lr: 6.2092e-06  max_mem: 5320M
